{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Timliuw/DP-Tim/blob/main/CI_Tim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd74f5f",
      "metadata": {
        "id": "cfd74f5f"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import copy\n",
        "import getopt\n",
        "import psycopg2\n",
        "import sys\n",
        "import time\n",
        "import pandas as pd\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "zfatDYXyr6eo",
      "metadata": {
        "id": "zfatDYXyr6eo"
      },
      "outputs": [],
      "source": [
        "#for experiments purpose\n",
        "import gspread\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.service_account import Credentials\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "import os\n",
        "os.listdir()\n",
        "\n",
        "scope = [\n",
        "    \"https://spreadsheets.google.com/feeds\",  # Google Sheets API\n",
        "    \"https://www.googleapis.com/auth/drive\"   # Google Drive API\n",
        "]\n",
        "\n",
        "# Trigger the file upload dialog\n",
        "try:\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(\"sublime-mission-447319-c2-0df1612796a8.json\", scope)\n",
        "except:\n",
        "   uploaded = files.upload()\n",
        "\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(\"sublime-mission-447319-c2-0df1612796a8.json\", scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "spreadsheet = client.open_by_key(\"1yVVt5ACdBbjsZ_7IiRkvPGIHmpKe8mFXcvyL0PVP2cE\")\n",
        "\n",
        "worksheet1 = spreadsheet.get_worksheet(0)\n",
        "worksheet = worksheet1\n",
        "worksheet2 = spreadsheet.get_worksheet(1)\n",
        "\n",
        "def get_color(curr_value, prev_value):\n",
        "    if curr_value < 0.6 * prev_value:\n",
        "        return {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6}  # very green\n",
        "    elif curr_value < prev_value:\n",
        "        return {\"red\": 0.8, \"green\": 1.0, \"blue\": 0.8}  # green\n",
        "    elif curr_value > 1.4 * prev_value:\n",
        "        return {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6}  # very red\n",
        "    elif curr_value > prev_value:\n",
        "        return {\"red\": 1.0, \"green\": 0.8, \"blue\": 0.8}  # red\n",
        "    return None\n",
        "\n",
        "def write_to_sheet(worksheet, row_data, output_mode=0, compare=False):\n",
        "    # Append the new row to the sheet\n",
        "    try:\n",
        "        worksheet.append_row(row_data)\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        print(f\"Row data: {row_data}\")\n",
        "    # Format colour according to the comparing results\n",
        "    if compare:\n",
        "        pre_row_index = -2\n",
        "        if (output_mode == 2): pre_row_index = -18\n",
        "        sheet_data = worksheet.get_all_values()\n",
        "        last_row_index = len(sheet_data)\n",
        "        if last_row_index > 1:\n",
        "            last_row = sheet_data[-1]\n",
        "            prev_row = sheet_data[pre_row_index]\n",
        "            for col_index, (curr_value, prev_value) in enumerate(zip(last_row, prev_row), start=1):\n",
        "                try:\n",
        "                    curr_value = float(curr_value)\n",
        "                    prev_value = float(prev_value)\n",
        "                    if (worksheet.row_values(1)[col_index-1] == \"est median\"):\n",
        "                      prev_value = abs(true_med - prev_value)\n",
        "                      curr_value = abs(true_med - curr_value)\n",
        "                    color = get_color(curr_value, prev_value)\n",
        "                    if color:\n",
        "                        worksheet.format(f\"{chr(64 + col_index)}{last_row_index}\", {\"backgroundColor\": color})\n",
        "                except:\n",
        "                    continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "202456b3",
      "metadata": {
        "id": "202456b3"
      },
      "outputs": [],
      "source": [
        "def discretize(D, b):\n",
        "    n = len(D)\n",
        "    discreteD = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        discreteD[i] = int(D[i]/b)\n",
        "    return discreteD\n",
        "\n",
        "def discrete(D):\n",
        "    n = len(D)\n",
        "    newD = np.zeros(n)\n",
        "    previous = -1\n",
        "    for i in range(n):\n",
        "        if D[i]!=previous:\n",
        "            newD[i] = n*D[i]\n",
        "            #print(newD[i])\n",
        "            previous = D[i]\n",
        "        elif D[i]==previous:\n",
        "            newD[i] = newD[i-1]+1\n",
        "\n",
        "    return newD\n",
        "\n",
        "def count(D, a):\n",
        "    counter = 0\n",
        "    n = len(D)\n",
        "    low = 0\n",
        "    up=n-1\n",
        "    mid = int((low+up)/2)\n",
        "    while True:\n",
        "        if D[mid]>a:\n",
        "            up=mid\n",
        "            mid = int((low+up)/2)\n",
        "        if D[mid]<a:\n",
        "            low=mid\n",
        "            mid = int((low+up)/2)\n",
        "        if D[mid]==a:\n",
        "            i=0\n",
        "            while D[mid+i]==a:\n",
        "                i+=1\n",
        "            return mid+i\n",
        "\n",
        "def clip(D, a, b):\n",
        "    clipped = copy.deepcopy(D)\n",
        "    clipped[clipped<a] = a\n",
        "    clipped[clipped>b] = b\n",
        "    return clipped\n",
        "\n",
        "def LapNoise():\n",
        "    a = random.uniform(0,1)\n",
        "    b = math.log(1/(1-a))\n",
        "    c = random.uniform(0,1)\n",
        "    if c>0.5:\n",
        "        return b\n",
        "    else:\n",
        "        return -b\n",
        "\n",
        "def F(x):\n",
        "    return 1/2+1/(4*math.pi)*(math.log(abs(2*x**2+2*math.sqrt(2)*x+2)/abs(abs(2*x**2-2*math.sqrt(2)*x+2)))+2*math.atan(math.sqrt(2)*x+1)+2*math.atan(math.sqrt(2)*x-1))\n",
        "def inver_F(y):\n",
        "    #find the solution of F(x)=y\n",
        "    #Find between -1000000 and 1000000 because F(1000000)=1.0 in python\n",
        "    if y>1/2:\n",
        "        low =0.0\n",
        "        high = 1000000.0\n",
        "        mid = (high+low)/2\n",
        "        while abs(high-low)>0.0000001:\n",
        "            if F(mid)>y:\n",
        "                high=mid\n",
        "            elif F(mid)==y:\n",
        "                return mid\n",
        "            else:\n",
        "                low = mid\n",
        "            mid = (high+low)/2\n",
        "\n",
        "        return high\n",
        "    if y==1/2:\n",
        "        return 0\n",
        "\n",
        "def CauchyNoise():\n",
        "    a = random.uniform(0.5,1)\n",
        "    b = inver_F(a)\n",
        "    c = random.uniform(0,1)\n",
        "    if c>0.5:\n",
        "        return b\n",
        "    else:\n",
        "        return -b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531be4b4",
      "metadata": {
        "id": "531be4b4"
      },
      "outputs": [],
      "source": [
        "# Their algorithm\n",
        "def constructu(eps, a,b, D):\n",
        "    # global u\n",
        "    # global l\n",
        "    # global weight\n",
        "    #[a,b] denotes range\n",
        "    n = len(D)\n",
        "\n",
        "    #index: rank of ordered discretized data\n",
        "    u = np.zeros(n+2)#utility score\n",
        "    l = np.zeros(n+2)#corresponding data\n",
        "    l[0] = a\n",
        "    for i in range(n+1):\n",
        "        if i<=int(n/2):\n",
        "            u[i] = -int(n/2)-1+i\n",
        "            l[i+1]= D[i]\n",
        "        #u[int(n/2+1)] = 0\n",
        "        #l[int(n/2+2)] = D[int(n/2)]\n",
        "        if i>int(n/2):\n",
        "            u[i] = int(n/2)+1-i\n",
        "            l[i]= D[i-1]\n",
        "\n",
        "    l[n+1] = b\n",
        "    u[n+1] = -n-1-u[0]\n",
        "    weight = []\n",
        "    for i in range(int(n/2)+1):\n",
        "        weight.append((l[i+1]-l[i])*math.pow(np.e, eps*u[i]/2))\n",
        "    weight.append(1)\n",
        "    for i in range(int(n/2)+1,n+1):\n",
        "        weight.append((l[i]-l[i-1])*math.pow(np.e, eps*u[i]/2))\n",
        "    # print(\"their weight len\",len(weight))\n",
        "\n",
        "    # worksheet.append_row(weight)\n",
        "    totalWeight = sum(weight)\n",
        "    weight = weight/totalWeight\n",
        "    df['Their weights'] = weight\n",
        "    df[\"Their u\"] = list(u)\n",
        "    return u, l, weight\n",
        "\n",
        "def EMMedian_new(l,weight):\n",
        "    i = np.random.choice(list(range(len(l))), p=weight)\n",
        "    # only return int\n",
        "    if i==int(n/2)+1:\n",
        "        return int(l[i]/n)\n",
        "    if i<int(n/2)+1:\n",
        "        return int(np.random.randint(l[i], l[i+1],dtype=np.int64) / n)\n",
        "    if i>int(n/2)+1:\n",
        "        return int(np.random.randint(l[i-1], l[i],dtype=np.int64) / n)\n",
        "\n",
        "def constructu_CI(eps, beta, N, u, l):\n",
        "    # global u1\n",
        "    # global weight1\n",
        "    # global u2\n",
        "    # global weight2\n",
        "    # global factor\n",
        "\n",
        "    factor = int(8/eps*np.log(4*n*N/beta))\n",
        "    print(\"factor is \"+str(factor))\n",
        "    #u1: left util\n",
        "    #u2: right util\n",
        "    u1 = np.zeros(n+2)\n",
        "    u2 = np.zeros(n+2)\n",
        "    for i in range(n+2):\n",
        "        if i<=int(n/2)+1:\n",
        "            u1[i] = -abs(u[i]+factor)\n",
        "            u2[i] = u[i]-factor\n",
        "        else:\n",
        "            u1[i] = u[i]-factor\n",
        "            u2[i] = -abs(u[i]+factor)\n",
        "\n",
        "    idx = int(n/2)+1-factor\n",
        "    weight1 = []\n",
        "    for i in range(idx):\n",
        "        weight1.append((l[i+1]-l[i])*math.pow(np.e, eps*u1[i]/4))\n",
        "    weight1.append(1)\n",
        "    for i in range(idx,n+1):\n",
        "        weight1.append((l[i]-l[i-1])*math.pow(np.e, eps*u1[i]/4))\n",
        "\n",
        "    totalWeight1 = sum(weight1)\n",
        "    weight1 = weight1/totalWeight1\n",
        "\n",
        "    idx = int(n/2)+1+factor\n",
        "    weight2 = []\n",
        "    for i in range(idx):\n",
        "        weight2.append((l[i+1]-l[i])*math.pow(np.e, eps*u2[i]/4))\n",
        "    weight2.append(1)\n",
        "    for i in range(idx,n+1):\n",
        "        weight2.append((l[i]-l[i-1])*math.pow(np.e, eps*u2[i]/4))\n",
        "\n",
        "    totalWeight2 = sum(weight2)\n",
        "    weight2 = weight2/totalWeight2\n",
        "    return u1,weight1,u2,weight2,factor\n",
        "\n",
        "def EMMedianCI(l,weight,weight1, weight2,factor):\n",
        "    i1 = np.random.choice(list(range(len(l))), p=weight1)\n",
        "    if i1==int(n/2)+1-factor:\n",
        "        x1= int(l[i1]/n)\n",
        "    if i1<int(n/2)+1-factor:\n",
        "        x1= int(np.random.randint(l[i1], l[i1+1],dtype=np.int64)/n)\n",
        "    if i1>int(n/2)+1-factor:\n",
        "        x1= int(np.random.randint(l[i1-1], l[i1],dtype=np.int64)/n)\n",
        "\n",
        "    i2 = np.random.choice(list(range(len(l))), p=weight2)\n",
        "    if i2==int(n/2)+1+factor:\n",
        "        x2= int(l[i2]/n)\n",
        "    if i2<int(n/2)+1+factor:\n",
        "        x2= int(np.random.randint(l[i2], l[i2+1],dtype=np.int64)/n)\n",
        "    if i2>int(n/2)+1+factor:\n",
        "        x2= int(np.random.randint(l[i2-1], l[i2],dtype=np.int64)/n)\n",
        "\n",
        "    est = EMMedian_new(l,weight)\n",
        "    indicator=0\n",
        "    if D[int(n/2)]<=x2 and D[int(n/2)]>=x1:\n",
        "        indicator=1\n",
        "\n",
        "    return x1,x2 ,indicator,est"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eps = []\n",
        "beta = []\n",
        "D = []\n",
        "newD = []\n",
        "domain_size = 4000\n",
        "num_repeat = 100\n",
        "b_list_step = 1\n"
      ],
      "metadata": {
        "id": "iYqaj0NLo-tw"
      },
      "id": "iYqaj0NLo-tw",
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "id": "5cdd1c06",
      "metadata": {
        "id": "5cdd1c06"
      },
      "outputs": [],
      "source": [
        "# November 22nd / November 29th\n",
        "#1) Learn noisy median o of distribution using Exponential Mechanism\n",
        "def EM_median(eps,beta,D,domain_size):\n",
        "    #print(\"Results for EM, beta = \"+str(beta) + \", epsilon = \" + str(eps))\n",
        "    interval_prob = []\n",
        "    vals, counts = np.unique(D,return_counts=True)\n",
        "    # for i in range(len(counts)):\n",
        "    #   if (counts[i] != 1): print(\"!=1:\",vals[i],counts[i])\n",
        "    rank = 0\n",
        "    vals = [0.0] + vals.tolist()\n",
        "    cdf = 0.0\n",
        "    rank_dict = {}\n",
        "    weights = []\n",
        "    u = []\n",
        "    n = len(D)\n",
        "    for i in range(1,len(vals)):\n",
        "        rank += counts[i-1]\n",
        "        rank_dict[vals[i]] = rank\n",
        "        utility = -1.0* np.abs(rank - (n/2))\n",
        "        u.append(utility)\n",
        "        p = (vals[i] - vals[i-1])* math.pow(np.e, eps*utility/2) # new?\n",
        "        cdf += p\n",
        "        weights.append(p)\n",
        "        interval_prob.append(cdf)\n",
        "\n",
        "    # print(\"our weight len\",len(weight))\n",
        "    rand_val = cdf * np.random.uniform(0,1)\n",
        "    rank_o = 0\n",
        "    # weights = [w/sum(weights) for w in weights]\n",
        "    # df['Our weights'] = weights+[0,0]\n",
        "    # df[\"Our u\"] = u+[0,0]\n",
        "    # print(\"our weight:\",weight[int(n/2-10):int(n/2+10)])\n",
        "    # worksheet.append_row(weight[n/2-10:n/2+50])\n",
        "    for i in range(1,len(vals)):\n",
        "        if rand_val <= interval_prob[i]:\n",
        "            sens = 1\n",
        "            ci = (2 * sens / eps) * (np.log(domain_size / beta))\n",
        "            # o = np.random.uniform(vals[i-1],vals[i])\n",
        "            o = int(np.random.randint(vals[i], vals[i+1],dtype=np.int64))\n",
        "            # print(\"i:\", i, \"vals[i-1]:\", vals[i-1],\"vals[i]:\",vals[i])\n",
        "            rank_o = rank_dict[vals[i-1]]\n",
        "            #print(\"median rank: %d out of %d\" %(rank_dict[vals[i-1]],len(vals)) )\n",
        "            #print(\"range for median rank: (%f,%f)\" %(vals[i-1],vals[i]))\n",
        "            #print(\"sampled median value: (%f)\" % (o)) #need to convert from rank to true value\n",
        "            #print(\"size of confidence interval: %f\" %(ci)) # for rank\n",
        "            break\n",
        "    return o,rank_o,rank_dict\n",
        "\n",
        "#2)\n",
        "def find_rank(rank_dict,val):\n",
        "    ranks = list(rank_dict.values())\n",
        "    keys = list(rank_dict.keys())\n",
        "    output = 0\n",
        "    for i in range(len(ranks)-1):\n",
        "        if val < keys[i+1]:\n",
        "            output = ranks[i]\n",
        "            break\n",
        "    #print(rank_dict[output])\n",
        "    return output#int(output)\n",
        "\n",
        "\n",
        "def SVT_median(o,rank_o,rank_dict,eps,beta,D,domain_size,T,b_list):\n",
        "    #print(\"T: \", T)\n",
        "    noisy_T = T + np.random.laplace(2/eps)\n",
        "    sensitivity = 1\n",
        "    bounds = domain_size\n",
        "\n",
        "    for b in b_list: #range(0,b_max,step):\n",
        "        perturbed_value = min(abs(find_rank(rank_dict, o+b)-rank_o),abs(find_rank(rank_dict, o-b)-rank_o)) + np.random.laplace(2*sensitivity/eps)\n",
        "        if perturbed_value > noisy_T:\n",
        "            bounds = b\n",
        "            break\n",
        "    #print(max(o-bounds,0))\n",
        "    #print(min(o+bounds,domain_size-1))\n",
        "    # print(perturbed_value)\n",
        "    result = max(o-bounds,0),min(o+bounds,domain_size-1)\n",
        "    return result\n",
        "\n",
        "##### main function ######\n",
        "\n",
        "def our_CI(D,domain_size,b_list):\n",
        "    C = (2/eps_1) *(np.log(domain_size/beta_1))\n",
        "    alpha = (8*np.log(m)+np.log(2/beta_2)) / eps_2\n",
        "    #print(\"C\", C)\n",
        "    #print(\"alpha\", alpha)\n",
        "    T = C + alpha\n",
        "\n",
        "    o,rank_o,rank_dict = EM_median(eps_1,beta_1,D,domain_size)\n",
        "    # lower,upper = SVT_median(o,rank_o,rank_dict,eps_2,beta_1,D,domain_size,T,b_list)\n",
        "    lower,upper = SVT_median(o,rank_o,rank_dict,eps_2,beta_1,D,domain_size,T,b_list)\n",
        "    #print(\"median:\",o)\n",
        "    #print(\"The bounds are:\")\n",
        "    #print('[{},{}]'.format(lower,upper))\n",
        "    indi = -1 #if CI contains true med\n",
        "    if (use_discretized == 1):\n",
        "      lower,upper = lower/n,upper/n\n",
        "      o /= n\n",
        "    if true_med < upper and true_med > lower:\n",
        "        indi = 1\n",
        "    else:\n",
        "        indi = 0\n",
        "\n",
        "    return lower,upper,indi,o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "id": "c742116c",
      "metadata": {
        "id": "c742116c"
      },
      "outputs": [],
      "source": [
        "def test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,compare = False):\n",
        "  domain_size = int(max(D)-min(D))\n",
        "  if (use_discretized == 1):\n",
        "    b_list = range(0, domain_size, b_list_step*n)\n",
        "  else:\n",
        "    b_list = range(0, domain_size, b_list_step)\n",
        "\n",
        "  len_eps = []\n",
        "  err_eps = []\n",
        "  est_median = []\n",
        "  times = []\n",
        "  ranks = []\n",
        "  lengths = []\n",
        "  errors = []\n",
        "  rank_errors_1 = [] # based on n/2\n",
        "  rank_errors_2 = [] # based on find_rank(rank_dict,true_med)\n",
        "  # est_list = []\n",
        "  med_rank = int(find_rank(rank_dict, true_med))\n",
        "  for i in range(len(beta)):\n",
        "      print(\"Results for EM based median, beta = \"+str(beta[i]))\n",
        "      correct_count = 0\n",
        "\n",
        "      for j in range(num_repeat):\n",
        "          start = time.time()\n",
        "          xl,xr,indi,est = our_CI(D,domain_size,b_list)#EMMedianCI()\n",
        "\n",
        "          end = time.time()\n",
        "          times.append(end-start)\n",
        "          correct_count+=indi\n",
        "          lengths.append((xr-xl)/(2))\n",
        "\n",
        "          # interesting and subtle difference!\n",
        "          # mid_value = (xr+xl)/2\n",
        "          errors.append(abs(est-true_med))\n",
        "          est_median.append(est)\n",
        "          rank = int(find_rank(rank_dict, est))\n",
        "          ranks.append(rank)\n",
        "          rank_errors_1.append(int(abs(n/2 - rank)))\n",
        "          rank_errors_2.append(int(abs(med_rank - rank)))\n",
        "      original_errors = errors\n",
        "      errors = np.array(errors, dtype=object)\n",
        "      correct_rate = correct_count/num_repeat\n",
        "      avgLength = sum(lengths)/num_repeat\n",
        "      errors.sort()\n",
        "      errorQuantile = errors[int(num_repeat*(1-beta[i]))]\n",
        "      avg_error = np.average(errors)\n",
        "      avgTime = sum(times)/len(times)\n",
        "\n",
        "\n",
        "      # output medians and error\n",
        "\n",
        "      #download errors\n",
        "      # df = pd.DataFrame(errors)\n",
        "      # file_name = f\"data_error.csv\"\n",
        "      # df.to_csv(file_name, index=False, header=False)\n",
        "      # files.download(file_name)\n",
        "\n",
        "      # median_error\n",
        "      if np.all(errors == errors[0]):\n",
        "          stddev_based_avg_err = errors[0]\n",
        "          IQR_based_avg_err = errors[0]\n",
        "      else:\n",
        "          std_dev = np.std(errors)\n",
        "          stddev_based_avg_err = np.average(errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "          q1 = np.percentile(errors, 25)\n",
        "          q3 = np.percentile(errors, 75)\n",
        "          iqr = q3 - q1\n",
        "          lower_bound = q1 - 1.5 * iqr\n",
        "          upper_bound = q3 + 1.5 * iqr\n",
        "          IQR_based_avg_err = np.average(errors[(errors >= lower_bound) & (errors <= upper_bound)])\n",
        "      # rank_error\n",
        "      avg_rank_error_1 = np.average(rank_errors_1)\n",
        "      avg_rank_error_2 = np.average(rank_errors_2)\n",
        "      print(\"estimated median value: \"+ str(np.average(est_median)))\n",
        "      print(\"correct rate = \", correct_rate)\n",
        "      print(\"Average CI length = \"+str(avgLength))\n",
        "      print(\"error quantile is \"+ str(errorQuantile))\n",
        "      print(\"CI length/ error quantile = \"+str(avgLength/errorQuantile))\n",
        "      print(\"Average Time to find CI = \" + str(avgTime))\n",
        "\n",
        "      name = \"our_CI\"\n",
        "      if (use_discretized == 1):\n",
        "        name = \"our_CI(discretized)\"\n",
        "        domain_size = domain_size/n\n",
        "      if (errorQuantile == 0): relative_CI_width = -1\n",
        "      else: relative_CI_width = avgLength / errorQuantile\n",
        "      if (output_mode == 0 or output_mode == 2):\n",
        "        row_data = [\n",
        "            name,\n",
        "            data_uuid,\n",
        "            n,\n",
        "            domain_size, #new\n",
        "            sens,\n",
        "            beta[i],\n",
        "            eps[i],\n",
        "            num_repeat,\n",
        "            true_med,\n",
        "            np.average(est_median),\n",
        "            correct_rate,\n",
        "            avgLength,\n",
        "            errorQuantile,\n",
        "            avg_error,\n",
        "            stddev_based_avg_err,\n",
        "            IQR_based_avg_err,\n",
        "            avg_rank_error_1,\n",
        "            avg_rank_error_2,\n",
        "            relative_CI_width,\n",
        "            avgTime,\n",
        "            b_list_step,\n",
        "            beta_1,\n",
        "            beta_2,\n",
        "            eps_1,\n",
        "            eps_2\n",
        "        ]\n",
        "        write_to_sheet(worksheet1, row_data, output_mode=output_mode, compare=compare)\n",
        "\n",
        "      # New! Check all medians and errors\n",
        "      if (output_mode == 1 or output_mode == 2):\n",
        "        sorted_med = sorted(est_median)\n",
        "        est_median.insert(0, \"Our est_median\")\n",
        "        sorted_med.insert(0, \"Sorted Our est_median\")\n",
        "\n",
        "        sorted_errors = sorted(original_errors)\n",
        "        original_errors.insert(0, \"Our errors\")\n",
        "        sorted_errors.insert(0, \"Sorted Our errors\")\n",
        "\n",
        "        sorted_ranks = sorted(ranks)\n",
        "        ranks.insert(0, \"Our ranks\")\n",
        "        sorted_ranks.insert(0, \"Sorted Our ranks\")\n",
        "\n",
        "        sorted_lengths = sorted(lengths)\n",
        "        lengths.insert(0,\"Our CI lengths\")\n",
        "        sorted_lengths.insert (0, \"Sorted Our CI lengths\")\n",
        "\n",
        "        sorted_re_1 = sorted(rank_errors_1)\n",
        "        sorted_re_2 = sorted(rank_errors_2)\n",
        "        rank_errors_1.insert(0, \"Our rank_errors(n/2)\")\n",
        "        rank_errors_2.insert(0, \"Our rank_errors(find)\")\n",
        "        sorted_re_1.insert(0, \"Sorted Our rank_errors(n/2)\")\n",
        "        sorted_re_2.insert(0, \"Sorted Our rank_errors(find)\")\n",
        "\n",
        "\n",
        "        data_uid_row = [\"data:\", data_uuid, \"method:\", \"Our_CI\"]\n",
        "        true_med_row = [\"true median\"]+[true_med]*num_repeat\n",
        "        n_over_2_row = [\"true n/2\"] + [n/2]*num_repeat\n",
        "        med_rank_row = [\"true med_rank(find)\"] + [med_rank]*num_repeat\n",
        "\n",
        "        worksheet.append_row(data_uid_row)\n",
        "        worksheet.append_row(est_median)\n",
        "        worksheet.append_row(true_med_row)\n",
        "        worksheet.append_row(original_errors)\n",
        "        # write_to_sheet(worksheet1, errors, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(ranks)\n",
        "        worksheet.append_row(n_over_2_row)\n",
        "        worksheet.append_row(rank_errors_1)\n",
        "        # write_to_sheet(worksheet1, rank_errors_1, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(med_rank_row)\n",
        "        worksheet.append_row(rank_errors_2)\n",
        "        worksheet.append_row(lengths)\n",
        "\n",
        "        # write_to_sheet(worksheet1, rank_errors_2, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(sorted_med)\n",
        "        worksheet.append_row(sorted_ranks)\n",
        "        worksheet.append_row(sorted_errors)\n",
        "        worksheet.append_row(sorted_re_1)\n",
        "        worksheet.append_row(sorted_re_2)\n",
        "        worksheet.append_row(sorted_lengths)\n",
        "\n",
        "      len_eps.append(avgLength)\n",
        "      err_eps.append(errorQuantile)\n",
        "  print(len_eps)\n",
        "  print(err_eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "490b3cbd",
      "metadata": {
        "id": "490b3cbd"
      },
      "outputs": [],
      "source": [
        "def test_theirs(eps=eps, beta=beta, num_repeat=num_repeat, D=newD,median_method = 0,compare = False):\n",
        "  #median_method = 0:median from CI algorithm\n",
        "  #        = 1:median from EMMedianCI\n",
        "  len_eps = []\n",
        "  err_eps = []\n",
        "  est_median = []\n",
        "  times = []\n",
        "  ranks = []\n",
        "  EM_median_errors = []\n",
        "  med_rank = int(find_rank(rank_dict, true_med))\n",
        "  est_list = []\n",
        "  rank_errors_1 = [] # based on n/2\n",
        "  rank_errors_2 = [] # based on find_rank(rank_dict,true_med)\n",
        "  for i in range(len(beta)):\n",
        "      print(\"Results for EM based median, beta = \"+str(beta[i]))\n",
        "      errors = []\n",
        "      lengths = []\n",
        "      correct_count = 0\n",
        "      n = len(newD)\n",
        "      rad = 10000000\n",
        "      left=-rad\n",
        "      u,l,weight = constructu(eps[i], left*n,rad*n, newD)\n",
        "\n",
        "      u1,weight1,u2,weight2,factor = constructu_CI(eps[i],beta[i], rad,u,l)\n",
        "      for j in range(num_repeat):\n",
        "          start = time.time()\n",
        "          xl,xr,indi,est = EMMedianCI(l,weight,weight1,weight2,factor)\n",
        "          end = time.time()\n",
        "          times.append(end-start)\n",
        "          correct_count+=indi\n",
        "          lengths.append((xr-xl)/(2))\n",
        "          if (median_method == 0):\n",
        "            their_median = (xr+xl)/2\n",
        "          else:\n",
        "            their_median = est\n",
        "          est_median.append(their_median)\n",
        "          errors.append(abs(their_median-true_med))\n",
        "          EM_median_errors.append(abs(est-true_med)) # their def of errors\n",
        "          rank = int(find_rank(rank_dict, their_median))\n",
        "          ranks.append(rank)\n",
        "          rank_errors_1.append(int(abs(n/2 - rank)))\n",
        "          rank_errors_2.append(int(abs(med_rank - rank)))\n",
        "\n",
        "      original_errors = errors\n",
        "      errors = np.array(errors, dtype=object)\n",
        "      correct_rate = correct_count/num_repeat\n",
        "      avgLength = sum(lengths)/num_repeat\n",
        "      errors.sort()\n",
        "      errorQuantile = errors[int(num_repeat*(1-beta[i]))]\n",
        "\n",
        "      avgTime = sum(times)/len(times)\n",
        "\n",
        "\n",
        "      errors = np.array(errors)\n",
        "      avg_error = np.average(errors)\n",
        "      if np.all(errors == errors[0]):\n",
        "          stddev_based_avg_err = errors[0]\n",
        "          IQR_based_avg_err = errors[0]\n",
        "      else:\n",
        "          std_dev = np.std(errors)\n",
        "          stddev_based_avg_err = np.average(errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "\n",
        "          q1 = np.percentile(errors, 25)\n",
        "          q3 = np.percentile(errors, 75)\n",
        "          iqr = q3 - q1\n",
        "          lower_bound = q1 - 1.5 * iqr\n",
        "          upper_bound = q3 + 1.5 * iqr\n",
        "          IQR_based_avg_err = np.average(errors[(errors >= lower_bound) & (errors <= upper_bound)])\n",
        "\n",
        "      #rank_avg\n",
        "      avg_rank_error_1 = np.average(rank_errors_1)\n",
        "      avg_rank_error_2 = np.average(rank_errors_2)\n",
        "      print(\"Filtered Errors for IQR_based_avg_err:\", IQR_based_avg_err)\n",
        "\n",
        "      print(\"estimated median value: \"+ str(np.average(est_median)))\n",
        "      print(\"correct rate = \" +str(correct_count/num_repeat))\n",
        "      print(\"Average CI length = \"+str(avgLength))\n",
        "      print(\"error quantile is \"+ str(errorQuantile))\n",
        "      print(\"CI length/ error quantile = \"+str(avgLength/errorQuantile))\n",
        "      print(\"Average Time to find CI = \" + str(sum(times)/len(times)))\n",
        "      # print(\"Errors:\", errors)\n",
        "      # print(\"Standard Deviation:\", std_dev)\n",
        "      # print(\"Filtered Errors for stddev_based_avg_err:\", errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "\n",
        "      # print(\"Q1:\", q1, \"Q3:\", q3)\n",
        "      # print(\"IQR:\", iqr)\n",
        "      # print(\"Lower Bound:\", lower_bound, \"Upper Bound:\", upper_bound)\n",
        "      if (median_method == 0):\n",
        "        name = \"EM_CI\"\n",
        "      else:\n",
        "        name = \"EM\"\n",
        "\n",
        "      if (output_mode == 0 or output_mode == 2):\n",
        "        row_data = [\n",
        "            name,\n",
        "            data_uuid,\n",
        "            n,\n",
        "            domain_size,\n",
        "            sens,\n",
        "            beta[i],\n",
        "            eps[i],\n",
        "            num_repeat,\n",
        "            true_med,\n",
        "            np.average(est_median),\n",
        "            correct_rate,\n",
        "            avgLength,\n",
        "            errorQuantile,\n",
        "            avg_error,\n",
        "            stddev_based_avg_err,\n",
        "            IQR_based_avg_err,\n",
        "            avg_rank_error_1,\n",
        "            avg_rank_error_2,\n",
        "            avgLength / errorQuantile,\n",
        "            avgTime\n",
        "        ]\n",
        "        write_to_sheet(worksheet1, row_data, compare = compare)\n",
        "\n",
        "      if (output_mode == 1 or output_mode == 2):\n",
        "        sorted_med = sorted(est_median)\n",
        "        est_median.insert(0, \"EM est_median\")\n",
        "        sorted_med.insert(0, \"Sorted EM est_median\")\n",
        "\n",
        "        sorted_errors = sorted(original_errors)\n",
        "        original_errors.insert(0, \"EM errors\")\n",
        "        sorted_errors.insert(0, \"Sorted EM errors\")\n",
        "\n",
        "        sorted_ranks = sorted(ranks)\n",
        "        ranks.insert(0, \"EM ranks\")\n",
        "        sorted_ranks.insert(0, \"Sorted EM ranks\")\n",
        "\n",
        "        sorted_re_1 = sorted(rank_errors_1)\n",
        "        sorted_re_2 = sorted(rank_errors_2)\n",
        "        rank_errors_1.insert(0, \"EM rank_errors(n/2)\")\n",
        "        rank_errors_2.insert(0, \"EM rank_errors(find)\")\n",
        "        sorted_re_1.insert(0, \"Sorted EM rank_errors(n/2)\")\n",
        "        sorted_re_2.insert(0, \"Sorted EM rank_errors(find)\")\n",
        "\n",
        "        sorted_lengths = sorted(lengths)\n",
        "        lengths.insert(0,\"EM CI lengths\")\n",
        "        sorted_lengths.insert (0, \"Sorted EM CI lengths\")\n",
        "\n",
        "        data_uid_row = [\"data:\", data_uuid, \"method:\", \"EM_CI\"]\n",
        "        true_med_row = [\"true median\"]+[true_med]*num_repeat\n",
        "        n_over_2_row = [\"true n/2\"] + [n/2]*num_repeat\n",
        "        med_rank_row = [\"true med_rank(find)\"] + [med_rank]*num_repeat\n",
        "\n",
        "        print(est_list)\n",
        "        worksheet.append_row(data_uid_row)\n",
        "        worksheet.append_row(est_median)\n",
        "        worksheet.append_row(true_med_row)\n",
        "\n",
        "        worksheet.append_row(original_errors)\n",
        "        # write_to_sheet(worksheet1, original_errors, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(ranks)\n",
        "        worksheet.append_row(n_over_2_row)\n",
        "        worksheet.append_row(rank_errors_1)\n",
        "        # write_to_sheet(worksheet1, rank_errors_1, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(med_rank_row)\n",
        "        worksheet.append_row(rank_errors_2)\n",
        "        worksheet.append_row(lengths)\n",
        "        # write_to_sheet(worksheet1, rank_errors_2, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(sorted_med)\n",
        "        worksheet.append_row(sorted_ranks)\n",
        "        worksheet.append_row(sorted_errors)\n",
        "        worksheet.append_row(sorted_re_1)\n",
        "        worksheet.append_row(sorted_re_2)\n",
        "        worksheet.append_row(sorted_lengths)\n",
        "\n",
        "\n",
        "\n",
        "      len_eps.append(avgLength)\n",
        "      err_eps.append(errorQuantile)\n",
        "  print(len_eps)\n",
        "  print(err_eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "-xoDZUe5Or-N",
      "metadata": {
        "id": "-xoDZUe5Or-N"
      },
      "outputs": [],
      "source": [
        "def readInput(mode):\n",
        "    import numpy as np\n",
        "    read_data_uuid = \"64b7c8bf89f14113bd12f5f15e276546\"\n",
        "    file_paths = {\n",
        "        0: (\"./bank_marketing.csv\", 5),\n",
        "        1: (\"./adult.csv\", 2),\n",
        "        2: (\"./sample_data/california_housing_test.csv\", 3),\n",
        "        3: (\"./sample_data/california_housing_test.csv\", 8),\n",
        "        10: (\"./data_\"+read_data_uuid+\".csv\",0),\n",
        "    }\n",
        "\n",
        "    if mode not in file_paths:\n",
        "        raise ValueError(\"Invalid mode. Choose between 0 to 3\")\n",
        "\n",
        "    input_path, column_index = file_paths[mode]\n",
        "\n",
        "    with open(input_path, 'r') as input_file:\n",
        "        lines = input_file.readlines()\n",
        "    n = len(lines)\n",
        "    D = np.zeros(n)\n",
        "    for i, line in enumerate(lines):\n",
        "        if i > 0:\n",
        "            elements = line.split(\",\")\n",
        "            try:\n",
        "                value = float(elements[column_index])\n",
        "                D[i - 1] = int(value)\n",
        "            except ValueError:\n",
        "                print(f\"Skipping invalid data at line {i}: {elements[column_index]}\")\n",
        "    return D\n",
        "\n",
        "def normalize_non_negative(D):\n",
        "  if lowest<0:\n",
        "    D = [d-lowest for d in D]\n",
        "  return D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "id": "kTEhx4k8KNoQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTEhx4k8KNoQ",
        "outputId": "e247f41e-f283-4063-c5a8-18142c973a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lowest: 0\n",
            "[226802.  89814. 336951. ... 201490. 287927.      0.]\n",
            "Data_size: 48843\n",
            "Domain size: 1490400\n",
            "true median:  178142.0\n",
            "true median rank: 24421.5\n"
          ]
        }
      ],
      "source": [
        "# Experiment Data Input\n",
        "\n",
        "dataset_id_dict = {0:\"bank_marketing\", 1:\"adult\", 2:\"cali_housing_test\", 3:\"cali_housing_value\",\n",
        "                   10: \"old_synthetic_data\"}\n",
        "mode = 1\n",
        "\n",
        "if (mode == -1):\n",
        "  n = 4000  # 45#000\n",
        "  domain_size = 4000  # 40#000\n",
        "  D = np.random.uniform(0, domain_size, n)\n",
        "  lowest = 0\n",
        "  highest = domain_size\n",
        "else:\n",
        "  D = readInput(mode)\n",
        "  n = len(D)\n",
        "  lowest = int(min(D))\n",
        "  #elinminate negative numbers\n",
        "  # if (lowest < 0):\n",
        "  #   D = normalize_non_negative(D)\n",
        "  #   lowest = 0\n",
        "  highest = int(max(D))\n",
        "  print(\"lowest:\",lowest)\n",
        "\n",
        "\n",
        "domain_size = highest - lowest\n",
        "print(D)\n",
        "\n",
        "D.sort()\n",
        "D = discretize(D, 1)\n",
        "newD = discrete(D)\n",
        "true_med = np.median(D)\n",
        "\n",
        "print(\"Data_size:\", n)\n",
        "print(\"Domain size:\", domain_size)\n",
        "\n",
        "print(\"true median: \", true_med)\n",
        "\n",
        "# rank_dict\n",
        "vals, counts = np.unique(D,return_counts=True)\n",
        "rank_dict = {}\n",
        "rank = 0\n",
        "vals = [0.0] + vals.tolist()\n",
        "for i in range(1,len(vals)):\n",
        "    rank += counts[i-1]\n",
        "    rank_dict[vals[i]] = rank\n",
        "print(\"true median rank:\",n/2)\n",
        "\n",
        "\n",
        "\n",
        "# Data Persistence\n",
        "if (mode == -1):\n",
        "  df = pd.DataFrame(D)\n",
        "  data_uuid = uuid.uuid4().hex\n",
        "  file_name = f\"data_{data_uuid}.csv\"\n",
        "  df.to_csv(file_name, index=False, header=False)\n",
        "  files.download(file_name)\n",
        "  print(f\"File saved as {file_name}\")\n",
        "else:\n",
        "  data_uuid = dataset_id_dict[mode]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "G-o_F3TWSUzN",
      "metadata": {
        "id": "G-o_F3TWSUzN"
      },
      "outputs": [],
      "source": [
        "# CI Parameters\n",
        "eps = [1]\n",
        "beta = [0.01]\n",
        "sens = 1 #fixed\n",
        "num_repeat=100\n",
        "use_discretized = 0\n",
        "# for val, rank in rank_dict.items():\n",
        "#     print(val,\"  \",rank)\n",
        "\n",
        "# Parameters for our_CI\n",
        "beta_1 = 0.5 *beta[0]\n",
        "beta_2 = beta[0] - beta_1\n",
        "# eps_1 = 0.5 * eps[0]\n",
        "# eps_2 = eps[0] - eps_1\n",
        "eps_1 = 0.5 * eps[0]\n",
        "eps_2 = eps[0] - eps_1\n",
        "\n",
        "\n",
        "b_list_step = 1\n",
        "if mode == 1: b_list_step = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "ZZKk-CjfKeLU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZKk-CjfKeLU",
        "outputId": "d167adac-b648-48bf-cb8c-90eb3e6040c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for EM based median, beta = 0.01\n",
            "factor is 263\n",
            "Filtered Errors for IQR_based_avg_err: 22.98\n",
            "estimated median value: 178161.74\n",
            "correct rate = 1.0\n",
            "Average CI length = 1096.48\n",
            "error quantile is 100.0\n",
            "CI length/ error quantile = 10.9648\n",
            "Average Time to find CI = 0.01236788511276245\n",
            "[1096.48]\n",
            "[100.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 263\n",
            "Filtered Errors for IQR_based_avg_err: 167.73979591836735\n",
            "estimated median value: 178308.145\n",
            "correct rate = 1.0\n",
            "Average CI length = 1091.675\n",
            "error quantile is 212.0\n",
            "CI length/ error quantile = 5.149410377358491\n",
            "Average Time to find CI = 0.012351915836334229\n",
            "[1091.675]\n",
            "[212.0]\n",
            "-------------------First Test Done--------------------\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 178158.42\n",
            "correct rate =  1.0\n",
            "Average CI length = 1322.0\n",
            "error quantile is 135.0\n",
            "CI length/ error quantile = 9.792592592592593\n",
            "Average Time to find CI = 0.29604387760162354\n",
            "[1322.0]\n",
            "[135.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 178161.55706099138\n",
            "correct rate =  1.0\n",
            "Average CI length = 1440.5\n",
            "error quantile is 106.37952214237885\n",
            "CI length/ error quantile = 13.54113997684656\n",
            "Average Time to find CI = 0.5345641684532165\n",
            "[1440.5]\n",
            "[106.37952214237885]\n"
          ]
        }
      ],
      "source": [
        "# Test both\n",
        "\n",
        "# output_mode 0:experiment results,\n",
        "#        1:medians&ranks, CI legnths\n",
        "#        2:both\n",
        "\n",
        "# EM_mode  0: use our original EM\n",
        "#       1: use our original EM with discretized data\n",
        "#       2: use their EM with discretized data\n",
        "\n",
        "output_mode = 0\n",
        "download = 0\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df[\"rank\"] = list(range(1,len(D)+1)) + [0,0]\n",
        "df[\"data\"] = list(D)+ [0,0]\n",
        "df[\"discretized_data\"] = list(newD) + [0,0]\n",
        "test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=1,D=newD)\n",
        "test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=0,D=newD)\n",
        "\n",
        "print(\"-------------------EMCI Test Done--------------------\")\n",
        "\n",
        "if output_mode==2:\n",
        "  print(\"wait for 60 secs for the Second Test\")\n",
        "  time.sleep(60)\n",
        "\n",
        "use_discretized = 0\n",
        "test_ours(eps=eps, beta=beta, num_repeat=num_repeat,D=D,compare = True)\n",
        "\n",
        "use_discretized = 1\n",
        "test_ours(eps=eps, beta=beta, num_repeat=num_repeat,D=newD,compare = True)\n",
        "print(\"-------------------ourCI Test Done--------------------\")\n",
        "\n",
        "\n",
        "# Result Persistence\n",
        "csv_name = \"weight\"+data_uuid\n",
        "df.to_csv(csv_name+\".csv\",index=False)\n",
        "if (download == 1):\n",
        "  files.download(csv_name+\".csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72FYc7UozH2c",
      "metadata": {
        "id": "72FYc7UozH2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "29a9903a-8ce7-4592-88b8-584978d4b3c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running for beta=[0.01]\n",
            "[]\n",
            "[]\n",
            "beta=[0.01] done\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-c32b42251c2b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# test_ours()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"beta={beta} done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# # Test different beta\n",
        "# eps = [1]\n",
        "# eps_1 = 0.5 * eps[0]\n",
        "# eps_2 = eps[0] - eps_1\n",
        "# beta_list = [0.01,0.025,0.05,0.1,0.2]\n",
        "# for beta in beta_list:\n",
        "#   beta = [beta]\n",
        "#   beta_1 = 0.5 * beta[0]\n",
        "#   beta_2 = beta[0] - beta_1\n",
        "#   print(f\"Running for beta={beta}\")\n",
        "#   test_theirs()\n",
        "#   # test_ours()\n",
        "#   print(f\"beta={beta} done\")\n",
        "#   time.sleep(20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GfTJIPHarSAT",
      "metadata": {
        "id": "GfTJIPHarSAT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dkQZxi1QE90V"
      },
      "id": "dkQZxi1QE90V",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}