{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Timliuw/DP-Tim/blob/main/CI_Tim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd74f5f",
      "metadata": {
        "id": "cfd74f5f"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import copy\n",
        "import getopt\n",
        "import psycopg2\n",
        "import sys\n",
        "import time\n",
        "import pandas as pd\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zfatDYXyr6eo",
      "metadata": {
        "id": "zfatDYXyr6eo"
      },
      "outputs": [],
      "source": [
        "#for experiments purpose\n",
        "import gspread\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.service_account import Credentials\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "import os\n",
        "os.listdir()\n",
        "\n",
        "scope = [\n",
        "    \"https://spreadsheets.google.com/feeds\",  # Google Sheets API\n",
        "    \"https://www.googleapis.com/auth/drive\"   # Google Drive API\n",
        "]\n",
        "\n",
        "# Trigger the file upload dialog\n",
        "try:\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(\"sublime-mission-447319-c2-0df1612796a8.json\", scope)\n",
        "except:\n",
        "   uploaded = files.upload()\n",
        "\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(\"sublime-mission-447319-c2-0df1612796a8.json\", scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "spreadsheet = client.open_by_key(\"1yVVt5ACdBbjsZ_7IiRkvPGIHmpKe8mFXcvyL0PVP2cE\")\n",
        "\n",
        "worksheet1 = spreadsheet.get_worksheet(0)\n",
        "worksheet = worksheet1\n",
        "worksheet2 = spreadsheet.get_worksheet(1)\n",
        "\n",
        "def get_color(curr_value, prev_value):\n",
        "    if curr_value < 0.6 * prev_value:\n",
        "        return {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6}  # very green\n",
        "    elif curr_value < prev_value:\n",
        "        return {\"red\": 0.8, \"green\": 1.0, \"blue\": 0.8}  # green\n",
        "    elif curr_value > 1.4 * prev_value:\n",
        "        return {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6}  # very red\n",
        "    elif curr_value > prev_value:\n",
        "        return {\"red\": 1.0, \"green\": 0.8, \"blue\": 0.8}  # red\n",
        "    return None\n",
        "\n",
        "def write_to_sheet(worksheet, row_data, output_mode=0, compare=False):\n",
        "    # Append the new row to the sheet\n",
        "    try:\n",
        "        worksheet.append_row(row_data)\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        print(f\"Row data: {row_data}\")\n",
        "    # Format colour according to the comparing results\n",
        "    if compare:\n",
        "        pre_row_index = -2\n",
        "        if (output_mode == 2): pre_row_index = -18\n",
        "        sheet_data = worksheet.get_all_values()\n",
        "        last_row_index = len(sheet_data)\n",
        "        if last_row_index > 1:\n",
        "            last_row = sheet_data[-1]\n",
        "            prev_row = sheet_data[pre_row_index]\n",
        "            for col_index, (curr_value, prev_value) in enumerate(zip(last_row, prev_row), start=1):\n",
        "                try:\n",
        "                    curr_value = float(curr_value)\n",
        "                    prev_value = float(prev_value)\n",
        "                    if (worksheet.row_values(1)[col_index-1] == \"est median\"):\n",
        "                      prev_value = abs(true_med - prev_value)\n",
        "                      curr_value = abs(true_med - curr_value)\n",
        "                    color = get_color(curr_value, prev_value)\n",
        "                    if color:\n",
        "                        worksheet.format(f\"{chr(64 + col_index)}{last_row_index}\", {\"backgroundColor\": color})\n",
        "                except:\n",
        "                    continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "202456b3",
      "metadata": {
        "id": "202456b3"
      },
      "outputs": [],
      "source": [
        "def discretize(D, b):\n",
        "    n = len(D)\n",
        "    discreteD = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        discreteD[i] = int(D[i]/b)\n",
        "    return discreteD\n",
        "\n",
        "def discrete(D):\n",
        "    n = len(D)\n",
        "    newD = np.zeros(n)\n",
        "    previous = -1\n",
        "    for i in range(n):\n",
        "        if D[i]!=previous:\n",
        "            newD[i] = n*D[i]\n",
        "            #print(newD[i])\n",
        "            previous = D[i]\n",
        "        elif D[i]==previous:\n",
        "            newD[i] = newD[i-1]+1\n",
        "\n",
        "    return newD\n",
        "\n",
        "def count(D, a):\n",
        "    counter = 0\n",
        "    n = len(D)\n",
        "    low = 0\n",
        "    up=n-1\n",
        "    mid = int((low+up)/2)\n",
        "    while True:\n",
        "        if D[mid]>a:\n",
        "            up=mid\n",
        "            mid = int((low+up)/2)\n",
        "        if D[mid]<a:\n",
        "            low=mid\n",
        "            mid = int((low+up)/2)\n",
        "        if D[mid]==a:\n",
        "            i=0\n",
        "            while D[mid+i]==a:\n",
        "                i+=1\n",
        "            return mid+i\n",
        "\n",
        "def clip(D, a, b):\n",
        "    clipped = copy.deepcopy(D)\n",
        "    clipped[clipped<a] = a\n",
        "    clipped[clipped>b] = b\n",
        "    return clipped\n",
        "\n",
        "def LapNoise():\n",
        "    a = random.uniform(0,1)\n",
        "    b = math.log(1/(1-a))\n",
        "    c = random.uniform(0,1)\n",
        "    if c>0.5:\n",
        "        return b\n",
        "    else:\n",
        "        return -b\n",
        "\n",
        "def F(x):\n",
        "    return 1/2+1/(4*math.pi)*(math.log(abs(2*x**2+2*math.sqrt(2)*x+2)/abs(abs(2*x**2-2*math.sqrt(2)*x+2)))+2*math.atan(math.sqrt(2)*x+1)+2*math.atan(math.sqrt(2)*x-1))\n",
        "def inver_F(y):\n",
        "    #find the solution of F(x)=y\n",
        "    #Find between -1000000 and 1000000 because F(1000000)=1.0 in python\n",
        "    if y>1/2:\n",
        "        low =0.0\n",
        "        high = 1000000.0\n",
        "        mid = (high+low)/2\n",
        "        while abs(high-low)>0.0000001:\n",
        "            if F(mid)>y:\n",
        "                high=mid\n",
        "            elif F(mid)==y:\n",
        "                return mid\n",
        "            else:\n",
        "                low = mid\n",
        "            mid = (high+low)/2\n",
        "\n",
        "        return high\n",
        "    if y==1/2:\n",
        "        return 0\n",
        "\n",
        "def CauchyNoise():\n",
        "    a = random.uniform(0.5,1)\n",
        "    b = inver_F(a)\n",
        "    c = random.uniform(0,1)\n",
        "    if c>0.5:\n",
        "        return b\n",
        "    else:\n",
        "        return -b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531be4b4",
      "metadata": {
        "id": "531be4b4"
      },
      "outputs": [],
      "source": [
        "# Their algorithm\n",
        "def constructu(eps, a,b, D):\n",
        "    # global u\n",
        "    # global l\n",
        "    # global weight\n",
        "    #[a,b] denotes range\n",
        "    n = len(D)\n",
        "\n",
        "    u = np.zeros(n+2)#utility score\n",
        "    l = np.zeros(n+2)#corresponding data\n",
        "    l[0] = a\n",
        "    for i in range(n+1): #i=rank-1\n",
        "        if i<=int(n/2):\n",
        "            u[i] = -int(n/2)-1+i\n",
        "            l[i+1]= D[i]\n",
        "        #u[int(n/2+1)] = 0\n",
        "        #l[int(n/2+2)] = D[int(n/2)]\n",
        "        if i>int(n/2):\n",
        "            u[i] = int(n/2)+1-i\n",
        "            l[i]= D[i-1]\n",
        "\n",
        "    l[n+1] = b\n",
        "    u[n+1] = -n-1-u[0]\n",
        "    weight = []\n",
        "    # l[i] corresponds to data in D with rank i\n",
        "    for i in range(int(n/2)+1): # weight[0...n/2]\n",
        "        weight.append((l[i+1]-l[i])*math.pow(np.e, eps*u[i]/2)) #weight[i]=(l[i+1]-l[i])...\n",
        "        # if (i == int(n/2)): print(l[i+1],l[i],u[i])\n",
        "    weight.append(1) # weight[n/2+1] = 1??\n",
        "    for i in range(int(n/2)+1,n+1): #weight[n/2+2..n+1]\n",
        "        weight.append((l[i]-l[i-1])*math.pow(np.e, eps*u[i]/2)) #weight[i+1]=(l[i]-l[i-1])...\n",
        "        # if (i == int(n/2)+1): print(l[i],l[i-1],u[i])\n",
        "    # worksheet.append_row(weight)\n",
        "    totalWeight = sum(weight)\n",
        "    weight = weight/totalWeight\n",
        "    df['Their weights'] = weight\n",
        "    df[\"Their u\"] = list(u)\n",
        "    return u, l, weight\n",
        "\n",
        "def EMMedian_new(l,weight):\n",
        "    i = np.random.choice(list(range(len(l))), p=weight)\n",
        "    # only return int\n",
        "    if i==int(n/2)+1:\n",
        "        return int(l[i]/n)\n",
        "    if i<int(n/2)+1:\n",
        "        return int(np.random.randint(l[i], l[i+1],dtype=np.int64) / n)\n",
        "    if i>int(n/2)+1:\n",
        "        return int(np.random.randint(l[i-1], l[i],dtype=np.int64) / n)\n",
        "\n",
        "def constructu_CI(eps, beta, N, u, l):\n",
        "    # global u1\n",
        "    # global weight1\n",
        "    # global u2\n",
        "    # global weight2\n",
        "    # global factor\n",
        "\n",
        "    factor = int(8/eps*np.log(4*n*N/beta))\n",
        "    print(\"factor is \"+str(factor))\n",
        "    #u1: left util\n",
        "    #u2: right util\n",
        "    u1 = np.zeros(n+2)\n",
        "    u2 = np.zeros(n+2)\n",
        "    for i in range(n+2):\n",
        "        if i<=int(n/2)+1:\n",
        "            u1[i] = -abs(u[i]+factor)\n",
        "            u2[i] = u[i]-factor\n",
        "        else:\n",
        "            u1[i] = u[i]-factor\n",
        "            u2[i] = -abs(u[i]+factor)\n",
        "\n",
        "    idx = int(n/2)+1-factor\n",
        "    weight1 = []\n",
        "    for i in range(idx):\n",
        "        weight1.append((l[i+1]-l[i])*math.pow(np.e, eps*u1[i]/4))\n",
        "    weight1.append(1)\n",
        "    for i in range(idx,n+1):\n",
        "        weight1.append((l[i]-l[i-1])*math.pow(np.e, eps*u1[i]/4))\n",
        "    totalWeight1 = sum(weight1)\n",
        "    weight1 = weight1/totalWeight1\n",
        "\n",
        "    idx = int(n/2)+1+factor\n",
        "    idx = min(int(n/2)+1+factor,n+1)\n",
        "    weight2 = []\n",
        "    for i in range(idx):\n",
        "        weight2.append((l[i+1]-l[i])*math.pow(np.e, eps*u2[i]/4))\n",
        "    weight2.append(1)\n",
        "    for i in range(idx,n+1):\n",
        "        weight2.append((l[i]-l[i-1])*math.pow(np.e, eps*u2[i]/4))\n",
        "\n",
        "    totalWeight2 = sum(weight2)\n",
        "    weight2 = weight2/totalWeight2\n",
        "    return u1,weight1,u2,weight2,factor\n",
        "\n",
        "def EMMedianCI(l,weight,weight1, weight2,factor):\n",
        "    i1 = np.random.choice(list(range(len(l))), p=weight1)\n",
        "    if i1==int(n/2)+1-factor:\n",
        "        x1= int(l[i1]/n)\n",
        "    if i1<int(n/2)+1-factor:\n",
        "        x1= int(np.random.randint(l[i1], l[i1+1],dtype=np.int64)/n)\n",
        "    if i1>int(n/2)+1-factor:\n",
        "        x1= int(np.random.randint(l[i1-1], l[i1],dtype=np.int64)/n)\n",
        "\n",
        "    i2 = np.random.choice(list(range(len(l))), p=weight2)\n",
        "    if i2==int(n/2)+1+factor:\n",
        "        x2= int(l[i2]/n)\n",
        "    if i2<int(n/2)+1+factor:\n",
        "        x2= int(np.random.randint(l[i2], l[i2+1],dtype=np.int64)/n)\n",
        "    if i2>int(n/2)+1+factor:\n",
        "        x2= int(np.random.randint(l[i2-1], l[i2],dtype=np.int64)/n)\n",
        "\n",
        "    est = EMMedian_new(l,weight)\n",
        "    indicator=0\n",
        "    if D[int(n/2)]<=x2 and D[int(n/2)]>=x1:\n",
        "        indicator=1\n",
        "\n",
        "    return x1,x2 ,indicator,est"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eps = []\n",
        "beta = []\n",
        "D = []\n",
        "newD = []\n",
        "domain_size = 4000\n",
        "num_repeat = 100\n",
        "b_list_step = 1\n"
      ],
      "metadata": {
        "id": "iYqaj0NLo-tw"
      },
      "id": "iYqaj0NLo-tw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cdd1c06",
      "metadata": {
        "id": "5cdd1c06"
      },
      "outputs": [],
      "source": [
        "# Our algorithm\n",
        "#1) Learn noisy median o of distribution using Exponential Mechanism\n",
        "def EM_median(eps,beta,D,domain_size):\n",
        "    #print(\"Results for EM, beta = \"+str(beta) + \", epsilon = \" + str(eps))\n",
        "    interval_prob = []\n",
        "    vals, counts = np.unique(D,return_counts=True)\n",
        "    # for i in range(len(counts)):\n",
        "    #   if (counts[i] != 1): print(\"!=1:\",vals[i],counts[i])\n",
        "    rank = 0\n",
        "    vals = [0.0] + vals.tolist()\n",
        "    cdf = 0.0\n",
        "    rank_dict = {}\n",
        "    weights = []\n",
        "    weight_each = []\n",
        "    u = []\n",
        "    n = len(D)\n",
        "    for i in range(1,len(vals)):\n",
        "        rank += counts[i-1]\n",
        "        # print(vals[i],rank)\n",
        "        rank_dict[vals[i]] = rank\n",
        "        utility = -1.0* np.abs(rank - (n/2))\n",
        "        u.append(utility)\n",
        "        p = (vals[i] - vals[i-1])* math.pow(np.e, eps*utility/2)\n",
        "        # if (len(u) == 2000): print(vals[i],vals[i-1],utility,p)\n",
        "        cdf += p\n",
        "        weights.append(p)\n",
        "        if use_discretized == 0:\n",
        "          for j in range(counts[i-1]-1):\n",
        "            weights.append(0)\n",
        "            u.append(0)\n",
        "        interval_prob.append(cdf)\n",
        "    # print(\"our weight len\",len(weight))\n",
        "    rand_val = cdf * np.random.uniform(0,1)\n",
        "    rank_o = 0\n",
        "    # print(\"total weights:\",sum(weights))\n",
        "    total_weights = sum(weights)\n",
        "    weights = [w/total_weights for w in weights]\n",
        "    # print(\"meidan weight:\",weights[1999])\n",
        "    if (use_discretized == 0):\n",
        "      weight_name = 'our weights'\n",
        "      u_name = 'our u'\n",
        "    else:\n",
        "      weight_name = 'our weights(discre)'\n",
        "      u_name = 'our u(discre)'\n",
        "    df[weight_name] = weights+[0,0]\n",
        "    df[u_name] = u+[0,0]\n",
        "\n",
        "    for i in range(1,len(vals)):\n",
        "        if rand_val <= interval_prob[i]:\n",
        "            sens = 1\n",
        "            ci = (2 * sens / eps) * (np.log(domain_size / beta))\n",
        "            # o = np.random.uniform(vals[i-1],vals[i])\n",
        "            o = int(np.random.randint(vals[i], vals[i+1],dtype=np.int64))\n",
        "            # print(\"i:\", i, \"vals[i-1]:\", vals[i-1],\"vals[i]:\",vals[i])\n",
        "            rank_o = rank_dict[vals[i-1]]\n",
        "            # print(\"rank_o:\",rank_o,\"vals[i] and vals[i+1]\",vals[i],vals[i+1])\n",
        "            break\n",
        "    return o,rank_o,rank_dict\n",
        "\n",
        "#2)\n",
        "def find_rank(rank_dict,val):\n",
        "    ranks = list(rank_dict.values())\n",
        "    keys = list(rank_dict.keys())\n",
        "    output = 0\n",
        "    for i in range(len(ranks)-1):\n",
        "        if val < keys[i+1]:\n",
        "            output = ranks[i]\n",
        "            break\n",
        "    #print(rank_dict[output])\n",
        "    return output#int(output)\n",
        "\n",
        "\n",
        "def SVT_median(o,rank_o,rank_dict,eps,beta,D,domain_size,T,b_list):\n",
        "    #print(\"T: \", T)\n",
        "    noisy_T = T + np.random.laplace(2/eps)\n",
        "    sensitivity = 1\n",
        "    bounds = domain_size\n",
        "\n",
        "    for b in b_list: #range(0,b_max,step):\n",
        "        perturbed_value = min(abs(find_rank(rank_dict, o+b)-rank_o),abs(find_rank(rank_dict, o-b)-rank_o)) + np.random.laplace(2*sensitivity/eps)\n",
        "        if perturbed_value > noisy_T:\n",
        "            bounds = b\n",
        "            break\n",
        "    #print(max(o-bounds,0))\n",
        "    #print(min(o+bounds,domain_size-1))\n",
        "    # print(perturbed_value)\n",
        "    result = max(o-bounds,0),min(o+bounds,domain_size-1)\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "def Their_EMMedian_modified(l,weight,D):\n",
        "    i = np.random.choice(list(range(len(l))), p=weight)\n",
        "    # only return int\n",
        "    val = 0\n",
        "    if i==int(n/2)+1:\n",
        "      val = int(l[i]/n)\n",
        "    if i<int(n/2)+1:\n",
        "      val = int(np.random.randint(l[i], l[i+1],dtype=np.int64) / n)\n",
        "    if i>int(n/2)+1:\n",
        "      val = int(np.random.randint(l[i-1], l[i],dtype=np.int64) / n)\n",
        "    vals, counts = np.unique(D,return_counts=True)\n",
        "    rank_dict = {}\n",
        "    rank = 0\n",
        "    vals = [0.0] + vals.tolist()\n",
        "    for i in range(1,len(vals)):\n",
        "        rank += counts[i-1]\n",
        "        rank_dict[vals[i]] = rank\n",
        "    return val,i,rank_dict #rank_dict is from global variable\n",
        "\n",
        "##### main function ######\n",
        "\n",
        "def our_CI(D,domain_size,b_list,med_method=0,l=[],weight=[]):\n",
        "    C = (2/eps_1) *(np.log(domain_size/beta_1))\n",
        "    m = len(b_list)\n",
        "    alpha = (8*np.log(m)+np.log(2/beta_2)) / eps_2\n",
        "    #print(\"C\", C)\n",
        "    #print(\"alpha\", alpha)\n",
        "    T = C + alpha\n",
        "    if (med_method==1):\n",
        "      o,rank_o,rank_dict = Their_EMMedian_modified(l,weight,D) #theirs\n",
        "    else:\n",
        "      o,rank_o,rank_dict = EM_median(eps_1,beta_1,D,domain_size) #ours\n",
        "    # lower,upper = SVT_median(o,rank_o,rank_dict,eps_2,beta_1,D,domain_size,T,b_list)\n",
        "    lower,upper = SVT_median(o,rank_o,rank_dict,eps_2,beta_1,D,domain_size,T,b_list)\n",
        "    #print(\"median:\",o)\n",
        "    #print(\"The bounds are:\")\n",
        "    #print('[{},{}]'.format(lower,upper))\n",
        "    indi = -1 #if CI contains true med\n",
        "    if (use_discretized == 1):\n",
        "      lower,upper = lower/n,upper/n\n",
        "      o /= n\n",
        "    if true_med < upper and true_med > lower:\n",
        "        indi = 1\n",
        "    else:\n",
        "        indi = 0\n",
        "\n",
        "    return lower,upper,indi,o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c742116c",
      "metadata": {
        "id": "c742116c"
      },
      "outputs": [],
      "source": [
        "def test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,compare = False,output=[],med_method = 0):\n",
        "  # med_method: 0 use our EM\n",
        "  #      : 1 use their EM (use_discretized must = 1)\n",
        "  domain_size = int(max(D)-min(D))\n",
        "  if (use_discretized == 1):\n",
        "    b_list = range(0, domain_size, b_list_step*n)\n",
        "    if (med_method == 1):\n",
        "      rad = 10000000\n",
        "      left = -rad\n",
        "      u,l,weight=constructu(eps_1,left*n,rad*n, D)\n",
        "  else:\n",
        "    b_list = range(0, domain_size, b_list_step)\n",
        "\n",
        "  len_eps = []\n",
        "  err_eps = []\n",
        "  est_median = []\n",
        "  times = []\n",
        "  ranks = []\n",
        "  lengths = []\n",
        "  errors = []\n",
        "  rank_errors_1 = [] # based on n/2\n",
        "  rank_errors_2 = [] # based on find_rank(rank_dict,true_med)\n",
        "  # est_list = []\n",
        "  med_rank = int(find_rank(rank_dict, true_med))\n",
        "  for i in range(len(beta)):\n",
        "      print(\"Results for EM based median, beta = \"+str(beta[i]))\n",
        "      correct_count = 0\n",
        "\n",
        "      for j in range(num_repeat):\n",
        "          start = time.time()\n",
        "          if med_method == 0:\n",
        "            xl,xr,indi,est = our_CI(D,domain_size,b_list)#EMMedianCI()\n",
        "          else:\n",
        "            xl,xr,indi,est = our_CI(D,domain_size,b_list,med_method,l,weight)\n",
        "          end = time.time()\n",
        "          times.append(end-start)\n",
        "          correct_count+=indi\n",
        "          lengths.append((xr-xl)/(2))\n",
        "\n",
        "          # interesting and subtle difference!\n",
        "          # mid_value = (xr+xl)/2\n",
        "          errors.append(abs(est-true_med))\n",
        "          est_median.append(est)\n",
        "          rank = int(find_rank(rank_dict, est))\n",
        "          ranks.append(rank)\n",
        "          rank_errors_1.append(int(abs(n/2 - rank)))\n",
        "          rank_errors_2.append(int(abs(med_rank - rank)))\n",
        "      original_errors = errors\n",
        "      errors = np.array(errors, dtype=object)\n",
        "      correct_rate = correct_count/num_repeat\n",
        "      avgLength = sum(lengths)/num_repeat\n",
        "      errors.sort()\n",
        "      errorQuantile = errors[int(num_repeat*(1-beta[i]))]\n",
        "      avg_error = np.average(errors)\n",
        "      avgTime = sum(times)/len(times)\n",
        "\n",
        "\n",
        "      # output medians and error\n",
        "\n",
        "      #download errors\n",
        "      # df = pd.DataFrame(errors)\n",
        "      # file_name = f\"data_error.csv\"\n",
        "      # df.to_csv(file_name, index=False, header=False)\n",
        "      # files.download(file_name)\n",
        "\n",
        "      # median_error\n",
        "      if np.all(errors == errors[0]):\n",
        "          stddev_based_avg_err = errors[0]\n",
        "          IQR_based_avg_err = errors[0]\n",
        "      else:\n",
        "          std_dev = np.std(errors)\n",
        "          stddev_based_avg_err = np.average(errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "          q1 = np.percentile(errors, 25)\n",
        "          q3 = np.percentile(errors, 75)\n",
        "          iqr = q3 - q1\n",
        "          lower_bound = q1 - 1.5 * iqr\n",
        "          upper_bound = q3 + 1.5 * iqr\n",
        "          IQR_based_avg_err = np.average(errors[(errors >= lower_bound) & (errors <= upper_bound)])\n",
        "      # rank_error\n",
        "      avg_rank_error_1 = np.average(rank_errors_1)\n",
        "      avg_rank_error_2 = np.average(rank_errors_2)\n",
        "\n",
        "\n",
        "      name = \"our_CI\"\n",
        "      if (use_discretized == 1):\n",
        "        name = \"our_CI(discretized)\"\n",
        "        domain_size = int(domain_size/n)\n",
        "      if (errorQuantile == 0): relative_CI_width = -1\n",
        "      else: relative_CI_width = avgLength / errorQuantile\n",
        "\n",
        "      print(\"estimated median value: \"+ str(np.average(est_median)))\n",
        "      print(\"correct rate = \", correct_rate)\n",
        "      print(\"Average CI length = \"+str(avgLength))\n",
        "      print(\"error quantile is \"+ str(errorQuantile))\n",
        "      print(\"CI length/ error quantile = \"+str(relative_CI_width))\n",
        "      print(\"Average Time to find CI = \" + str(avgTime))\n",
        "\n",
        "\n",
        "      row_data = [\n",
        "          name,\n",
        "          data_uuid,\n",
        "          n,\n",
        "          domain_size, #new\n",
        "          sens,\n",
        "          beta[i],\n",
        "          eps[i],\n",
        "          num_repeat,\n",
        "          true_med,\n",
        "          np.average(est_median),\n",
        "          correct_rate,\n",
        "          avgLength,\n",
        "          errorQuantile,\n",
        "          avg_error,\n",
        "          stddev_based_avg_err,\n",
        "          IQR_based_avg_err,\n",
        "          avg_rank_error_1,\n",
        "          avg_rank_error_2,\n",
        "          relative_CI_width,\n",
        "          avgTime,\n",
        "          b_list_step,\n",
        "          beta_1,\n",
        "          beta_2,\n",
        "          eps_1,\n",
        "          eps_2\n",
        "      ]\n",
        "      if (output_mode == 0 or output_mode == 2):\n",
        "        write_to_sheet(worksheet1, row_data, output_mode=output_mode, compare=compare)\n",
        "\n",
        "      # New! Check all medians and errors\n",
        "      if (output_mode == 1 or output_mode == 2):\n",
        "        sorted_med = sorted(est_median)\n",
        "        est_median.insert(0, \"Our est_median\")\n",
        "        sorted_med.insert(0, \"Sorted Our est_median\")\n",
        "\n",
        "        sorted_errors = sorted(original_errors)\n",
        "        original_errors.insert(0, \"Our errors\")\n",
        "        sorted_errors.insert(0, \"Sorted Our errors\")\n",
        "\n",
        "        sorted_ranks = sorted(ranks)\n",
        "        ranks.insert(0, \"Our ranks\")\n",
        "        sorted_ranks.insert(0, \"Sorted Our ranks\")\n",
        "\n",
        "        sorted_lengths = sorted(lengths)\n",
        "        lengths.insert(0,\"Our CI lengths\")\n",
        "        sorted_lengths.insert (0, \"Sorted Our CI lengths\")\n",
        "\n",
        "        sorted_re_1 = sorted(rank_errors_1)\n",
        "        sorted_re_2 = sorted(rank_errors_2)\n",
        "        rank_errors_1.insert(0, \"Our rank_errors(n/2)\")\n",
        "        rank_errors_2.insert(0, \"Our rank_errors(find)\")\n",
        "        sorted_re_1.insert(0, \"Sorted Our rank_errors(n/2)\")\n",
        "        sorted_re_2.insert(0, \"Sorted Our rank_errors(find)\")\n",
        "\n",
        "\n",
        "        data_uid_row = [\"data:\", data_uuid, \"method:\", \"Our_CI\"]\n",
        "        true_med_row = [\"true median\"]+[true_med]*num_repeat\n",
        "        n_over_2_row = [\"true n/2\"] + [n/2]*num_repeat\n",
        "        med_rank_row = [\"true med_rank(find)\"] + [med_rank]*num_repeat\n",
        "\n",
        "        worksheet.append_row(data_uid_row)\n",
        "        worksheet.append_row(est_median)\n",
        "        worksheet.append_row(true_med_row)\n",
        "        worksheet.append_row(original_errors)\n",
        "        # write_to_sheet(worksheet1, errors, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(ranks)\n",
        "        worksheet.append_row(n_over_2_row)\n",
        "        worksheet.append_row(rank_errors_1)\n",
        "        # write_to_sheet(worksheet1, rank_errors_1, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(med_rank_row)\n",
        "        worksheet.append_row(rank_errors_2)\n",
        "        worksheet.append_row(lengths)\n",
        "\n",
        "        # write_to_sheet(worksheet1, rank_errors_2, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(sorted_med)\n",
        "        worksheet.append_row(sorted_ranks)\n",
        "        worksheet.append_row(sorted_errors)\n",
        "        worksheet.append_row(sorted_re_1)\n",
        "        worksheet.append_row(sorted_re_2)\n",
        "        worksheet.append_row(sorted_lengths)\n",
        "\n",
        "      len_eps.append(avgLength)\n",
        "      err_eps.append(errorQuantile)\n",
        "      print(len_eps)\n",
        "      print(err_eps)\n",
        "      if (output_mode == 3):\n",
        "        output = row_data\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "490b3cbd",
      "metadata": {
        "id": "490b3cbd"
      },
      "outputs": [],
      "source": [
        "def test_theirs(eps=eps, beta=beta, num_repeat=num_repeat, D=newD,median_method = 0,compare = False,output=[]):\n",
        "  #median_method = 0:median from CI algorithm\n",
        "  #        = 1:median from EMMedianCI\n",
        "  n = len(newD)\n",
        "  domain_size = int((max(D)-min(D))/n)\n",
        "  len_eps = []\n",
        "  err_eps = []\n",
        "  est_median = []\n",
        "  times = []\n",
        "  ranks = []\n",
        "  EM_median_errors = []\n",
        "  med_rank = int(find_rank(rank_dict, true_med))\n",
        "  est_list = []\n",
        "  rank_errors_1 = [] # based on n/2\n",
        "  rank_errors_2 = [] # based on find_rank(rank_dict,true_med)\n",
        "  for i in range(len(beta)):\n",
        "      print(\"Results for EM based median, beta = \"+str(beta[i]))\n",
        "      errors = []\n",
        "      lengths = []\n",
        "      correct_count = 0\n",
        "      rad = 10000000\n",
        "      left=-rad\n",
        "      u,l,weight = constructu(eps[i], left*n,rad*n, newD)\n",
        "      u1,weight1,u2,weight2,factor = constructu_CI(eps[i],beta[i], rad,u,l)\n",
        "      for j in range(num_repeat):\n",
        "          start = time.time()\n",
        "          xl,xr,indi,est = EMMedianCI(l,weight,weight1,weight2,factor)\n",
        "          end = time.time()\n",
        "          times.append(end-start)\n",
        "          correct_count+=indi\n",
        "          lengths.append((xr-xl)/(2))\n",
        "          if (median_method == 0):\n",
        "            their_median = (xr+xl)/2\n",
        "          else:\n",
        "            their_median = est\n",
        "          est_median.append(their_median)\n",
        "          errors.append(abs(their_median-true_med))\n",
        "          EM_median_errors.append(abs(est-true_med)) # their def of errors\n",
        "          rank = int(find_rank(rank_dict, their_median))\n",
        "          ranks.append(rank)\n",
        "          rank_errors_1.append(int(abs(n/2 - rank)))\n",
        "          rank_errors_2.append(int(abs(med_rank - rank)))\n",
        "\n",
        "      original_errors = errors\n",
        "      errors = np.array(errors, dtype=object)\n",
        "      correct_rate = correct_count/num_repeat\n",
        "      avgLength = sum(lengths)/num_repeat\n",
        "      errors.sort()\n",
        "      errorQuantile = errors[int(num_repeat*(1-beta[i]))]\n",
        "\n",
        "      avgTime = sum(times)/len(times)\n",
        "\n",
        "\n",
        "      errors = np.array(errors)\n",
        "      avg_error = np.average(errors)\n",
        "      if (errorQuantile == 0): relative_CI_width = -1\n",
        "      else: relative_CI_width = avgLength / errorQuantile\n",
        "      if np.all(errors == errors[0]):\n",
        "          stddev_based_avg_err = errors[0]\n",
        "          IQR_based_avg_err = errors[0]\n",
        "      else:\n",
        "          std_dev = np.std(errors)\n",
        "          stddev_based_avg_err = np.average(errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "\n",
        "          q1 = np.percentile(errors, 25)\n",
        "          q3 = np.percentile(errors, 75)\n",
        "          iqr = q3 - q1\n",
        "          lower_bound = q1 - 1.5 * iqr\n",
        "          upper_bound = q3 + 1.5 * iqr\n",
        "          IQR_based_avg_err = np.average(errors[(errors >= lower_bound) & (errors <= upper_bound)])\n",
        "\n",
        "      #rank_avg\n",
        "      avg_rank_error_1 = np.average(rank_errors_1)\n",
        "      avg_rank_error_2 = np.average(rank_errors_2)\n",
        "      print(\"Filtered Errors for IQR_based_avg_err:\", IQR_based_avg_err)\n",
        "\n",
        "      print(\"estimated median value: \"+ str(np.average(est_median)))\n",
        "      print(\"correct rate = \" +str(correct_count/num_repeat))\n",
        "      print(\"Average CI length = \"+str(avgLength))\n",
        "      print(\"error quantile is \"+ str(errorQuantile))\n",
        "      print(\"CI length/ error quantile = \"+str(avgLength/errorQuantile))\n",
        "      print(\"Average Time to find CI = \" + str(sum(times)/len(times)))\n",
        "      # print(\"Errors:\", errors)\n",
        "      # print(\"Standard Deviation:\", std_dev)\n",
        "      # print(\"Filtered Errors for stddev_based_avg_err:\", errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "\n",
        "      # print(\"Q1:\", q1, \"Q3:\", q3)\n",
        "      # print(\"IQR:\", iqr)\n",
        "      # print(\"Lower Bound:\", lower_bound, \"Upper Bound:\", upper_bound)\n",
        "      if (median_method == 0):\n",
        "        name = \"EM_CI\"\n",
        "      else:\n",
        "        name = \"EM\"\n",
        "      row_data = [\n",
        "          name,\n",
        "          data_uuid,\n",
        "          n,\n",
        "          domain_size, #3\n",
        "          sens, #4\n",
        "          beta[i],#5\n",
        "          eps[i], #6\n",
        "          num_repeat, #7\n",
        "          true_med, #8\n",
        "          np.average(est_median), #9\n",
        "          correct_rate, #10\n",
        "          avgLength, #11\n",
        "          errorQuantile, #12\n",
        "          avg_error,#13\n",
        "          stddev_based_avg_err, #14\n",
        "          IQR_based_avg_err, #15\n",
        "          avg_rank_error_1, #16\n",
        "          avg_rank_error_2, #17\n",
        "          relative_CI_width, #18\n",
        "          avgTime\n",
        "      ]\n",
        "      if (output_mode == 0 or output_mode == 2):\n",
        "        write_to_sheet(worksheet1, row_data, compare = compare)\n",
        "\n",
        "      if (output_mode == 1 or output_mode == 2):\n",
        "        sorted_med = sorted(est_median)\n",
        "        est_median.insert(0, \"EM est_median\")\n",
        "        sorted_med.insert(0, \"Sorted EM est_median\")\n",
        "\n",
        "        sorted_errors = sorted(original_errors)\n",
        "        original_errors.insert(0, \"EM errors\")\n",
        "        sorted_errors.insert(0, \"Sorted EM errors\")\n",
        "\n",
        "        sorted_ranks = sorted(ranks)\n",
        "        ranks.insert(0, \"EM ranks\")\n",
        "        sorted_ranks.insert(0, \"Sorted EM ranks\")\n",
        "\n",
        "        sorted_re_1 = sorted(rank_errors_1)\n",
        "        sorted_re_2 = sorted(rank_errors_2)\n",
        "        rank_errors_1.insert(0, \"EM rank_errors(n/2)\")\n",
        "        rank_errors_2.insert(0, \"EM rank_errors(find)\")\n",
        "        sorted_re_1.insert(0, \"Sorted EM rank_errors(n/2)\")\n",
        "        sorted_re_2.insert(0, \"Sorted EM rank_errors(find)\")\n",
        "\n",
        "        sorted_lengths = sorted(lengths)\n",
        "        lengths.insert(0,\"EM CI lengths\")\n",
        "        sorted_lengths.insert (0, \"Sorted EM CI lengths\")\n",
        "\n",
        "        data_uid_row = [\"data:\", data_uuid, \"method:\", \"EM_CI\"]\n",
        "        true_med_row = [\"true median\"]+[true_med]*num_repeat\n",
        "        n_over_2_row = [\"true n/2\"] + [n/2]*num_repeat\n",
        "        med_rank_row = [\"true med_rank(find)\"] + [med_rank]*num_repeat\n",
        "\n",
        "        print(est_list)\n",
        "        worksheet.append_row(data_uid_row)\n",
        "        worksheet.append_row(est_median)\n",
        "        worksheet.append_row(true_med_row)\n",
        "\n",
        "        worksheet.append_row(original_errors)\n",
        "        # write_to_sheet(worksheet1, original_errors, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(ranks)\n",
        "        worksheet.append_row(n_over_2_row)\n",
        "        worksheet.append_row(rank_errors_1)\n",
        "        # write_to_sheet(worksheet1, rank_errors_1, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(med_rank_row)\n",
        "        worksheet.append_row(rank_errors_2)\n",
        "        worksheet.append_row(lengths)\n",
        "        # write_to_sheet(worksheet1, rank_errors_2, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(sorted_med)\n",
        "        worksheet.append_row(sorted_ranks)\n",
        "        worksheet.append_row(sorted_errors)\n",
        "        worksheet.append_row(sorted_re_1)\n",
        "        worksheet.append_row(sorted_re_2)\n",
        "        worksheet.append_row(sorted_lengths)\n",
        "\n",
        "\n",
        "\n",
        "      len_eps.append(avgLength)\n",
        "      err_eps.append(errorQuantile)\n",
        "      print(len_eps)\n",
        "      print(err_eps)\n",
        "      if (output_mode == 3):\n",
        "        output = row_data\n",
        "      return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-xoDZUe5Or-N",
      "metadata": {
        "id": "-xoDZUe5Or-N"
      },
      "outputs": [],
      "source": [
        "def readInput(mode):\n",
        "    import numpy as np\n",
        "    read_data_uuid = \"64b7c8bf89f14113bd12f5f15e276546\"\n",
        "    file_paths = {\n",
        "        0: (\"./bank_marketing.csv\", 5),\n",
        "        1: (\"./adult.csv\", 2),\n",
        "        2: (\"./sample_data/california_housing_test.csv\", 3),\n",
        "        3: (\"./sample_data/california_housing_test.csv\", 8),\n",
        "        5: (\"./ratings_small.csv\",3),\n",
        "        6: (\"./airplane_price_dataset.csv\",1),\n",
        "        7: (\"./airplane_price_dataset.csv\",2),\n",
        "        8: (\"./airplane_price_dataset.csv\",3),\n",
        "        9: (\"./airplane_price_dataset.csv\",4),\n",
        "        10: (\"./data_\"+read_data_uuid+\".csv\",0),\n",
        "    }\n",
        "\n",
        "    if mode not in file_paths:\n",
        "        raise ValueError(\"Invalid mode. Choose between 0 to 3\")\n",
        "\n",
        "    input_path, column_index = file_paths[mode]\n",
        "\n",
        "    with open(input_path, 'r',errors='ignore') as input_file:\n",
        "        lines = input_file.readlines()\n",
        "    n = len(lines)\n",
        "    D = np.zeros(n)\n",
        "    for i, line in enumerate(lines):\n",
        "        if i > 0:\n",
        "            elements = line.split(\",\")\n",
        "            try:\n",
        "                value = float(elements[column_index])\n",
        "                D[i - 1] = int(value)\n",
        "            except ValueError:\n",
        "              if (column_index < len(elements)):\n",
        "                print(f\"Skipping invalid data at line {i}: {elements[column_index]}\")\n",
        "    return D\n",
        "\n",
        "def normalize_non_negative(D):\n",
        "  if lowest<0:\n",
        "    D = [d-lowest for d in D]\n",
        "  return D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def color_vertically(worksheet,col=10,smaller_better=True,row_number=4):\n",
        "  # row_number: number of rows you want to colour\n",
        "  # Define the column indices\n",
        "  col_true = 9\n",
        "  values_I = worksheet.col_values(col_true)\n",
        "  values_col = worksheet.col_values(col)\n",
        "\n",
        "  # Extract the last k rows (ensuring they are numeric)\n",
        "  last_4_true = [float(values_I[-row_number + i]) for i in range(row_number)]\n",
        "  last_4_vals = [float(values_col[-row_number + i]) for i in range(row_number)]\n",
        "\n",
        "  if (col==10):\n",
        "    diffs = [abs(last_4_vals[i] - last_4_true[i]) for i in range(row_number)]\n",
        "  else:\n",
        "    diffs = last_4_vals\n",
        "\n",
        "  # Rank differences from smallest to largest\n",
        "  if smaller_better:\n",
        "      sorted_indices = sorted(range(len(diffs)), key=lambda k: diffs[k])\n",
        "  else:\n",
        "      sorted_indices = sorted(range(len(diffs)), key=lambda k: diffs[k], reverse=True)\n",
        "\n",
        "\n",
        "  # Define colors for ranking\n",
        "  colors = [\n",
        "    {\"red\": 0.0, \"green\": 1.0, \"blue\": 0.0},  # Green (best)\n",
        "    {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6},  # Light Green\n",
        "    {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6},  # Light Red\n",
        "    {\"red\": 1.0, \"green\": 0.0, \"blue\": 0.0},  # Red (worst)\n",
        "  ]\n",
        "\n",
        "  # Get the last 4 row indices\n",
        "  base_row = len(values_col) - row_number+1  # First of the last 4 rows (1-based index)\n",
        "\n",
        "  # Apply formatting\n",
        "  for rank, index in enumerate(sorted_indices):\n",
        "    row = base_row + index  # Correct row number\n",
        "    cell = f\"{chr(64 + col)}{row}\"  # Convert column number to letter (J)\n",
        "    worksheet.format(cell, {\"backgroundColor\": colors[rank]})"
      ],
      "metadata": {
        "id": "aV2Tp7gg_Nl8"
      },
      "id": "aV2Tp7gg_Nl8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def color_horizontally(worksheet):\n",
        "    col_b = 2  # Column B (1-based index)\n",
        "    col_e = 5  # Column E (1-based index)\n",
        "\n",
        "    # Get the last row values from Column B to Column E\n",
        "    last_row = worksheet.row_values(len(worksheet.get_all_values()))\n",
        "    # Convert the values to floats (or int if appropriate)\n",
        "    values_b_to_e = [float(value) for value in last_row[col_b - 1:col_e]]  # Ensure values are numeric\n",
        "\n",
        "    # Define colors for ranking\n",
        "    colors = [\n",
        "        {\"red\": 0.0, \"green\": 1.0, \"blue\": 0.0},  # Green (min)\n",
        "        {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6},  # Light Green (2nd smallest)\n",
        "        {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6},  # Light Red\n",
        "        {\"red\": 1.0, \"green\": 0.0, \"blue\": 0.0},  # Red (max)\n",
        "    ]\n",
        "\n",
        "    # Sort the values and map them to their ranks\n",
        "    sorted_indices = sorted(range(len(values_b_to_e)), key=lambda k: values_b_to_e[k])\n",
        "    rank_map = {sorted_indices[i]: i for i in range(len(sorted_indices))}  # Map index to rank\n",
        "\n",
        "    # Get the column letters for Column B to Column E\n",
        "    columns = ['B', 'C', 'D', 'E']\n",
        "\n",
        "    # Loop through each value and apply the background color based on its rank\n",
        "    for i, value in enumerate(values_b_to_e):\n",
        "        col_letter = columns[i]  # Get column letter\n",
        "        cell = f\"{col_letter}{len(worksheet.get_all_values())}\"  # Cell reference\n",
        "        rank = rank_map[i]  # Get the rank from the rank map\n",
        "        worksheet.format(cell, {\"backgroundColor\": colors[rank]})\n"
      ],
      "metadata": {
        "id": "ZIngr9znP4Vp"
      },
      "id": "ZIngr9znP4Vp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "kTEhx4k8KNoQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "kTEhx4k8KNoQ",
        "outputId": "cc0c15d4-694c-4974-a907-2d523d67dd10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[37128.97393773 35040.67574492 12038.51920676 ... 31415.71133272\n",
            " 17495.37936255 21797.9787702 ]\n",
            "Data_size: 20000\n",
            "Domain size: 40001\n",
            "true median:  20155.0\n",
            "true median rank: 10000.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_012e3879-c53b-4b64-ad5e-c03813528474\", \"data_6f291671e3b64594856276fc5f74a8a5.csv\", 154448)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved as data_6f291671e3b64594856276fc5f74a8a5.csv\n"
          ]
        }
      ],
      "source": [
        "# Experiment Data Input\n",
        "\n",
        "dataset_id_dict = {0:\"bank_marketing\", 1:\"adult\", 2:\"cali_housing_test\", 3:\"cali_housing_value\",\n",
        "           5:\"IMDB_time\",6:\"airplane_capacity\",7:\"airplane_range\",8:\"airplane_maintenance\",9:\"airplane_price\",\n",
        "           10: \"old_synthetic_data\"}\n",
        "mode = -1\n",
        "\n",
        "if (mode == -1):\n",
        "  n = 20000  # 45#000\n",
        "  domain_size = 40001  # 40#000\n",
        "  D = np.random.uniform(0, domain_size, n)\n",
        "  lowest = 0\n",
        "  highest = domain_size\n",
        "else:\n",
        "  D = readInput(mode)\n",
        "  lowest = int(min(D))\n",
        "  #elinminate negative numbers\n",
        "  # if (lowest < 0):\n",
        "  #   D = normalize_non_negative(D)\n",
        "  #   lowest = 0\n",
        "  highest = int(max(D))\n",
        "  print(\"lowest:\",lowest)\n",
        "\n",
        "n = len(D)\n",
        "domain_size = highest - lowest\n",
        "print(D)\n",
        "\n",
        "D.sort()\n",
        "D = discretize(D, 1)\n",
        "newD = discrete(D)\n",
        "true_med = np.median(D)\n",
        "\n",
        "print(\"Data_size:\", n)\n",
        "print(\"Domain size:\", domain_size)\n",
        "\n",
        "print(\"true median: \", true_med)\n",
        "\n",
        "# rank_dict\n",
        "vals, counts = np.unique(D,return_counts=True)\n",
        "rank_dict = {}\n",
        "rank = 0\n",
        "vals = [0.0] + vals.tolist()\n",
        "for i in range(1,len(vals)):\n",
        "    rank += counts[i-1]\n",
        "    rank_dict[vals[i]] = rank\n",
        "print(\"true median rank:\",n/2)\n",
        "\n",
        "\n",
        "\n",
        "# Data Persistence\n",
        "if (mode == -1):\n",
        "  df = pd.DataFrame(D)\n",
        "  data_uuid = uuid.uuid4().hex\n",
        "  file_name = f\"data_{data_uuid}.csv\"\n",
        "  df.to_csv(file_name, index=False, header=False)\n",
        "  files.download(file_name)\n",
        "  print(f\"File saved as {file_name}\")\n",
        "else:\n",
        "  data_uuid = dataset_id_dict[mode]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G-o_F3TWSUzN",
      "metadata": {
        "id": "G-o_F3TWSUzN"
      },
      "outputs": [],
      "source": [
        "# CI Parameters\n",
        "eps = [1]\n",
        "beta = [0.01]\n",
        "sens = 1 #fixed\n",
        "num_repeat=100\n",
        "\n",
        "# for val, rank in rank_dict.items():\n",
        "#     print(val,\"  \",rank)\n",
        "\n",
        "# Parameters for our_CI\n",
        "beta_1 = 0.5 *beta[0]\n",
        "beta_2 = beta[0] - beta_1\n",
        "# eps_1 = 0.5 * eps[0]\n",
        "# eps_2 = eps[0] - eps_1\n",
        "eps_1 = 0.5 * eps[0]\n",
        "eps_2 = eps[0] - eps_1\n",
        "\n",
        "\n",
        "b_list_step = 1\n",
        "if mode == 1: b_list_step = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZZKk-CjfKeLU",
      "metadata": {
        "id": "ZZKk-CjfKeLU"
      },
      "outputs": [],
      "source": [
        "# Test both\n",
        "\n",
        "# output_mode 0:experiment results,\n",
        "#        1:medians&ranks, CI legnths\n",
        "#        2:both\n",
        "#        3:return row_result and do not write to google spreadsheet\n",
        "\n",
        "# EM_mode  0: use our original EM\n",
        "#       1: use our original EM with discretized data\n",
        "#       2: use their EM with discretized data\n",
        "\n",
        "output_mode = 3\n",
        "download = 0\n",
        "df = pd.DataFrame()\n",
        "df[\"rank\"] = list(range(1,len(D)+1)) + [0,0]\n",
        "df[\"data\"] = list(D)+ [0,0]\n",
        "df[\"discretized_data\"] = list(newD) + [0,0]\n",
        "\n",
        "test_theirs(eps=[0.5], beta=beta, num_repeat=num_repeat,median_method=1,D=newD) #test EM\n",
        "# test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=0,D=newD) #test EM_CI\n",
        "\n",
        "print(\"-------------------EMCI Test Done--------------------\")\n",
        "\n",
        "if output_mode==2:\n",
        "  print(\"wait for 60 secs for the Second Test\")\n",
        "  time.sleep(60)\n",
        "\n",
        "use_discretized = 0\n",
        "test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,compare = True)\n",
        "# use_discretized = 1\n",
        "# test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,compare = True)\n",
        "print(\"-------------------ourCI Test Done--------------------\")\n",
        "color_vertically(worksheet,col=10)\n",
        "\n",
        "# Result Persistence\n",
        "csv_name = \"weight\"+data_uuid\n",
        "df.to_csv(csv_name+\".csv\",index=False)\n",
        "if (download == 1):\n",
        "  files.download(csv_name+\".csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "72FYc7UozH2c",
      "metadata": {
        "id": "72FYc7UozH2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48bb24a-ccb6-4153-81b7-55564b67069b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------Runing eps:0.125---------\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 4097\n",
            "Filtered Errors for IQR_based_avg_err: 59.145833333333336\n",
            "estimated median value: 20151.06\n",
            "correct rate = 1.0\n",
            "Average CI length = 8222.485\n",
            "error quantile is 199.0\n",
            "CI length/ error quantile = 41.31902010050251\n",
            "Average Time to find CI = 0.005344283580780029\n",
            "[8222.485]\n",
            "[199.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 2048\n",
            "Filtered Errors for IQR_based_avg_err: 60.015151515151516\n",
            "estimated median value: 20116.83\n",
            "correct rate = 1.0\n",
            "Average CI length = 4060.84\n",
            "error quantile is 262.5\n",
            "CI length/ error quantile = 15.469866666666666\n",
            "Average Time to find CI = 0.0052695608139038085\n",
            "[4060.84]\n",
            "[262.5]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 20160.68\n",
            "correct rate =  1.0\n",
            "Average CI length = 19998.5\n",
            "error quantile is 449.0\n",
            "CI length/ error quantile = 44.54008908685969\n",
            "Average Time to find CI = 0.09248602628707886\n",
            "[19998.5]\n",
            "[449.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 20141.464307\n",
            "correct rate =  1.0\n",
            "Average CI length = 19998.999975000028\n",
            "error quantile is 310.4623500000016\n",
            "CI length/ error quantile = 64.41682856230369\n",
            "Average Time to find CI = 0.10349973678588867\n",
            "[19998.999975000028]\n",
            "[310.4623500000016]\n",
            "---------Runing eps:0.25---------\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 2048\n",
            "Filtered Errors for IQR_based_avg_err: 28.802083333333332\n",
            "estimated median value: 20155.42\n",
            "correct rate = 1.0\n",
            "Average CI length = 4054.43\n",
            "error quantile is 124.0\n",
            "CI length/ error quantile = 32.69701612903226\n",
            "Average Time to find CI = 0.0052271604537963865\n",
            "[4054.43]\n",
            "[124.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 1024\n",
            "Filtered Errors for IQR_based_avg_err: 23.28723404255319\n",
            "estimated median value: 20154.745\n",
            "correct rate = 1.0\n",
            "Average CI length = 2010.345\n",
            "error quantile is 119.5\n",
            "CI length/ error quantile = 16.82297071129707\n",
            "Average Time to find CI = 0.005250651836395264\n",
            "[2010.345]\n",
            "[119.5]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 20141.96\n",
            "correct rate =  1.0\n",
            "Average CI length = 19998.5\n",
            "error quantile is 148.0\n",
            "CI length/ error quantile = 135.125\n",
            "Average Time to find CI = 0.09272339820861816\n",
            "[19998.5]\n",
            "[148.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 20151.621508\n",
            "correct rate =  1.0\n",
            "Average CI length = 19998.999975000028\n",
            "error quantile is 142.32080000000133\n",
            "CI length/ error quantile = 140.52057025396036\n",
            "Average Time to find CI = 0.10511791467666626\n",
            "[19998.999975000028]\n",
            "[142.32080000000133]\n",
            "---------Runing eps:0.5---------\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 1024\n",
            "Filtered Errors for IQR_based_avg_err: 18.6734693877551\n",
            "estimated median value: 20150.94\n",
            "correct rate = 1.0\n",
            "Average CI length = 2015.43\n",
            "error quantile is 81.0\n",
            "CI length/ error quantile = 24.881851851851852\n",
            "Average Time to find CI = 0.005414483547210694\n",
            "[2015.43]\n",
            "[81.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 512\n",
            "Filtered Errors for IQR_based_avg_err: 21.19191919191919\n",
            "estimated median value: 20175.825\n",
            "correct rate = 1.0\n",
            "Average CI length = 987.995\n",
            "error quantile is 85.5\n",
            "CI length/ error quantile = 11.555497076023391\n",
            "Average Time to find CI = 0.005309927463531494\n",
            "[987.995]\n",
            "[85.5]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 20146.84\n",
            "correct rate =  1.0\n",
            "Average CI length = 19998.5\n",
            "error quantile is 76.0\n",
            "CI length/ error quantile = 263.1381578947368\n",
            "Average Time to find CI = 0.08673258781433106\n",
            "[19998.5]\n",
            "[76.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 20152.6140285\n",
            "correct rate =  1.0\n",
            "Average CI length = 19998.999975000028\n",
            "error quantile is 83.61434999999983\n",
            "CI length/ error quantile = 239.1814320747583\n",
            "Average Time to find CI = 0.09870663404464722\n",
            "[19998.999975000028]\n",
            "[83.61434999999983]\n",
            "---------Runing eps:1---------\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 512\n",
            "Filtered Errors for IQR_based_avg_err: 10.434782608695652\n",
            "estimated median value: 20154.28\n",
            "correct rate = 1.0\n",
            "Average CI length = 987.185\n",
            "error quantile is 52.0\n",
            "CI length/ error quantile = 18.98432692307692\n",
            "Average Time to find CI = 0.00818777561187744\n",
            "[987.185]\n",
            "[52.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 256\n",
            "Filtered Errors for IQR_based_avg_err: 31.5765306122449\n",
            "estimated median value: 20186.545\n",
            "correct rate = 1.0\n",
            "Average CI length = 482.135\n",
            "error quantile is 59.0\n",
            "CI length/ error quantile = 8.171779661016949\n",
            "Average Time to find CI = 0.009258084297180176\n",
            "[482.135]\n",
            "[59.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 20150.0\n",
            "correct rate =  1.0\n",
            "Average CI length = 19998.5\n",
            "error quantile is 54.0\n",
            "CI length/ error quantile = 370.3425925925926\n",
            "Average Time to find CI = 0.08438514232635498\n",
            "[19998.5]\n",
            "[54.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 20152.3252465\n",
            "correct rate =  1.0\n",
            "Average CI length = 19998.999975000028\n",
            "error quantile is 33.218150000000605\n",
            "CI length/ error quantile = 602.0503843531221\n",
            "Average Time to find CI = 0.10593740463256836\n",
            "[19998.999975000028]\n",
            "[33.218150000000605]\n",
            "---------Runing eps:2---------\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 256\n",
            "Filtered Errors for IQR_based_avg_err: 7.97\n",
            "estimated median value: 20158.75\n",
            "correct rate = 1.0\n",
            "Average CI length = 482.03\n",
            "error quantile is 20.0\n",
            "CI length/ error quantile = 24.101499999999998\n",
            "Average Time to find CI = 0.005302715301513672\n",
            "[482.03]\n",
            "[20.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 128\n",
            "Filtered Errors for IQR_based_avg_err: 3.090909090909091\n",
            "estimated median value: 20155.405\n",
            "correct rate = 1.0\n",
            "Average CI length = 251.915\n",
            "error quantile is 11.5\n",
            "CI length/ error quantile = 21.905652173913044\n",
            "Average Time to find CI = 0.005233187675476075\n",
            "[251.915]\n",
            "[11.5]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 20150.12\n",
            "correct rate =  1.0\n",
            "Average CI length = 19998.5\n",
            "error quantile is 25.0\n",
            "CI length/ error quantile = 799.94\n",
            "Average Time to find CI = 0.09404266357421875\n",
            "[19998.5]\n",
            "[25.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 20152.4800045\n",
            "correct rate =  1.0\n",
            "Average CI length = 19998.999975000028\n",
            "error quantile is 23.515699999999924\n",
            "CI length/ error quantile = 850.4531004818097\n",
            "Average Time to find CI = 0.10712241411209106\n",
            "[19998.999975000028]\n",
            "[23.515699999999924]\n",
            "---------Runing eps:4---------\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 128\n",
            "Filtered Errors for IQR_based_avg_err: 5.0\n",
            "estimated median value: 20159.24\n",
            "correct rate = 1.0\n",
            "Average CI length = 251.315\n",
            "error quantile is 12.0\n",
            "CI length/ error quantile = 20.942916666666665\n",
            "Average Time to find CI = 0.005533843040466308\n",
            "[251.315]\n",
            "[12.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 64\n",
            "Filtered Errors for IQR_based_avg_err: 5.677083333333333\n",
            "estimated median value: 20149.325\n",
            "correct rate = 1.0\n",
            "Average CI length = 130.495\n",
            "error quantile is 10.5\n",
            "CI length/ error quantile = 12.428095238095239\n",
            "Average Time to find CI = 0.005296339988708496\n",
            "[130.495]\n",
            "[10.5]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 20149.72\n",
            "correct rate =  1.0\n",
            "Average CI length = 19998.5\n",
            "error quantile is 19.0\n",
            "CI length/ error quantile = 1052.5526315789473\n",
            "Average Time to find CI = 0.09425214767456054\n",
            "[19998.5]\n",
            "[19.0]\n",
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 20152.922007000005\n",
            "correct rate =  1.0\n",
            "Average CI length = 19998.999975000028\n",
            "error quantile is 10.83444999999847\n",
            "CI length/ error quantile = 1845.8712694232613\n",
            "Average Time to find CI = 0.09819554805755615\n",
            "[19998.999975000028]\n",
            "[10.83444999999847]\n"
          ]
        }
      ],
      "source": [
        "# write ouput to google spreadsheet in a clean format\n",
        "output_mode = 3\n",
        "return_index = 13 # 13 is for avg error\n",
        "experiment_target = \"Avg Median Error\"\n",
        "column1_title = \"eps\"\n",
        "\n",
        "worksheet.append_row([data_uuid,\"domain_size:\"+str(domain_size),\"n:\"+str(n),experiment_target])\n",
        "worksheet.append_row([column1_title,\"EM\",\"EM_CI\",\"our_CI\",\"our_CI(discretized)\"])\n",
        "eps_list = [0.125,0.25,0.5,1,2,4] #\n",
        "df = pd.DataFrame()\n",
        "b_list_step = 50000\n",
        "for eps_val in eps_list:\n",
        "  eps = [eps_val]\n",
        "  print(\"---------Runing eps:\"+str(eps_val)+\"---------\")\n",
        "  EM_output = test_theirs(eps=[eps_val*0.5], beta=beta, num_repeat=num_repeat,median_method=1,D=newD)[return_index] #test EM\n",
        "  EMCI_output = test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=0,D=newD)[return_index] #test EM_CI\n",
        "  eps_1 = 0.5 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  use_discretized = 0\n",
        "  ourCI_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,compare = True)[return_index]\n",
        "  use_discretized = 1\n",
        "  ourCI2_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,compare = True)[return_index]\n",
        "  output_RowData = [eps_val, EM_output,EMCI_output,ourCI_output,ourCI2_output]\n",
        "  worksheet.append_row(output_RowData)\n",
        "  color_horizontally(worksheet)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "color_horizontally(worksheet)"
      ],
      "metadata": {
        "id": "_o2ui9KrPjlM"
      },
      "id": "_o2ui9KrPjlM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GfTJIPHarSAT",
      "metadata": {
        "id": "GfTJIPHarSAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0783b997-7350-4105-930a-0abc001fd8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 4343.54\n",
            "correct rate =  0.0\n",
            "Average CI length = 0.0\n",
            "error quantile is 2663.0\n",
            "CI length/ error quantile = 0.0\n",
            "Average Time to find CI = 0.009568204879760742\n",
            "[0.0]\n",
            "[2663.0]\n"
          ]
        }
      ],
      "source": [
        "  output_mode = 0\n",
        "  eps = [1]\n",
        "  eps_1 = 0.5 * eps[0]\n",
        "  eps_2 = eps[0] - eps_1\n",
        "  use_discretized = 0\n",
        "  test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,compare = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dkQZxi1QE90V"
      },
      "id": "dkQZxi1QE90V",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}