{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Timliuw/DP-Tim/blob/main/CI_Tim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cfd74f5f",
      "metadata": {
        "id": "cfd74f5f"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import copy\n",
        "import getopt\n",
        "import psycopg2\n",
        "import sys\n",
        "import time\n",
        "import pandas as pd\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "zfatDYXyr6eo",
      "metadata": {
        "id": "zfatDYXyr6eo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "ace77d94-3600-436e-ea52-47d17df14df3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-18a1a06b-8d7e-4e43-8f9e-6320803bc4cb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-18a1a06b-8d7e-4e43-8f9e-6320803bc4cb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving adult.csv to adult.csv\n",
            "Saving airplane_price_dataset.csv to airplane_price_dataset.csv\n",
            "Saving bank_marketing.csv to bank_marketing.csv\n",
            "Saving california_housing_test.csv to california_housing_test.csv\n",
            "Saving ratings_small.csv to ratings_small.csv\n",
            "Saving sublime-mission-447319-c2-0df1612796a8.json to sublime-mission-447319-c2-0df1612796a8.json\n"
          ]
        }
      ],
      "source": [
        "#for experiments purpose\n",
        "import gspread\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.service_account import Credentials\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "import os\n",
        "os.listdir()\n",
        "\n",
        "scope = [\n",
        "    \"https://spreadsheets.google.com/feeds\",  # Google Sheets API\n",
        "    \"https://www.googleapis.com/auth/drive\"   # Google Drive API\n",
        "]\n",
        "\n",
        "# Trigger the file upload dialog\n",
        "try:\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(\"sublime-mission-447319-c2-0df1612796a8.json\", scope)\n",
        "except:\n",
        "   uploaded = files.upload()\n",
        "\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(\"sublime-mission-447319-c2-0df1612796a8.json\", scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "spreadsheet = client.open_by_key(\"1yVVt5ACdBbjsZ_7IiRkvPGIHmpKe8mFXcvyL0PVP2cE\")\n",
        "\n",
        "worksheet1 = spreadsheet.get_worksheet(0)\n",
        "worksheet = worksheet1\n",
        "worksheet2 = spreadsheet.get_worksheet(1)\n",
        "\n",
        "def get_color(curr_value, prev_value):\n",
        "    if curr_value < 0.6 * prev_value:\n",
        "        return {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6}  # very green\n",
        "    elif curr_value < prev_value:\n",
        "        return {\"red\": 0.8, \"green\": 1.0, \"blue\": 0.8}  # green\n",
        "    elif curr_value > 1.4 * prev_value:\n",
        "        return {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6}  # very red\n",
        "    elif curr_value > prev_value:\n",
        "        return {\"red\": 1.0, \"green\": 0.8, \"blue\": 0.8}  # red\n",
        "    return None\n",
        "\n",
        "def write_to_sheet(worksheet, row_data, output_mode=0, compare=False):\n",
        "    # Append the new row to the sheet\n",
        "    try:\n",
        "        worksheet.append_row(row_data)\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        print(f\"Row data: {row_data}\")\n",
        "    # Format colour according to the comparing results\n",
        "    if compare:\n",
        "        pre_row_index = -2\n",
        "        if (output_mode == 2): pre_row_index = -18\n",
        "        sheet_data = worksheet.get_all_values()\n",
        "        last_row_index = len(sheet_data)\n",
        "        if last_row_index > 1:\n",
        "            last_row = sheet_data[-1]\n",
        "            prev_row = sheet_data[pre_row_index]\n",
        "            for col_index, (curr_value, prev_value) in enumerate(zip(last_row, prev_row), start=1):\n",
        "                try:\n",
        "                    curr_value = float(curr_value)\n",
        "                    prev_value = float(prev_value)\n",
        "                    if (worksheet.row_values(1)[col_index-1] == \"est median\"):\n",
        "                      prev_value = abs(true_med - prev_value)\n",
        "                      curr_value = abs(true_med - curr_value)\n",
        "                    color = get_color(curr_value, prev_value)\n",
        "                    if color:\n",
        "                        worksheet.format(f\"{chr(64 + col_index)}{last_row_index}\", {\"backgroundColor\": color})\n",
        "                except:\n",
        "                    continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "202456b3",
      "metadata": {
        "id": "202456b3"
      },
      "outputs": [],
      "source": [
        "def discretize(D, b):\n",
        "    n = len(D)\n",
        "    discreteD = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        discreteD[i] = int(D[i]/b)\n",
        "    return discreteD\n",
        "\n",
        "def discrete(D):\n",
        "    n = len(D)\n",
        "    newD = np.zeros(n)\n",
        "    previous = -1\n",
        "    for i in range(n):\n",
        "        if D[i]!=previous:\n",
        "            newD[i] = n*D[i]\n",
        "            #print(newD[i])\n",
        "            previous = D[i]\n",
        "        elif D[i]==previous:\n",
        "            newD[i] = newD[i-1]+1\n",
        "\n",
        "    return newD\n",
        "\n",
        "def count(D, a):\n",
        "    counter = 0\n",
        "    n = len(D)\n",
        "    low = 0\n",
        "    up=n-1\n",
        "    mid = int((low+up)/2)\n",
        "    while True:\n",
        "        if D[mid]>a:\n",
        "            up=mid\n",
        "            mid = int((low+up)/2)\n",
        "        if D[mid]<a:\n",
        "            low=mid\n",
        "            mid = int((low+up)/2)\n",
        "        if D[mid]==a:\n",
        "            i=0\n",
        "            while D[mid+i]==a:\n",
        "                i+=1\n",
        "            return mid+i\n",
        "\n",
        "def clip(D, a, b):\n",
        "    clipped = copy.deepcopy(D)\n",
        "    clipped[clipped<a] = a\n",
        "    clipped[clipped>b] = b\n",
        "    return clipped\n",
        "\n",
        "def LapNoise():\n",
        "    a = random.uniform(0,1)\n",
        "    b = math.log(1/(1-a))\n",
        "    c = random.uniform(0,1)\n",
        "    if c>0.5:\n",
        "        return b\n",
        "    else:\n",
        "        return -b\n",
        "\n",
        "def F(x):\n",
        "    return 1/2+1/(4*math.pi)*(math.log(abs(2*x**2+2*math.sqrt(2)*x+2)/abs(abs(2*x**2-2*math.sqrt(2)*x+2)))+2*math.atan(math.sqrt(2)*x+1)+2*math.atan(math.sqrt(2)*x-1))\n",
        "def inver_F(y):\n",
        "    #find the solution of F(x)=y\n",
        "    #Find between -1000000 and 1000000 because F(1000000)=1.0 in python\n",
        "    if y>1/2:\n",
        "        low =0.0\n",
        "        high = 1000000.0\n",
        "        mid = (high+low)/2\n",
        "        while abs(high-low)>0.0000001:\n",
        "            if F(mid)>y:\n",
        "                high=mid\n",
        "            elif F(mid)==y:\n",
        "                return mid\n",
        "            else:\n",
        "                low = mid\n",
        "            mid = (high+low)/2\n",
        "\n",
        "        return high\n",
        "    if y==1/2:\n",
        "        return 0\n",
        "\n",
        "def CauchyNoise():\n",
        "    a = random.uniform(0.5,1)\n",
        "    b = inver_F(a)\n",
        "    c = random.uniform(0,1)\n",
        "    if c>0.5:\n",
        "        return b\n",
        "    else:\n",
        "        return -b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "531be4b4",
      "metadata": {
        "id": "531be4b4"
      },
      "outputs": [],
      "source": [
        "# Their algorithm\n",
        "def constructu(eps, a,b, D):\n",
        "    # global u\n",
        "    # global l\n",
        "    # global weight\n",
        "    #[a,b] denotes range\n",
        "    n = len(D)\n",
        "\n",
        "    u = np.zeros(n+2)#utility score\n",
        "    l = np.zeros(n+2)#corresponding data\n",
        "    l[0] = a\n",
        "    for i in range(n+1): #i=rank-1\n",
        "        if i<=int(n/2):\n",
        "            u[i] = -int(n/2)-1+i\n",
        "            l[i+1]= D[i]\n",
        "        #u[int(n/2+1)] = 0\n",
        "        #l[int(n/2+2)] = D[int(n/2)]\n",
        "        if i>int(n/2):\n",
        "            u[i] = int(n/2)+1-i\n",
        "            l[i]= D[i-1]\n",
        "\n",
        "    l[n+1] = b\n",
        "    u[n+1] = -n-1-u[0]\n",
        "    weight = []\n",
        "    # l[i] corresponds to data in D with rank i\n",
        "    for i in range(int(n/2)+1): # weight[0...n/2]\n",
        "        weight.append((l[i+1]-l[i])*math.pow(np.e, eps*u[i]/2)) #weight[i]=(l[i+1]-l[i])...\n",
        "        # if (i == int(n/2)): print(l[i+1],l[i],u[i])\n",
        "    weight.append(1) # weight[n/2+1] = 1??\n",
        "    for i in range(int(n/2)+1,n+1): #weight[n/2+2..n+1]\n",
        "        weight.append((l[i]-l[i-1])*math.pow(np.e, eps*u[i]/2)) #weight[i+1]=(l[i]-l[i-1])...\n",
        "        # if (i == int(n/2)+1): print(l[i],l[i-1],u[i])\n",
        "    # worksheet.append_row(weight)\n",
        "    totalWeight = sum(weight)\n",
        "    weight = weight/totalWeight\n",
        "    # df['Their weights'] = weight\n",
        "    # df[\"Their u\"] = list(u)\n",
        "    return u, l, weight\n",
        "\n",
        "def EMMedian_new(l,weight):\n",
        "    i = np.random.choice(list(range(len(l))), p=weight)\n",
        "    # only return int\n",
        "    if i==int(n/2)+1:\n",
        "        return int(l[i]/n)\n",
        "    if i<int(n/2)+1:\n",
        "        return int(np.random.randint(l[i], l[i+1],dtype=np.int64) / n)\n",
        "    if i>int(n/2)+1:\n",
        "        return int(np.random.randint(l[i-1], l[i],dtype=np.int64) / n)\n",
        "\n",
        "def constructu_CI(eps, beta, N, u, l):\n",
        "    # global u1\n",
        "    # global weight1\n",
        "    # global u2\n",
        "    # global weight2\n",
        "    # global factor\n",
        "\n",
        "    factor = int(8/eps*np.log(4*n*N/beta))\n",
        "    print(\"factor is \"+str(factor))\n",
        "    #u1: left util\n",
        "    #u2: right util\n",
        "    u1 = np.zeros(n+2)\n",
        "    u2 = np.zeros(n+2)\n",
        "    for i in range(n+2):\n",
        "        if i<=int(n/2)+1:\n",
        "            u1[i] = -abs(u[i]+factor)\n",
        "            u2[i] = u[i]-factor\n",
        "        else:\n",
        "            u1[i] = u[i]-factor\n",
        "            u2[i] = -abs(u[i]+factor)\n",
        "\n",
        "    idx = int(n/2)+1-factor\n",
        "    weight1 = []\n",
        "    for i in range(idx):\n",
        "        weight1.append((l[i+1]-l[i])*math.pow(np.e, eps*u1[i]/4))\n",
        "    weight1.append(1)\n",
        "    for i in range(idx,n+1):\n",
        "        weight1.append((l[i]-l[i-1])*math.pow(np.e, eps*u1[i]/4))\n",
        "    totalWeight1 = sum(weight1)\n",
        "    weight1 = weight1/totalWeight1\n",
        "\n",
        "    idx = int(n/2)+1+factor\n",
        "    idx = min(int(n/2)+1+factor,n+1)\n",
        "    weight2 = []\n",
        "    for i in range(idx):\n",
        "        weight2.append((l[i+1]-l[i])*math.pow(np.e, eps*u2[i]/4))\n",
        "    weight2.append(1)\n",
        "    for i in range(idx,n+1):\n",
        "        weight2.append((l[i]-l[i-1])*math.pow(np.e, eps*u2[i]/4))\n",
        "\n",
        "    totalWeight2 = sum(weight2)\n",
        "    weight2 = weight2/totalWeight2\n",
        "    return u1,weight1,u2,weight2,factor\n",
        "\n",
        "def EMMedianCI(l,weight,weight1, weight2,factor):\n",
        "    i1 = np.random.choice(list(range(len(l))), p=weight1)\n",
        "    if i1==int(n/2)+1-factor:\n",
        "        x1= int(l[i1]/n)\n",
        "    if i1<int(n/2)+1-factor:\n",
        "        x1= int(np.random.randint(l[i1], l[i1+1],dtype=np.int64)/n)\n",
        "    if i1>int(n/2)+1-factor:\n",
        "        x1= int(np.random.randint(l[i1-1], l[i1],dtype=np.int64)/n)\n",
        "\n",
        "    i2 = np.random.choice(list(range(len(l))), p=weight2)\n",
        "    if i2==int(n/2)+1+factor:\n",
        "        x2= int(l[i2]/n)\n",
        "    if i2<int(n/2)+1+factor:\n",
        "        x2= int(np.random.randint(l[i2], l[i2+1],dtype=np.int64)/n)\n",
        "    if i2>int(n/2)+1+factor:\n",
        "        x2= int(np.random.randint(l[i2-1], l[i2],dtype=np.int64)/n)\n",
        "\n",
        "    est = EMMedian_new(l,weight)\n",
        "    indicator=0\n",
        "    if D[int(n/2)]<=x2 and D[int(n/2)]>=x1:\n",
        "        indicator=1\n",
        "\n",
        "    return x1,x2 ,indicator,est"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eps = []\n",
        "beta = []\n",
        "D = []\n",
        "newD = []\n",
        "domain_size = 4000\n",
        "num_repeat = 100\n",
        "b_list_step = 1\n"
      ],
      "metadata": {
        "id": "iYqaj0NLo-tw"
      },
      "id": "iYqaj0NLo-tw",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5cdd1c06",
      "metadata": {
        "id": "5cdd1c06"
      },
      "outputs": [],
      "source": [
        "# Our algorithm\n",
        "#1) Learn noisy median o of distribution using Exponential Mechanism\n",
        "def EM_median(eps,beta,D,domain_size):\n",
        "    #print(\"Results for EM, beta = \"+str(beta) + \", epsilon = \" + str(eps))\n",
        "    interval_prob = []\n",
        "    vals, counts = np.unique(D,return_counts=True)\n",
        "    # for i in range(len(counts)):\n",
        "    #   if (counts[i] != 1): print(\"!=1:\",vals[i],counts[i])\n",
        "    rank = 0\n",
        "    lowest = D[0] #new! same as min(D),since D is sorted\n",
        "    vals = [lowest-1] + vals.tolist()\n",
        "    # print(\"vals:\",vals)\n",
        "    cdf = 0.0\n",
        "    rank_dict = {}\n",
        "    weights = []\n",
        "    weight_each = []\n",
        "    u = []\n",
        "    n = len(D)\n",
        "    for i in range(1,len(vals)):\n",
        "        rank += counts[i-1]\n",
        "        # print(vals[i],rank)\n",
        "        rank_dict[vals[i]] = rank\n",
        "        utility = -1.0* np.abs(rank - (n/2))\n",
        "        u.append(utility)\n",
        "        p = (vals[i] - vals[i-1])* math.pow(np.e, eps*utility/2)\n",
        "        cdf += p\n",
        "        weights.append(p)\n",
        "        if use_discretized == 0:\n",
        "          for j in range(counts[i-1]-1):\n",
        "            weights.append(0)\n",
        "            u.append(0)\n",
        "        interval_prob.append(cdf)\n",
        "    # print(\"our weight len\",len(weight))\n",
        "    rand_val = cdf * np.random.uniform(0,1)\n",
        "    rank_o = 0\n",
        "    # print(\"total weights:\",sum(weights))\n",
        "    total_weights = sum(weights)\n",
        "    weights = [w/total_weights for w in weights]\n",
        "    # print(\"meidan weight:\",weights[1999])\n",
        "    if (use_discretized == 0):\n",
        "      weight_name = 'our weights'\n",
        "      u_name = 'our u'\n",
        "    else:\n",
        "      weight_name = 'our weights(discre)'\n",
        "      u_name = 'our u(discre)'\n",
        "    # df[weight_name] = weights+[0,0]\n",
        "    # df[u_name] = u+[0,0]\n",
        "\n",
        "    for i in range(0,len(vals)):\n",
        "        # print(\"--------(\",vals[i],vals[i+1],\"]---------\")\n",
        "        # for j in range(1, 20):\n",
        "        #   print(int(np.random.randint(vals[i]+1, vals[i+1]+1,dtype=np.int64)))\n",
        "        if rand_val <= interval_prob[i]:\n",
        "          sens = 1\n",
        "          ci = (2 * sens / eps) * (np.log(domain_size / beta))\n",
        "          # o = np.random.uniform(vals[i-1],vals[i])\n",
        "          o = int(np.random.randint(vals[i]+1, vals[i+1]+1,dtype=np.int64)) # new\n",
        "          # print(\"i:\", i, \"vals[i-1]:\", vals[i-1],\"vals[i]:\",vals[i])\n",
        "          rank_o = rank_dict[vals[i]]\n",
        "          # print(\"rank_o:\",rank_o,\"vals[i] and vals[i+1]\",vals[i],vals[i+1])\n",
        "          break\n",
        "    return o,rank_o,rank_dict\n",
        "\n",
        "#2)\n",
        "def find_rank(rank_dict,val):\n",
        "    ranks = list(rank_dict.values())\n",
        "    keys = list(rank_dict.keys())\n",
        "    output = 0\n",
        "    for i in range(len(ranks)-1):\n",
        "        if val < keys[i+1]:\n",
        "            output = ranks[i]\n",
        "            break\n",
        "    #print(rank_dict[output])\n",
        "    return output#int(output)\n",
        "\n",
        "\n",
        "def SVT_median(o,rank_o,rank_dict,eps,D,domain_size,T,b_list):\n",
        "    # print(\"T: \", T)\n",
        "    noisy_T = T + np.random.laplace(2/eps)\n",
        "    sensitivity = 1\n",
        "    bounds = domain_size\n",
        "\n",
        "    for b in b_list: #range(0,b_max,step):\n",
        "        perturbed_value = min(abs(find_rank(rank_dict, o+b)-rank_o),abs(find_rank(rank_dict, o-b)-rank_o)) + np.random.laplace(2*sensitivity/eps)\n",
        "        # print(min(abs(find_rank(rank_dict, o+b)-rank_o),abs(find_rank(rank_dict, o-b)-rank_o)))\n",
        "        if perturbed_value > noisy_T:\n",
        "            bounds = b\n",
        "            break\n",
        "    #print(max(o-bounds,0))\n",
        "    #print(min(o+bounds,domain_size-1))\n",
        "    # print(perturbed_value)\n",
        "    result = max(o-bounds,0),min(o+bounds,domain_size-1)\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "def Their_EMMedian_modified(l,weight,D):\n",
        "    vals, counts = np.unique(D,return_counts=True)\n",
        "    rank_dict = {}\n",
        "    rank = 0\n",
        "    vals = [0.0] + vals.tolist()\n",
        "    for i in range(1,len(vals)):\n",
        "        rank += counts[i-1]\n",
        "        rank_dict[vals[i]] = rank\n",
        "    i = np.random.choice(list(range(len(l))), p=weight)\n",
        "    # only return int\n",
        "    val = 0\n",
        "    if i==int(n/2)+1:\n",
        "      val = int(l[i])\n",
        "    if i<int(n/2)+1:\n",
        "      val = int(np.random.randint(l[i], l[i+1],dtype=np.int64))\n",
        "    if i>int(n/2)+1:\n",
        "      val = int(np.random.randint(l[i-1], l[i],dtype=np.int64))\n",
        "      i=i-1\n",
        "    return val,i,rank_dict #rank_dict is from global variable\n",
        "\n",
        "##### main function ######\n",
        "\n",
        "def our_CI(D,domain_size,b_list,med_method=0,l=[],weight=[]):\n",
        "    C = (2/eps_1) *(np.log(domain_size/beta_1))\n",
        "    m = len(b_list)\n",
        "    alpha = (8*np.log(m)+np.log(2/beta_2)) / eps_2\n",
        "    #print(\"C\", C)\n",
        "    #print(\"alpha\", alpha)\n",
        "    T = C + alpha\n",
        "    if (med_method==1):\n",
        "      o,rank_o,rank_dict = Their_EMMedian_modified(l,weight,D) #their EM\n",
        "    else:\n",
        "      o,rank_o,rank_dict = EM_median(eps_1,beta_1,D,domain_size) #our EM\n",
        "    # print(\"o and rank_o:\",o,rank_o)\n",
        "    lower,upper = SVT_median(o,rank_o,rank_dict,eps_2,D,domain_size,T,b_list)\n",
        "    #print(\"median:\",o)\n",
        "    #print(\"The bounds are:\")\n",
        "    #print('[{},{}]'.format(lower,upper))\n",
        "    indi = -1 #if CI contains true med\n",
        "    if (use_discretized == 1):\n",
        "      lower,upper = lower/n,upper/n\n",
        "      o /= n\n",
        "    if true_med < upper and true_med > lower:\n",
        "        indi = 1\n",
        "    else:\n",
        "        indi = 0\n",
        "\n",
        "    return lower,upper,indi,o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c742116c",
      "metadata": {
        "id": "c742116c"
      },
      "outputs": [],
      "source": [
        "def test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,compare = False,output=[],med_method = 0,name=\"\"):\n",
        "  # med_method: 0 use our EM\n",
        "  #      : 1 use their EM (use_discretized must = 1)\n",
        "  domain_size = int(max(D)-min(D))\n",
        "  if (use_discretized == 1):\n",
        "    b_list = range(0, domain_size, int(b_list_step*n))\n",
        "    if (med_method == 1):\n",
        "      rad = 10000000\n",
        "      left = -rad\n",
        "      u,l,weight=constructu(eps_1,left*n,rad*n, D)\n",
        "  else:\n",
        "    b_list = range(0, domain_size, b_list_step)\n",
        "\n",
        "  len_eps = []\n",
        "  err_eps = []\n",
        "  est_median = []\n",
        "  times = []\n",
        "  ranks = []\n",
        "  lengths = []\n",
        "  errors = []\n",
        "  rank_errors_1 = [] # based on n/2\n",
        "  rank_errors_2 = [] # based on find_rank(rank_dict,true_med)\n",
        "  # est_list = []\n",
        "  med_rank = int(find_rank(rank_dict, true_med))\n",
        "  for i in range(len(beta)):\n",
        "      print(\"Results for EM based median, beta = \"+str(beta[i]))\n",
        "      correct_count = 0\n",
        "\n",
        "      for j in range(num_repeat):\n",
        "          start = time.time()\n",
        "          if med_method == 0:\n",
        "            xl,xr,indi,est = our_CI(D,domain_size,b_list)#EMMedianCI()\n",
        "          else:\n",
        "            xl,xr,indi,est = our_CI(D,domain_size,b_list,med_method,l,weight)\n",
        "          end = time.time()\n",
        "          times.append(end-start)\n",
        "          correct_count+=indi\n",
        "          lengths.append((xr-xl)/(2))\n",
        "\n",
        "          # interesting and subtle difference!\n",
        "          # mid_value = (xr+xl)/2\n",
        "          errors.append(abs(est-true_med))\n",
        "          est_median.append(est)\n",
        "          rank = int(find_rank(rank_dict, est))\n",
        "          ranks.append(rank)\n",
        "          rank_errors_1.append(int(abs(n/2 - rank)))\n",
        "          rank_errors_2.append(int(abs(med_rank - rank)))\n",
        "      original_errors = errors\n",
        "      errors = np.array(errors, dtype=object)\n",
        "      correct_rate = correct_count/num_repeat\n",
        "      avgLength = sum(lengths)/num_repeat\n",
        "      errors.sort()\n",
        "      errorQuantile = errors[int(num_repeat*(1-beta[i]))]\n",
        "      avg_error = np.average(errors)\n",
        "      avgTime = sum(times)/len(times)\n",
        "\n",
        "\n",
        "      # output medians and error\n",
        "\n",
        "      #download errors\n",
        "      # df = pd.DataFrame(errors)\n",
        "      # file_name = f\"data_error.csv\"\n",
        "      # df.to_csv(file_name, index=False, header=False)\n",
        "      # files.download(file_name)\n",
        "\n",
        "      # median_error\n",
        "      if np.all(errors == errors[0]):\n",
        "          stddev_based_avg_err = errors[0]\n",
        "          IQR_based_avg_err = errors[0]\n",
        "      else:\n",
        "          std_dev = np.std(errors)\n",
        "          stddev_based_avg_err = np.average(errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "          q1 = np.percentile(errors, 25)\n",
        "          q3 = np.percentile(errors, 75)\n",
        "          iqr = q3 - q1\n",
        "          lower_bound = q1 - 1.5 * iqr\n",
        "          upper_bound = q3 + 1.5 * iqr\n",
        "          IQR_based_avg_err = np.average(errors[(errors >= lower_bound) & (errors <= upper_bound)])\n",
        "      # rank_error\n",
        "      avg_rank_error_1 = np.average(rank_errors_1)\n",
        "      avg_rank_error_2 = np.average(rank_errors_2)\n",
        "\n",
        "      if name==\"\":\n",
        "        name = \"our_CI\"\n",
        "        if (use_discretized == 1):\n",
        "          name = \"our_CI(discretized)\"\n",
        "          domain_size = int(domain_size/n)\n",
        "          if (med_method == 1): name = \"our_CI(their EM)\"\n",
        "      if (errorQuantile == 0): relative_CI_width = -1\n",
        "      else: relative_CI_width = avgLength / errorQuantile\n",
        "\n",
        "      print(\"estimated median value: \"+ str(np.average(est_median)))\n",
        "      print(\"correct rate = \", correct_rate)\n",
        "      print(\"Average CI length = \"+str(avgLength))\n",
        "      print(\"error quantile is \"+ str(errorQuantile))\n",
        "      print(\"CI length/ error quantile = \"+str(relative_CI_width))\n",
        "      print(\"Average Time to find CI = \" + str(avgTime))\n",
        "\n",
        "\n",
        "      row_data = [\n",
        "          name,\n",
        "          data_uuid,\n",
        "          n,\n",
        "          domain_size, #new\n",
        "          sens,\n",
        "          beta[i],\n",
        "          eps[i],\n",
        "          num_repeat,\n",
        "          true_med,\n",
        "          np.average(est_median),\n",
        "          correct_rate,\n",
        "          avgLength,\n",
        "          errorQuantile,\n",
        "          avg_error,\n",
        "          stddev_based_avg_err,\n",
        "          IQR_based_avg_err,\n",
        "          avg_rank_error_1,\n",
        "          avg_rank_error_2,\n",
        "          relative_CI_width,\n",
        "          avgTime,\n",
        "          b_list_step,\n",
        "          beta_1,\n",
        "          beta_2,\n",
        "          eps_1,\n",
        "          eps_2\n",
        "      ]\n",
        "      if (output_mode == 0 or output_mode == 2):\n",
        "        write_to_sheet(worksheet1, row_data, output_mode=output_mode, compare=compare)\n",
        "\n",
        "      # New! Check all medians and errors\n",
        "      if (output_mode == 1 or output_mode == 2):\n",
        "        sorted_med = sorted(est_median)\n",
        "        est_median.insert(0, \"Our est_median\")\n",
        "        sorted_med.insert(0, \"Sorted Our est_median\")\n",
        "\n",
        "        sorted_errors = sorted(original_errors)\n",
        "        original_errors.insert(0, \"Our errors\")\n",
        "        sorted_errors.insert(0, \"Sorted Our errors\")\n",
        "\n",
        "        sorted_ranks = sorted(ranks)\n",
        "        ranks.insert(0, \"Our ranks\")\n",
        "        sorted_ranks.insert(0, \"Sorted Our ranks\")\n",
        "\n",
        "        sorted_lengths = sorted(lengths)\n",
        "        lengths.insert(0,\"Our CI lengths\")\n",
        "        sorted_lengths.insert (0, \"Sorted Our CI lengths\")\n",
        "\n",
        "        sorted_re_1 = sorted(rank_errors_1)\n",
        "        sorted_re_2 = sorted(rank_errors_2)\n",
        "        rank_errors_1.insert(0, \"Our rank_errors(n/2)\")\n",
        "        rank_errors_2.insert(0, \"Our rank_errors(find)\")\n",
        "        sorted_re_1.insert(0, \"Sorted Our rank_errors(n/2)\")\n",
        "        sorted_re_2.insert(0, \"Sorted Our rank_errors(find)\")\n",
        "\n",
        "\n",
        "        data_uid_row = [\"data:\", data_uuid, \"method:\", \"Our_CI\"]\n",
        "        true_med_row = [\"true median\"]+[true_med]*num_repeat\n",
        "        n_over_2_row = [\"true n/2\"] + [n/2]*num_repeat\n",
        "        med_rank_row = [\"true med_rank(find)\"] + [med_rank]*num_repeat\n",
        "\n",
        "        worksheet.append_row(data_uid_row)\n",
        "        worksheet.append_row(est_median)\n",
        "        worksheet.append_row(true_med_row)\n",
        "        worksheet.append_row(original_errors)\n",
        "        # write_to_sheet(worksheet1, errors, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(ranks)\n",
        "        worksheet.append_row(n_over_2_row)\n",
        "        worksheet.append_row(rank_errors_1)\n",
        "        # write_to_sheet(worksheet1, rank_errors_1, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(med_rank_row)\n",
        "        worksheet.append_row(rank_errors_2)\n",
        "        worksheet.append_row(lengths)\n",
        "\n",
        "        # write_to_sheet(worksheet1, rank_errors_2, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(sorted_med)\n",
        "        worksheet.append_row(sorted_ranks)\n",
        "        worksheet.append_row(sorted_errors)\n",
        "        worksheet.append_row(sorted_re_1)\n",
        "        worksheet.append_row(sorted_re_2)\n",
        "        worksheet.append_row(sorted_lengths)\n",
        "\n",
        "      len_eps.append(avgLength)\n",
        "      err_eps.append(errorQuantile)\n",
        "      print(len_eps)\n",
        "      print(err_eps)\n",
        "      if (output_mode == 3):\n",
        "        output = row_data\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "490b3cbd",
      "metadata": {
        "id": "490b3cbd"
      },
      "outputs": [],
      "source": [
        "def test_theirs(eps=eps, beta=beta, num_repeat=num_repeat, D=newD,median_method = 0,compare = False,output=[]):\n",
        "  #median_method = 0:median from CI algorithm\n",
        "  #        = 1:median from EMMedianCI\n",
        "  n = len(newD)\n",
        "  domain_size = int((max(D)-min(D))/n)\n",
        "  len_eps = []\n",
        "  err_eps = []\n",
        "  est_median = []\n",
        "  times = []\n",
        "  ranks = []\n",
        "  EM_median_errors = []\n",
        "  med_rank = int(find_rank(rank_dict, true_med))\n",
        "  est_list = []\n",
        "  rank_errors_1 = [] # based on n/2\n",
        "  rank_errors_2 = [] # based on find_rank(rank_dict,true_med)\n",
        "  for i in range(len(beta)):\n",
        "      print(\"Results for EM based median, beta = \"+str(beta[i]))\n",
        "      errors = []\n",
        "      lengths = []\n",
        "      correct_count = 0\n",
        "      rad = 10000000\n",
        "      left=-rad\n",
        "      u,l,weight = constructu(eps[i], left*n,rad*n, newD)\n",
        "      u1,weight1,u2,weight2,factor = constructu_CI(eps[i],beta[i], rad,u,l)\n",
        "      for j in range(num_repeat):\n",
        "          start = time.time()\n",
        "          xl,xr,indi,est = EMMedianCI(l,weight,weight1,weight2,factor)\n",
        "          end = time.time()\n",
        "          times.append(end-start)\n",
        "          correct_count+=indi\n",
        "          lengths.append((xr-xl)/(2))\n",
        "          if (median_method == 0):\n",
        "            their_median = (xr+xl)/2\n",
        "          else:\n",
        "            their_median = est\n",
        "          est_median.append(their_median)\n",
        "          errors.append(abs(their_median-true_med))\n",
        "          EM_median_errors.append(abs(est-true_med)) # their def of errors\n",
        "          rank = int(find_rank(rank_dict, their_median))\n",
        "          ranks.append(rank)\n",
        "          rank_errors_1.append(int(abs(n/2 - rank)))\n",
        "          rank_errors_2.append(int(abs(med_rank - rank)))\n",
        "\n",
        "      original_errors = errors\n",
        "      errors = np.array(errors, dtype=object)\n",
        "      correct_rate = correct_count/num_repeat\n",
        "      avgLength = sum(lengths)/num_repeat\n",
        "      errors.sort()\n",
        "      errorQuantile = errors[int(num_repeat*(1-beta[i]))]\n",
        "\n",
        "      avgTime = sum(times)/len(times)\n",
        "\n",
        "\n",
        "      errors = np.array(errors)\n",
        "      avg_error = np.average(errors)\n",
        "      if (errorQuantile == 0): relative_CI_width = -1\n",
        "      else: relative_CI_width = avgLength / errorQuantile\n",
        "      if np.all(errors == errors[0]):\n",
        "          stddev_based_avg_err = errors[0]\n",
        "          IQR_based_avg_err = errors[0]\n",
        "      else:\n",
        "          std_dev = np.std(errors)\n",
        "          stddev_based_avg_err = np.average(errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "\n",
        "          q1 = np.percentile(errors, 25)\n",
        "          q3 = np.percentile(errors, 75)\n",
        "          iqr = q3 - q1\n",
        "          lower_bound = q1 - 1.5 * iqr\n",
        "          upper_bound = q3 + 1.5 * iqr\n",
        "          IQR_based_avg_err = np.average(errors[(errors >= lower_bound) & (errors <= upper_bound)])\n",
        "\n",
        "      #rank_avg\n",
        "      avg_rank_error_1 = np.average(rank_errors_1)\n",
        "      avg_rank_error_2 = np.average(rank_errors_2)\n",
        "      print(\"Filtered Errors for IQR_based_avg_err:\", IQR_based_avg_err)\n",
        "\n",
        "      print(\"estimated median value: \"+ str(np.average(est_median)))\n",
        "      print(\"correct rate = \" +str(correct_count/num_repeat))\n",
        "      print(\"Average CI length = \"+str(avgLength))\n",
        "      print(\"error quantile is \"+ str(errorQuantile))\n",
        "      print(\"CI length/ error quantile = \"+str(avgLength/errorQuantile))\n",
        "      print(\"Average Time to find CI = \" + str(sum(times)/len(times)))\n",
        "      # print(\"Errors:\", errors)\n",
        "      # print(\"Standard Deviation:\", std_dev)\n",
        "      # print(\"Filtered Errors for stddev_based_avg_err:\", errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "\n",
        "      # print(\"Q1:\", q1, \"Q3:\", q3)\n",
        "      # print(\"IQR:\", iqr)\n",
        "      # print(\"Lower Bound:\", lower_bound, \"Upper Bound:\", upper_bound)\n",
        "      if (median_method == 0):\n",
        "        name = \"EM_CI\"\n",
        "      else:\n",
        "        name = \"EM\"\n",
        "      row_data = [\n",
        "          name,\n",
        "          data_uuid,\n",
        "          n,\n",
        "          domain_size, #3\n",
        "          sens, #4\n",
        "          beta[i],#5\n",
        "          eps[i], #6\n",
        "          num_repeat, #7\n",
        "          true_med, #8\n",
        "          np.average(est_median), #9\n",
        "          correct_rate, #10\n",
        "          avgLength, #11\n",
        "          errorQuantile, #12\n",
        "          avg_error,#13\n",
        "          stddev_based_avg_err, #14\n",
        "          IQR_based_avg_err, #15\n",
        "          avg_rank_error_1, #16\n",
        "          avg_rank_error_2, #17\n",
        "          relative_CI_width, #18\n",
        "          avgTime\n",
        "      ]\n",
        "      if (output_mode == 0 or output_mode == 2):\n",
        "        write_to_sheet(worksheet1, row_data, compare = compare)\n",
        "\n",
        "      if (output_mode == 1 or output_mode == 2):\n",
        "        sorted_med = sorted(est_median)\n",
        "        est_median.insert(0, \"EM est_median\")\n",
        "        sorted_med.insert(0, \"Sorted EM est_median\")\n",
        "\n",
        "        sorted_errors = sorted(original_errors)\n",
        "        original_errors.insert(0, \"EM errors\")\n",
        "        sorted_errors.insert(0, \"Sorted EM errors\")\n",
        "\n",
        "        sorted_ranks = sorted(ranks)\n",
        "        ranks.insert(0, \"EM ranks\")\n",
        "        sorted_ranks.insert(0, \"Sorted EM ranks\")\n",
        "\n",
        "        sorted_re_1 = sorted(rank_errors_1)\n",
        "        sorted_re_2 = sorted(rank_errors_2)\n",
        "        rank_errors_1.insert(0, \"EM rank_errors(n/2)\")\n",
        "        rank_errors_2.insert(0, \"EM rank_errors(find)\")\n",
        "        sorted_re_1.insert(0, \"Sorted EM rank_errors(n/2)\")\n",
        "        sorted_re_2.insert(0, \"Sorted EM rank_errors(find)\")\n",
        "\n",
        "        sorted_lengths = sorted(lengths)\n",
        "        lengths.insert(0,\"EM CI lengths\")\n",
        "        sorted_lengths.insert (0, \"Sorted EM CI lengths\")\n",
        "\n",
        "        data_uid_row = [\"data:\", data_uuid, \"method:\", \"EM_CI\"]\n",
        "        true_med_row = [\"true median\"]+[true_med]*num_repeat\n",
        "        n_over_2_row = [\"true n/2\"] + [n/2]*num_repeat\n",
        "        med_rank_row = [\"true med_rank(find)\"] + [med_rank]*num_repeat\n",
        "\n",
        "        print(est_list)\n",
        "        worksheet.append_row(data_uid_row)\n",
        "        worksheet.append_row(est_median)\n",
        "        worksheet.append_row(true_med_row)\n",
        "\n",
        "        worksheet.append_row(original_errors)\n",
        "        # write_to_sheet(worksheet1, original_errors, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(ranks)\n",
        "        worksheet.append_row(n_over_2_row)\n",
        "        worksheet.append_row(rank_errors_1)\n",
        "        # write_to_sheet(worksheet1, rank_errors_1, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(med_rank_row)\n",
        "        worksheet.append_row(rank_errors_2)\n",
        "        worksheet.append_row(lengths)\n",
        "        # write_to_sheet(worksheet1, rank_errors_2, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(sorted_med)\n",
        "        worksheet.append_row(sorted_ranks)\n",
        "        worksheet.append_row(sorted_errors)\n",
        "        worksheet.append_row(sorted_re_1)\n",
        "        worksheet.append_row(sorted_re_2)\n",
        "        worksheet.append_row(sorted_lengths)\n",
        "\n",
        "\n",
        "\n",
        "      len_eps.append(avgLength)\n",
        "      err_eps.append(errorQuantile)\n",
        "      print(len_eps)\n",
        "      print(err_eps)\n",
        "      if (output_mode == 3):\n",
        "        output = row_data\n",
        "      return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "-xoDZUe5Or-N",
      "metadata": {
        "id": "-xoDZUe5Or-N"
      },
      "outputs": [],
      "source": [
        "def readInput(mode):\n",
        "    import numpy as np\n",
        "    read_data_uuid = \"64b7c8bf89f14113bd12f5f15e276546\"\n",
        "    file_paths = {\n",
        "        0: (\"./bank_marketing.csv\", 5),\n",
        "        1: (\"./adult.csv\", 2),\n",
        "        2: (\"./sample_data/california_housing_test.csv\", 3),\n",
        "        3: (\"./sample_data/california_housing_test.csv\", 8),\n",
        "        5: (\"./ratings_small.csv\",3),\n",
        "        6: (\"./airplane_price_dataset.csv\",1),\n",
        "        7: (\"./airplane_price_dataset.csv\",2),\n",
        "        8: (\"./airplane_price_dataset.csv\",3),\n",
        "        9: (\"./airplane_price_dataset.csv\",4),\n",
        "        10: (\"./data_\"+read_data_uuid+\".csv\",0),\n",
        "    }\n",
        "\n",
        "    if mode not in file_paths:\n",
        "        raise ValueError(\"Invalid mode. Choose between 0 to 3\")\n",
        "\n",
        "    input_path, column_index = file_paths[mode]\n",
        "\n",
        "    with open(input_path, 'r',errors='ignore') as input_file:\n",
        "        lines = input_file.readlines()\n",
        "    n = len(lines)\n",
        "    # D = np.zeros(n)\n",
        "    D = np.zeros(n-1) #new! there are n-1 data points\n",
        "    for i, line in enumerate(lines):\n",
        "        if i > 0:\n",
        "            elements = line.split(\",\")\n",
        "            try:\n",
        "                value = float(elements[column_index])\n",
        "                D[i - 1] = int(value)\n",
        "            except ValueError:\n",
        "              if (column_index < len(elements)):\n",
        "                print(f\"Skipping invalid data at line {i}: {elements[column_index]}\")\n",
        "    # df = pd.DataFrame()\n",
        "    # df[\"data\"] = list(D)\n",
        "    # df.to_csv(\"data.csv\",index=False)\n",
        "    # files.download(\"data.csv\")\n",
        "    return D\n",
        "\n",
        "def normalize_non_negative(D):\n",
        "  if lowest<0:\n",
        "    D = [d-lowest for d in D]\n",
        "  return D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def color_vertically(worksheet,col=10,smaller_better=True,row_number=4):\n",
        "  # row_number: number of rows you want to colour\n",
        "  # Define the column indices\n",
        "  col_true = 9\n",
        "  values_I = worksheet.col_values(col_true)\n",
        "  values_col = worksheet.col_values(col)\n",
        "\n",
        "  # Extract the last k rows (ensuring they are numeric)\n",
        "  last_4_true = [float(values_I[-row_number + i]) for i in range(row_number)]\n",
        "  last_4_vals = [float(values_col[-row_number + i]) for i in range(row_number)]\n",
        "\n",
        "  if (col==10):\n",
        "    diffs = [abs(last_4_vals[i] - last_4_true[i]) for i in range(row_number)]\n",
        "  else:\n",
        "    diffs = last_4_vals\n",
        "\n",
        "  # Rank differences from smallest to largest\n",
        "  if smaller_better:\n",
        "      sorted_indices = sorted(range(len(diffs)), key=lambda k: diffs[k])\n",
        "  else:\n",
        "      sorted_indices = sorted(range(len(diffs)), key=lambda k: diffs[k], reverse=True)\n",
        "\n",
        "\n",
        "  # Define colors for ranking\n",
        "  colors = [\n",
        "    {\"red\": 0.0, \"green\": 1.0, \"blue\": 0.0},  # Green (best)\n",
        "    {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6},  # Light Green\n",
        "    {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6},  # Light Red\n",
        "    {\"red\": 1.0, \"green\": 0.0, \"blue\": 0.0},  # Red (worst)\n",
        "  ]\n",
        "\n",
        "  # Get the last 4 row indices\n",
        "  base_row = len(values_col) - row_number+1  # First of the last 4 rows (1-based index)\n",
        "\n",
        "  # Apply formatting\n",
        "  for rank, index in enumerate(sorted_indices):\n",
        "    row = base_row + index  # Correct row number\n",
        "    cell = f\"{chr(64 + col)}{row}\"  # Convert column number to letter (J)\n",
        "    worksheet.format(cell, {\"backgroundColor\": colors[rank]})"
      ],
      "metadata": {
        "id": "aV2Tp7gg_Nl8"
      },
      "id": "aV2Tp7gg_Nl8",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def color_horizontally(worksheet,col_n=4):\n",
        "    col_b = 2  # Column B (1-based index)\n",
        "    col_end = 1 + col_n\n",
        "\n",
        "    # Get the last row values from Column B to Column E\n",
        "    last_row = worksheet.row_values(len(worksheet.get_all_values()))\n",
        "    # Convert the values to floats (or int if appropriate)\n",
        "    values_b_to_end = [float(value) for value in last_row[col_b - 1:col_end]]  # Ensure values are numeric\n",
        "\n",
        "    # Define colors for ranking\n",
        "    colors = [\n",
        "        {\"red\": 0.0, \"green\": 1.0, \"blue\": 0.0},  # Green (min)\n",
        "        {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6},  # Light Green (2nd smallest)\n",
        "        {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6},  # Light Red\n",
        "        {\"red\": 1.0, \"green\": 0.0, \"blue\": 0.0},  # Red (max)\n",
        "    ]\n",
        "    if col_n==5:\n",
        "      colors = [\n",
        "        {\"red\": 0.0, \"green\": 1.0, \"blue\": 0.0},  # Green (min)\n",
        "        {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6},  # Light Green (2nd smallest)\n",
        "        {\"red\": 1.0, \"green\": 1.0, \"blue\": 1.0},\n",
        "        {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6},  # Light Red\n",
        "        {\"red\": 1.0, \"green\": 0.0, \"blue\": 0.0},  # Red (max)\n",
        "      ]\n",
        "    # Sort the values and map them to their ranks\n",
        "    sorted_indices = sorted(range(len(values_b_to_end)), key=lambda k: values_b_to_end[k])\n",
        "    rank_map = {sorted_indices[i]: i for i in range(len(sorted_indices))}  # Map index to rank\n",
        "\n",
        "    # Get the column letters for Column B to Column E\n",
        "    columns = ['B', 'C', 'D', 'E']\n",
        "    if col_n==5: columns = ['B', 'C', 'D', 'E', 'F']\n",
        "\n",
        "    # Loop through each value and apply the background color based on its rank\n",
        "    for i, value in enumerate(values_b_to_end):\n",
        "        col_letter = columns[i]  # Get column letter\n",
        "        cell = f\"{col_letter}{len(worksheet.get_all_values())}\"  # Cell reference\n",
        "        rank = rank_map[i]  # Get the rank from the rank map\n",
        "        worksheet.format(cell, {\"backgroundColor\": colors[rank]})\n"
      ],
      "metadata": {
        "id": "ZIngr9znP4Vp"
      },
      "id": "ZIngr9znP4Vp",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "kTEhx4k8KNoQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "kTEhx4k8KNoQ",
        "outputId": "d9df01d0-8024-4525-c92b-f29ed174bce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.11478249e-04 3.55444627e+00 4.59865783e+00 ... 3.99606372e+03\n",
            " 3.99716179e+03 4.00035721e+03]\n",
            "[0.0000e+00 1.2000e+04 1.6000e+04 ... 1.5984e+07 1.5988e+07 1.6000e+07]\n",
            "Data_size: 4000\n",
            "Domain size: 4000\n",
            "true median:  1999.0\n",
            "true median rank: 2000.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bf506ddd-7a6a-44f1-a106-b581ebd5fc59\", \"data_58c67af39a174e0581d7fcf006f949d1.csv\", 26906)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved as data_58c67af39a174e0581d7fcf006f949d1.csv\n"
          ]
        }
      ],
      "source": [
        "# Experiment Data Input\n",
        "\n",
        "dataset_id_dict = {0:\"bank_marketing\", 1:\"adult\", 2:\"cali_housing_test\", 3:\"cali_housing_value\",\n",
        "           5:\"IMDB_time\",6:\"airplane_capacity\",7:\"airplane_range\",8:\"airplane_maintenance\",9:\"airplane_price\",\n",
        "           10: \"old_synthetic_data\"}\n",
        "mode = -1\n",
        "\n",
        "if (mode == -1):\n",
        "  n = 4000  # 45#000\n",
        "  domain_size = 4000  # 40#000\n",
        "  D = np.random.uniform(0, domain_size+1, n)\n",
        "  lowest = 0\n",
        "  highest = domain_size\n",
        "else:\n",
        "  D = readInput(mode)\n",
        "  lowest = int(min(D))\n",
        "  #elinminate negative numbers\n",
        "  # if (lowest < 0):\n",
        "  #   D = normalize_non_negative(D)\n",
        "  #   lowest = 0\n",
        "  highest = int(max(D))\n",
        "  print(\"lowest:\",lowest)\n",
        "\n",
        "n = len(D)\n",
        "domain_size = highest - lowest\n",
        "\n",
        "D.sort()\n",
        "print(D)\n",
        "\n",
        "D = discretize(D, 1)\n",
        "newD = discrete(D)\n",
        "print(newD)\n",
        "true_med = np.median(D)\n",
        "\n",
        "print(\"Data_size:\", n)\n",
        "print(\"Domain size:\", domain_size)\n",
        "\n",
        "print(\"true median: \", true_med)\n",
        "# rank_dict\n",
        "vals, counts = np.unique(D,return_counts=True)\n",
        "rank_dict = {}\n",
        "rank = 0\n",
        "vals = [0.0] + vals.tolist()\n",
        "for i in range(1,len(vals)):\n",
        "    rank += counts[i-1]\n",
        "    rank_dict[vals[i]] = rank\n",
        "print(\"true median rank:\",n/2)\n",
        "\n",
        "\n",
        "\n",
        "# Data Persistence\n",
        "if (mode == -1):\n",
        "  df = pd.DataFrame(D)\n",
        "  data_uuid = uuid.uuid4().hex\n",
        "  file_name = f\"data_{data_uuid}.csv\"\n",
        "  df.to_csv(file_name, index=False, header=False)\n",
        "  files.download(file_name)\n",
        "  print(f\"File saved as {file_name}\")\n",
        "else:\n",
        "  data_uuid = dataset_id_dict[mode]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "G-o_F3TWSUzN",
      "metadata": {
        "id": "G-o_F3TWSUzN"
      },
      "outputs": [],
      "source": [
        "# CI Parameters\n",
        "eps = [1]\n",
        "beta = [0.01]\n",
        "sens = 1 #fixed\n",
        "num_repeat=100\n",
        "\n",
        "# for val, rank in rank_dict.items():\n",
        "#     print(val,\"  \",rank)\n",
        "\n",
        "# Parameters for our_CI\n",
        "beta_1 = 0.5 *beta[0]\n",
        "beta_2 = beta[0] - beta_1\n",
        "# eps_1 = 0.5 * eps[0]\n",
        "# eps_2 = eps[0] - eps_1\n",
        "eps_1 = 0.5 * eps[0]\n",
        "eps_2 = eps[0] - eps_1\n",
        "\n",
        "\n",
        "b_list_step = 1\n",
        "if mode == 1: b_list_step = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ZZKk-CjfKeLU",
      "metadata": {
        "id": "ZZKk-CjfKeLU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "8de9d36b-9954-4d8b-b9a9-34631089fcda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for EM based median, beta = 0.01\n",
            "factor is 60\n",
            "Filtered Errors for IQR_based_avg_err: 5.303030303030303\n",
            "estimated median value: 1941.76\n",
            "correct rate = 1.0\n",
            "Average CI length = 67.11\n",
            "error quantile is 9.5\n",
            "CI length/ error quantile = 7.064210526315789\n",
            "Average Time to find CI = 0.001182687282562256\n",
            "[67.11]\n",
            "[9.5]\n",
            "-------------------EMCI Test Done--------------------\n",
            "Results for EM based median, beta = 0.01\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-b71814593f41>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0muse_discretized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtest_ours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_list_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_list_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_repeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_repeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0moptimized_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0meps_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mtest_ours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_list_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimized_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_repeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_repeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"our_CI(opt)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-d3772df52bb8>\u001b[0m in \u001b[0;36mtest_ours\u001b[0;34m(b_list_step, eps, beta, num_repeat, D, compare, output, med_method, name)\u001b[0m\n\u001b[1;32m     30\u001b[0m           \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mmed_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mxl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mour_CI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdomain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#EMMedianCI()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mxl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mour_CI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdomain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmed_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d99500eeb07b>\u001b[0m in \u001b[0;36mour_CI\u001b[0;34m(D, domain_size, b_list, med_method, l, weight)\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrank_o\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrank_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTheir_EMMedian_modified\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#their EM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m       \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrank_o\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrank_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEM_median\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdomain_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#our EM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;31m# print(\"o and rank_o:\",o,rank_o)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVT_median\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrank_o\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrank_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdomain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d99500eeb07b>\u001b[0m in \u001b[0;36mEM_median\u001b[0;34m(eps, beta, D, domain_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mutility\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mcdf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Test both\n",
        "\n",
        "# output_mode 0:experiment results,\n",
        "#        1:medians&ranks, CI legnths\n",
        "#        2:both\n",
        "#        3:return row_result and do not write to google spreadsheet\n",
        "\n",
        "# EM_mode  0: use our original EM\n",
        "#       1: use our original EM with discretized data\n",
        "#       2: use their EM with discretized data\n",
        "\n",
        "output_mode = 0\n",
        "download = 0\n",
        "df = pd.DataFrame()\n",
        "# df[\"rank\"] = list(range(1,len(D)+1)) + [0,0]\n",
        "# df[\"data\"] = list(D)+ [0,0]\n",
        "# df[\"discretized_data\"] = list(newD) + [0,0]\n",
        "\n",
        "# test_theirs(eps=[0.5], beta=beta, num_repeat=num_repeat,median_method=1,D=newD) #test EM\n",
        "test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=0,D=newD) #test EM_CI\n",
        "\n",
        "print(\"-------------------EMCI Test Done--------------------\")\n",
        "\n",
        "if output_mode==2:\n",
        "  print(\"wait for 60 secs for the Second Test\")\n",
        "  time.sleep(60)\n",
        "\n",
        "use_discretized = 0\n",
        "test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,compare = False)\n",
        "optimized_step = int(8/eps_2)\n",
        "test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,compare = False,name=\"our_CI(opt)\")\n",
        "# use_discretized = 1\n",
        "# test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,compare = False,med_method=1)\n",
        "# test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,compare = False,med_method=0)\n",
        "print(\"-------------------ourCI Test Done--------------------\")\n",
        "\n",
        "# if (output_mode != 3):`\n",
        "#   color_vertically(worksheet,col=10,row_number=4) #est_median\n",
        "#   color_vertically(worksheet,col=14,row_number=4) #avg error\n",
        "#   color_vertically(worksheet,col=12,row_number=4) #avgCI_length\n",
        "\n",
        "# Result Persistence\n",
        "csv_name = \"weight\"+data_uuid\n",
        "df.to_csv(csv_name+\".csv\",index=False)\n",
        "if (download == 1):\n",
        "  files.download(csv_name+\".csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test median\n",
        "output_mode = 3\n",
        "return_index = 13\n",
        "experiment_target = \"Avg Median Error\"\n",
        "column1_title = \"eps\"\n",
        "\n",
        "worksheet.append_row([data_uuid,\"domain_size:\"+str(domain_size),\"n:\"+str(n),experiment_target])\n",
        "worksheet.append_row([column1_title,\"EM\",\"EM_CI\",\"our_CI\",\"our_CI(discretized)\"])\n",
        "eps_list = [0.125,0.25,0.5,1,2,4] #\n",
        "df = pd.DataFrame()\n",
        "b_list_step = 1\n",
        "for eps_val in eps_list:\n",
        "  eps = [eps_val]\n",
        "  print(\"---------Runing eps:\"+str(eps_val)+\"---------\")\n",
        "  EMCI_output = test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=0,D=newD)[return_index] #test EM_CI\n",
        "  eps_1 = 0.5 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  use_discretized = 0\n",
        "  ourCI_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,compare = True)[return_index]\n",
        "  use_discretized = 1\n",
        "  ourCI2_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,compare = True,med_method=1)[return_index]\n",
        "  output_RowData = [eps_val, EM_output,EMCI_output,ourCI_output,ourCI2_output]\n",
        "  worksheet.append_row(output_RowData)\n",
        "  color_horizontally(worksheet)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vG3mXgqCLaqS"
      },
      "id": "vG3mXgqCLaqS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72FYc7UozH2c",
      "metadata": {
        "id": "72FYc7UozH2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75844226-495e-45a9-bd3d-e61833106532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------Runing eps:0.25---------\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 972\n",
            "Filtered Errors for IQR_based_avg_err: 10.792553191489361\n",
            "estimated median value: 2004.72\n",
            "correct rate = 1.0\n",
            "Average CI length = 971.35\n",
            "error quantile is 82.5\n",
            "CI length/ error quantile = 11.773939393939393\n",
            "Average Time to find CI = 0.0018765115737915039\n",
            "[971.35]\n",
            "[82.5]\n",
            "Results for EM based median, beta = 0.01\n"
          ]
        }
      ],
      "source": [
        "# Test CI\n",
        "output_mode = 3\n",
        "return_index = 11 # 13 is for avg error\n",
        "experiment_target = \"Avg CI length\"\n",
        "column1_title = \"eps\"\n",
        "b_list_step = 1\n",
        "worksheet.append_row([data_uuid,\"domain_size:\"+str(domain_size),\"n:\"+str(n),experiment_target,\"b_step:\"+str(b_list_step)])\n",
        "worksheet.append_row([column1_title,\"EM_CI\",\"our_CI(b_step)\",\"our_CI(optimized_step)\",\"our_CI(optimized_step+1)\",\"our_CI(optimized_step-1)\"])\n",
        "eps_list = [0.25,0.5,1,2,4]\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for eps_val in eps_list:\n",
        "  eps = [eps_val]\n",
        "  print(\"---------Runing eps:\"+str(eps_val)+\"---------\")\n",
        "  EMCI_output = test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=0,D=newD)[return_index] #EM_CI\n",
        "  eps_1 = 0.5 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  optimized_step = int(8/eps_2)\n",
        "  use_discretized = 0\n",
        "  ourCI_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D)[return_index] #our_CI\n",
        "  ourCI2_output = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D)[return_index]\n",
        "  ourCI3_output = test_ours(b_list_step=optimized_step+1,eps=eps, beta=beta, num_repeat=num_repeat,D=D)[return_index]\n",
        "  ourCI4_output = test_ours(b_list_step=optimized_step-1,eps=eps, beta=beta, num_repeat=num_repeat,D=D)[return_index]\n",
        "  # use_discretized = 1\n",
        "  # ourCI2_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD)[return_index] #our_CI(discretized)\n",
        "  # ourCI3_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,med_method=1)[return_index] #our_CI(their_EM)\n",
        "  output_RowData = [eps_val,EMCI_output,ourCI_output,ourCI2_output,ourCI3_output,ourCI4_output]\n",
        "  worksheet.append_row(output_RowData)\n",
        "  color_horizontally(worksheet,col_n=5)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "color_horizontally(worksheet)"
      ],
      "metadata": {
        "id": "_o2ui9KrPjlM"
      },
      "id": "_o2ui9KrPjlM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GfTJIPHarSAT",
      "metadata": {
        "id": "GfTJIPHarSAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0783b997-7350-4105-930a-0abc001fd8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for EM based median, beta = 0.01\n",
            "estimated median value: 4343.54\n",
            "correct rate =  0.0\n",
            "Average CI length = 0.0\n",
            "error quantile is 2663.0\n",
            "CI length/ error quantile = 0.0\n",
            "Average Time to find CI = 0.009568204879760742\n",
            "[0.0]\n",
            "[2663.0]\n"
          ]
        }
      ],
      "source": [
        "  output_mode = 0\n",
        "  eps = [1]\n",
        "  eps_1 = 0.5 * eps[0]\n",
        "  eps_2 = eps[0] - eps_1\n",
        "  use_discretized = 0\n",
        "  test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,compare = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dkQZxi1QE90V"
      },
      "id": "dkQZxi1QE90V",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}