{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Timliuw/DP-Tim/blob/main/CI_Tim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cfd74f5f",
      "metadata": {
        "id": "cfd74f5f"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import copy\n",
        "import getopt\n",
        "import psycopg2\n",
        "import sys\n",
        "import time\n",
        "import pandas as pd\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for experiments purpose\n",
        "import gspread\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.service_account import Credentials\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "import os\n",
        "os.listdir()\n",
        "\n",
        "scope = [\n",
        "    \"https://spreadsheets.google.com/feeds\",  # Google Sheets API\n",
        "    \"https://www.googleapis.com/auth/drive\"   # Google Drive API\n",
        "]\n",
        "\n",
        "# Trigger the file upload dialog\n",
        "try:\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(\"sublime-mission-447319-c2-0df1612796a8.json\", scope)\n",
        "except:\n",
        "   uploaded = files.upload()\n",
        "\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(\"sublime-mission-447319-c2-0df1612796a8.json\", scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "spreadsheet = client.open_by_key(\"1yVVt5ACdBbjsZ_7IiRkvPGIHmpKe8mFXcvyL0PVP2cE\")\n",
        "\n",
        "worksheet1 = spreadsheet.get_worksheet(0)\n",
        "worksheet = worksheet1\n",
        "worksheet2 = spreadsheet.get_worksheet(1)\n",
        "\n",
        "def get_color(curr_value, prev_value):\n",
        "    if curr_value < 0.6 * prev_value:\n",
        "        return {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6}  # very green\n",
        "    elif curr_value < prev_value:\n",
        "        return {\"red\": 0.8, \"green\": 1.0, \"blue\": 0.8}  # green\n",
        "    elif curr_value > 1.4 * prev_value:\n",
        "        return {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6}  # very red\n",
        "    elif curr_value > prev_value:\n",
        "        return {\"red\": 1.0, \"green\": 0.8, \"blue\": 0.8}  # red\n",
        "    return None\n",
        "\n",
        "def write_to_sheet(worksheet, row_data, output_mode=0, compare=False):\n",
        "    # Append the new row to the sheet\n",
        "    try:\n",
        "        worksheet.append_row(row_data)\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        print(f\"Row data: {row_data}\")\n",
        "    # Format colour according to the comparing results\n",
        "    if compare:\n",
        "        pre_row_index = -2\n",
        "        if (output_mode == 2): pre_row_index = -16\n",
        "        sheet_data = worksheet.get_all_values()\n",
        "        last_row_index = len(sheet_data)\n",
        "        if last_row_index > 1:\n",
        "            last_row = sheet_data[-1]\n",
        "            prev_row = sheet_data[pre_row_index]\n",
        "            for col_index, (curr_value, prev_value) in enumerate(zip(last_row, prev_row), start=1):\n",
        "                try:\n",
        "                    curr_value = float(curr_value)\n",
        "                    prev_value = float(prev_value)\n",
        "                    if (worksheet.row_values(1)[col_index-1] == \"est median\"):\n",
        "                      prev_value = abs(true_med - prev_value)\n",
        "                      curr_value = abs(true_med - curr_value)\n",
        "                    color = get_color(curr_value, prev_value)\n",
        "                    if color:\n",
        "                        worksheet.format(f\"{chr(64 + col_index)}{last_row_index}\", {\"backgroundColor\": color})\n",
        "                except:\n",
        "                    continue"
      ],
      "metadata": {
        "id": "zfatDYXyr6eo"
      },
      "id": "zfatDYXyr6eo",
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "202456b3",
      "metadata": {
        "id": "202456b3"
      },
      "outputs": [],
      "source": [
        "def discretize(D, b):\n",
        "    n = len(D)\n",
        "    discreteD = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        discreteD[i] = int(D[i]/b)\n",
        "    return discreteD\n",
        "\n",
        "def discrete(D):\n",
        "    n = len(D)\n",
        "    newD = np.zeros(n)\n",
        "    previous = -1\n",
        "    for i in range(n):\n",
        "        if D[i]!=previous:\n",
        "            newD[i] = n*D[i]\n",
        "            #print(newD[i])\n",
        "            previous = D[i]\n",
        "        elif D[i]==previous:\n",
        "            newD[i] = newD[i-1]+1\n",
        "\n",
        "    return newD\n",
        "\n",
        "def count(D, a):\n",
        "    counter = 0\n",
        "    n = len(D)\n",
        "    low = 0\n",
        "    up=n-1\n",
        "    mid = int((low+up)/2)\n",
        "    while True:\n",
        "        if D[mid]>a:\n",
        "            up=mid\n",
        "            mid = int((low+up)/2)\n",
        "        if D[mid]<a:\n",
        "            low=mid\n",
        "            mid = int((low+up)/2)\n",
        "        if D[mid]==a:\n",
        "            i=0\n",
        "            while D[mid+i]==a:\n",
        "                i+=1\n",
        "            return mid+i\n",
        "\n",
        "def clip(D, a, b):\n",
        "    clipped = copy.deepcopy(D)\n",
        "    clipped[clipped<a] = a\n",
        "    clipped[clipped>b] = b\n",
        "    return clipped\n",
        "\n",
        "def LapNoise():\n",
        "    a = random.uniform(0,1)\n",
        "    b = math.log(1/(1-a))\n",
        "    c = random.uniform(0,1)\n",
        "    if c>0.5:\n",
        "        return b\n",
        "    else:\n",
        "        return -b\n",
        "\n",
        "def F(x):\n",
        "    return 1/2+1/(4*math.pi)*(math.log(abs(2*x**2+2*math.sqrt(2)*x+2)/abs(abs(2*x**2-2*math.sqrt(2)*x+2)))+2*math.atan(math.sqrt(2)*x+1)+2*math.atan(math.sqrt(2)*x-1))\n",
        "def inver_F(y):\n",
        "    #find the solution of F(x)=y\n",
        "    #Find between -1000000 and 1000000 because F(1000000)=1.0 in python\n",
        "    if y>1/2:\n",
        "        low =0.0\n",
        "        high = 1000000.0\n",
        "        mid = (high+low)/2\n",
        "        while abs(high-low)>0.0000001:\n",
        "            if F(mid)>y:\n",
        "                high=mid\n",
        "            elif F(mid)==y:\n",
        "                return mid\n",
        "            else:\n",
        "                low = mid\n",
        "            mid = (high+low)/2\n",
        "\n",
        "        return high\n",
        "    if y==1/2:\n",
        "        return 0\n",
        "\n",
        "def CauchyNoise():\n",
        "    a = random.uniform(0.5,1)\n",
        "    b = inver_F(a)\n",
        "    c = random.uniform(0,1)\n",
        "    if c>0.5:\n",
        "        return b\n",
        "    else:\n",
        "        return -b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "531be4b4",
      "metadata": {
        "id": "531be4b4"
      },
      "outputs": [],
      "source": [
        "def constructu(eps, a,b, D):\n",
        "    global u\n",
        "    global l\n",
        "    global weight\n",
        "    #[a,b] denotes range\n",
        "    n = len(D)\n",
        "    u = np.zeros(n+2)#utility score\n",
        "    l = np.zeros(n+2)#score changing point\n",
        "    l[0] = a\n",
        "    for i in range(n+1):\n",
        "        if i<=int(n/2):\n",
        "            u[i] = -int(n/2)-1+i\n",
        "            l[i+1]= D[i]\n",
        "        #u[int(n/2+1)] = 0\n",
        "        #l[int(n/2+2)] = D[int(n/2)]\n",
        "        if i>int(n/2):\n",
        "            u[i] = int(n/2)+1-i\n",
        "            l[i]= D[i-1]\n",
        "\n",
        "    l[n+1] = b\n",
        "    u[n+1] = -n-1-u[0]\n",
        "    weight = []\n",
        "    for i in range(int(n/2)+1):\n",
        "        weight.append((l[i+1]-l[i])*math.pow(np.e, eps*u[i]/2))\n",
        "    weight.append(1)\n",
        "    for i in range(int(n/2)+1,n+1):\n",
        "        weight.append((l[i]-l[i-1])*math.pow(np.e, eps*u[i]/2))\n",
        "\n",
        "    totalWeight = sum(weight)\n",
        "    weight = weight/totalWeight\n",
        "    #print(len(weight))\n",
        "\n",
        "def EMMedian_new():\n",
        "    i = np.random.choice(list(range(len(l))), p=weight)\n",
        "    if i==int(n/2)+1:\n",
        "        return int(l[i]/n)\n",
        "    if i<int(n/2)+1:\n",
        "        return int(np.random.randint(l[i], l[i+1],dtype=np.int64)/n)\n",
        "    if i>int(n/2)+1:\n",
        "        return int(np.random.randint(l[i-1], l[i],dtype=np.int64)/n)\n",
        "\n",
        "def constructu_CI(eps, beta, N):\n",
        "    global u1\n",
        "    global weight1\n",
        "    global u2\n",
        "    global weight2\n",
        "    global factor\n",
        "\n",
        "    factor = int(8/eps*np.log(4*n*N/beta))\n",
        "    print(\"factor is \"+str(factor))\n",
        "    u1 = np.zeros(n+2)\n",
        "    u2 = np.zeros(n+2)\n",
        "    for i in range(n+2):\n",
        "        if i<=int(n/2)+1:\n",
        "            u1[i] = -abs(u[i]+factor)\n",
        "            u2[i] = u[i]-factor\n",
        "        else:\n",
        "            u1[i] = u[i]-factor\n",
        "            u2[i] = -abs(u[i]+factor)\n",
        "\n",
        "    idx = int(n/2)+1-factor\n",
        "    weight1 = []\n",
        "    for i in range(idx):\n",
        "        weight1.append((l[i+1]-l[i])*math.pow(np.e, eps*u1[i]/4))\n",
        "    weight1.append(1)\n",
        "    for i in range(idx,n+1):\n",
        "        weight1.append((l[i]-l[i-1])*math.pow(np.e, eps*u1[i]/4))\n",
        "\n",
        "    totalWeight1 = sum(weight1)\n",
        "    weight1 = weight1/totalWeight1\n",
        "\n",
        "    idx = int(n/2)+1+factor\n",
        "    weight2 = []\n",
        "    for i in range(idx):\n",
        "        weight2.append((l[i+1]-l[i])*math.pow(np.e, eps*u2[i]/4))\n",
        "    weight2.append(1)\n",
        "    for i in range(idx,n+1):\n",
        "        weight2.append((l[i]-l[i-1])*math.pow(np.e, eps*u2[i]/4))\n",
        "\n",
        "    totalWeight2 = sum(weight2)\n",
        "    weight2 = weight2/totalWeight2\n",
        "\n",
        "def EMMedianCI():\n",
        "    i1 = np.random.choice(list(range(len(l))), p=weight1)\n",
        "    if i1==int(n/2)+1-factor:\n",
        "        x1= int(l[i1]/n)\n",
        "    if i1<int(n/2)+1-factor:\n",
        "        x1= int(np.random.randint(l[i1], l[i1+1],dtype=np.int64)/n)\n",
        "    if i1>int(n/2)+1-factor:\n",
        "        x1= int(np.random.randint(l[i1-1], l[i1],dtype=np.int64)/n)\n",
        "\n",
        "    i2 = np.random.choice(list(range(len(l))), p=weight2)\n",
        "    if i2==int(n/2)+1+factor:\n",
        "        x2= int(l[i2]/n)\n",
        "    if i2<int(n/2)+1+factor:\n",
        "        x2= int(np.random.randint(l[i2], l[i2+1],dtype=np.int64)/n)\n",
        "    if i2>int(n/2)+1+factor:\n",
        "        x2= int(np.random.randint(l[i2-1], l[i2],dtype=np.int64)/n)\n",
        "\n",
        "    est = EMMedian_new()\n",
        "    indicator=0\n",
        "    if D[int(n/2)]<=x2 and D[int(n/2)]>=x1:\n",
        "        indicator=1\n",
        "\n",
        "    return x1,x2 ,indicator,est"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "93ba4034",
      "metadata": {
        "id": "93ba4034"
      },
      "outputs": [],
      "source": [
        "def SVTquantile(eps, beta, D, tau, rad):\n",
        "    start = time.time()\n",
        "    TNoise = 2/eps*LapNoise()\n",
        "    T = tau\n",
        "\n",
        "    for i in range(rad+1):\n",
        "        Ti = T-4/eps*np.log(2*(i+1)**2 * np.pi**2/(3*beta)) - 2/eps*np.log(4/beta)+TNoise\n",
        "        Qi = counts[i]+4/eps*LapNoise()\n",
        "        if Qi>Ti:\n",
        "            end = time.time()\n",
        "            #print(\"time is \"+str(end-start))\n",
        "            return i\n",
        "def SVTmedian(eps, beta, D, rad):\n",
        "    start = time.time()\n",
        "    TNoise = 2/eps*LapNoise()\n",
        "    n=len(D)\n",
        "    T = int(n/2)\n",
        "\n",
        "    for i in range(rad+1):\n",
        "        Ti = T+TNoise\n",
        "        Qi = counts[i]+4/eps*LapNoise()\n",
        "        if Qi>Ti:\n",
        "            end = time.time()\n",
        "            #print(\"time is \"+str(end-start))\n",
        "            return i\n",
        "\n",
        "def SVTMedian(eps, beta, D):\n",
        "    n = len(D)\n",
        "    rad = 1000000\n",
        "    Q = SVTmedian(eps, beta, D, rad)\n",
        "\n",
        "    factor = int(16/eps*math.log(2*(2*rad+1)**2 *math.pi**2/(3*beta))+8/eps*math.log(4/beta))+1\n",
        "    ##Then run SVT, do not double\n",
        "    ##find the n/2 +- factor quantile\n",
        "    T1 = int(n/2)-1\n",
        "    T2 = int(n/2)+factor\n",
        "    XLeft = SVTquantile(eps/2, beta/2, D, T1, rad)\n",
        "    #print(XLeft)\n",
        "    XRight = SVTquantile(eps/2, beta/2, D, T2, rad)\n",
        "    #print(XRight)\n",
        "    indicator=0\n",
        "    if D[int(n/2)]<=Q+ XRight and D[int(n/2)]>=XLeft:\n",
        "        indicator=1\n",
        "\n",
        "    return Q, XLeft,XRight,indicator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "31d427a6",
      "metadata": {
        "id": "31d427a6"
      },
      "outputs": [],
      "source": [
        "def smoothMedian(eps, beta, D,delta=0):\n",
        "    #given D, first compute S(D)\n",
        "    n = len(D)\n",
        "    m = int(n/2)\n",
        "    rad = 1000000\n",
        "    SS = 0\n",
        "    if delta==0:\n",
        "        alpha = eps/20\n",
        "        for k in range(500):\n",
        "            for t in range(k+2):\n",
        "                if m+t>n-1:\n",
        "                    rightx = rad\n",
        "                else:\n",
        "                    rightx = D[m+t]\n",
        "                if m+t-k-1 <0:\n",
        "                    leftx = -rad\n",
        "                else:\n",
        "                    leftx = D[m+t-k-1]\n",
        "                temp = math.pow(math.e, -k*alpha)*(rightx-leftx)\n",
        "                SS = max(SS,temp)\n",
        "        #print(SS)\n",
        "        noisySS = SS*math.pow(math.e, 2*alpha/eps*LapNoise()+2*alpha/eps*math.log(2/beta))\n",
        "\n",
        "        Q = D[int(n/2)]+20*SS/eps*CauchyNoise()\n",
        "        #print(Q)\n",
        "        indicator=0\n",
        "        factor = 20*noisySS/eps*inver_F(1-beta/4)\n",
        "        if D[int(n/2)]<=Q+ factor and D[int(n/2)]>=Q-factor:\n",
        "            indicator=1\n",
        "\n",
        "        return Q, factor,indicator\n",
        "    else:\n",
        "        alpha = eps/(4*math.log(1/delta))\n",
        "        for k in range(500):\n",
        "            for t in range(k+2):\n",
        "                if m+t>n-1:\n",
        "                    rightx = rad\n",
        "                else:\n",
        "                    rightx = D[m+t]\n",
        "                if m+t-k-1 <0:\n",
        "                    leftx = -rad\n",
        "                else:\n",
        "                    leftx = D[m+t-k-1]\n",
        "                temp = math.pow(math.e, -k*alpha)*(rightx-leftx)\n",
        "                SS = max(SS,temp)\n",
        "        #print(SS)\n",
        "        noisySS = SS*math.pow(math.e, 2*alpha/eps*LapNoise()+2*alpha/eps*math.log(2/beta))\n",
        "        #print(noisySS)\n",
        "        Q = D[int(n/2)]+4*SS/eps*LapNoise()\n",
        "\n",
        "\n",
        "        indicator=0\n",
        "        if D[int(n/2)]<=Q+ 4*noisySS/eps*math.log(2/beta) and D[int(n/2)]>=Q-4*noisySS/eps*math.log(2/beta):\n",
        "            indicator=1\n",
        "\n",
        "        return Q, 4*noisySS/eps*math.log(2/beta),indicator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4d2ebe4f",
      "metadata": {
        "id": "4d2ebe4f"
      },
      "outputs": [],
      "source": [
        "# Our Additions (September 27th)\n",
        "# Exponetial Mechanism + Confidence Intervals\n",
        "\n",
        "#ci = (2 * sens / eps) * (np.log(domain_size / beta))\n",
        "#print(ci)\n",
        "\n",
        "#np.unique(D,return_counts=True)\n",
        "\n",
        "#vals, counts = np.unique(D,return_counts=True)\n",
        "#print(vals)\n",
        "#vals = [0.0] + vals.tolist()\n",
        "#print(vals)\n",
        "\n",
        "def basic_EM(eps,beta,D,domain_size):\n",
        "    print(\"Results for EM, beta = \"+str(beta) + \", epsilon = \" + str(eps))\n",
        "    #print(D)\n",
        "    #D = D.sort() # D is sorted\n",
        "    interval_prob = []\n",
        "    vals, counts = np.unique(D,return_counts=True)\n",
        "    #print(vals)\n",
        "    #print(counts)\n",
        "    rank = 0\n",
        "    vals = [0.0] + vals.tolist()\n",
        "    cdf = 0.0\n",
        "    for i in range(1,len(vals)):\n",
        "        rank += counts[i-1]\n",
        "        utility = -1.0* np.abs(rank - (len(D)/2))\n",
        "        #print(rank)\n",
        "        #print(utility)\n",
        "        #print(math.pow(np.e, eps*utility))\n",
        "        p = (vals[i] - vals[i-1])* math.pow(np.e, eps*utility)\n",
        "        cdf += p\n",
        "        interval_prob.append(cdf)\n",
        "    rand_val = cdf * np.random.uniform(0,1)\n",
        "    #print(cdf,rand_val)\n",
        "    for i in range(1,len(vals)):\n",
        "        if rand_val <= interval_prob[i]:\n",
        "            sens = 1\n",
        "            ci = (2 * sens / eps) * (np.log(domain_size / beta))\n",
        "            med_val = np.random.uniform(vals[i-1],vals[i])\n",
        "\n",
        "            print(\"median rank: %d out of %d\" %(i,len(vals)) )\n",
        "            print(\"range for median rank: (%f,%f)\" %(vals[i-1],vals[i]))\n",
        "            #print(\"sampled median value: (%f)\" % (med_val)) #need to convert from rank to true value\n",
        "            print(\"size of confidence interval: %f\" %(ci)) # for rank\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5cdd1c06",
      "metadata": {
        "id": "5cdd1c06"
      },
      "outputs": [],
      "source": [
        "# November 22nd / November 29th\n",
        "\n",
        "#1) Learn noisy median o of distribution using Exponential Mechanism\n",
        "def EM_median(eps,beta,D,domain_size):\n",
        "    #print(\"Results for EM, beta = \"+str(beta) + \", epsilon = \" + str(eps))\n",
        "    interval_prob = []\n",
        "    vals, counts = np.unique(D,return_counts=True)\n",
        "    rank = 0\n",
        "    vals = [0.0] + vals.tolist()\n",
        "    cdf = 0.0\n",
        "    rank_dict = {}\n",
        "    for i in range(1,len(vals)):\n",
        "        rank += counts[i-1]\n",
        "        rank_dict[vals[i]] = rank\n",
        "        utility = -1.0* np.abs(rank - (len(D)/2))\n",
        "        p = (vals[i] - vals[i-1])* math.pow(np.e, eps*utility)\n",
        "        cdf += p\n",
        "        interval_prob.append(cdf)\n",
        "    rand_val = cdf * np.random.uniform(0,1)\n",
        "    rank_o = 0\n",
        "    for i in range(1,len(vals)):\n",
        "        if rand_val <= interval_prob[i]:\n",
        "            sens = 1\n",
        "            ci = (2 * sens / eps) * (np.log(domain_size / beta))\n",
        "            o = np.random.uniform(vals[i-1],vals[i])\n",
        "            rank_o = rank_dict[vals[i-1]]\n",
        "            #print(\"median rank: %d out of %d\" %(rank_dict[vals[i-1]],len(vals)) )\n",
        "            #print(\"range for median rank: (%f,%f)\" %(vals[i-1],vals[i]))\n",
        "            #print(\"sampled median value: (%f)\" % (o)) #need to convert from rank to true value\n",
        "            #print(\"size of confidence interval: %f\" %(ci)) # for rank\n",
        "            break\n",
        "    return o,rank_o,rank_dict\n",
        "\n",
        "#2)\n",
        "def find_rank(rank_dict,val):\n",
        "    ranks = list(rank_dict.values())\n",
        "    keys = list(rank_dict.keys())\n",
        "    output = 0\n",
        "    for i in range(len(ranks)-1):\n",
        "        if val < keys[i+1]:\n",
        "            output = ranks[i]\n",
        "            break\n",
        "    #print(rank_dict[output])\n",
        "    return output#int(output)\n",
        "\n",
        "\n",
        "def SVT_median(o,rank_o,rank_dict,eps,beta,D,domain_size,T,b_list):\n",
        "    #print(\"T: \", T)\n",
        "    noisy_T = T + np.random.laplace(2/eps)\n",
        "    #print(\"noisy_T: \", noisy_T)\n",
        "    #print(\"rank_dict\", list(rank_dict.values()))\n",
        "    #print(\"rank_keys\", list(rank_dict.keys()))\n",
        "\n",
        "    sensitivity = 1\n",
        "    #b_max = 10\n",
        "    #step = 1\n",
        "    bounds = domain_size\n",
        "    for b in b_list: #range(0,b_max,step):\n",
        "        perturbed_value = min(abs(find_rank(rank_dict, o+b)-rank_o),abs(find_rank(rank_dict, o-b)-rank_o)) + np.random.laplace(2*sensitivity/eps)\n",
        "        if perturbed_value > noisy_T:\n",
        "            bounds = b\n",
        "            break\n",
        "    #print(max(o-bounds,0))\n",
        "    #print(min(o+bounds,domain_size-1))\n",
        "    return max(o-bounds,0),min(o+bounds,domain_size-1)\n",
        "\n",
        "##### main function ######\n",
        "\n",
        "def our_CI():\n",
        "    C = (2/eps_1) *(np.log(domain_size/beta_1))\n",
        "    alpha = (8*np.log(m)+np.log(2/beta_2)) / eps_2\n",
        "    #print(\"C\", C)\n",
        "    #print(\"alpha\", alpha)\n",
        "    T = C + alpha\n",
        "    o,rank_o,rank_dict = EM_median(eps_1,beta_1,D,domain_size)\n",
        "    lower,upper = SVT_median(o,rank_o,rank_dict,eps_2,beta_1,D,domain_size,T,b_list)\n",
        "    #print(\"median:\",o)\n",
        "    #print(\"The bounds are:\")\n",
        "    #print('[{},{}]'.format(lower,upper))\n",
        "    indi = -1 #if CI contains true med\n",
        "    if true_med < upper and true_med > lower:\n",
        "        indi = 1\n",
        "    else:\n",
        "        indi = 0\n",
        "    return lower,upper,indi,o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "c742116c",
      "metadata": {
        "id": "c742116c"
      },
      "outputs": [],
      "source": [
        "#Test for our_CI\n",
        "def test_ours(compare = False):\n",
        "  len_eps = []\n",
        "  err_eps = []\n",
        "  est_median = []\n",
        "  times = []\n",
        "  ranks = []\n",
        "  rank_errors_1 = [] # based on n/2\n",
        "  rank_errors_2 = [] # based on find_rank(rank_dict,true_med)\n",
        "  # est_list = []\n",
        "  med_rank = int(find_rank(rank_dict, true_med))\n",
        "  for i in range(len(beta)):\n",
        "      print(\"Results for EM based median, beta = \"+str(beta[i]))\n",
        "      errors = []\n",
        "      lengths = []\n",
        "      correct_count = 0\n",
        "\n",
        "      for j in range(num_repeat):\n",
        "          start = time.time()\n",
        "          xl,xr,indi,est = our_CI()#EMMedianCI()\n",
        "          end = time.time()\n",
        "          times.append(end-start)\n",
        "          correct_count+=indi\n",
        "          lengths.append((xr-xl)/(2))\n",
        "          est = (xr+xl)/2\n",
        "          est_median.append(est)\n",
        "          errors.append(abs(est-true_med))\n",
        "          est_rank = int(find_rank(rank_dict, est))\n",
        "          ranks.append(est_rank)\n",
        "          rank_errors_1.append(int(abs(n/2 - est_rank)))\n",
        "          rank_errors_2.append(int(abs(med_rank - est_rank)))\n",
        "          # est_list.append(est)\n",
        "      original_errors = errors\n",
        "      errors = np.array(errors, dtype=object)\n",
        "      correct_rate = correct_count/num_repeat\n",
        "      avgLength = sum(lengths)/num_repeat\n",
        "      errors.sort()\n",
        "      errorQuantile = errors[int(num_repeat*(1-beta[i]))]\n",
        "      avg_error = np.average(errors)\n",
        "      avgTime = sum(times)/len(times)\n",
        "\n",
        "\n",
        "      # output medians and error\n",
        "\n",
        "      #download errors\n",
        "      # df = pd.DataFrame(errors)\n",
        "      # file_name = f\"data_error.csv\"\n",
        "      # df.to_csv(file_name, index=False, header=False)\n",
        "      # files.download(file_name)\n",
        "\n",
        "      # median_error\n",
        "      if np.all(errors == errors[0]):\n",
        "          stddev_based_avg_err = errors[0]\n",
        "          IQR_based_avg_err = errors[0]\n",
        "      else:\n",
        "          std_dev = np.std(errors)\n",
        "          stddev_based_avg_err = np.average(errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "          q1 = np.percentile(errors, 25)\n",
        "          q3 = np.percentile(errors, 75)\n",
        "          iqr = q3 - q1\n",
        "          lower_bound = q1 - 1.5 * iqr\n",
        "          upper_bound = q3 + 1.5 * iqr\n",
        "          IQR_based_avg_err = np.average(errors[(errors >= lower_bound) & (errors <= upper_bound)])\n",
        "      # rank_error\n",
        "      avg_rank_error_1 = np.average(rank_errors_1)\n",
        "      avg_rank_error_2 = np.average(rank_errors_2)\n",
        "      print(\"estimated median value: \"+ str(np.average(est_median)))\n",
        "      print(\"correct rate = \", correct_rate)\n",
        "      print(\"Average CI length = \"+str(avgLength))\n",
        "      print(\"error quantile is \"+ str(errorQuantile))\n",
        "      print(\"CI length/ error quantile = \"+str(avgLength/errorQuantile))\n",
        "      print(\"Average Time to find CI = \" + str(avgTime))\n",
        "      if (output_mode == 0 or output_mode == 2):\n",
        "        row_data = [\n",
        "            \"our_CI\",\n",
        "            data_uuid,\n",
        "            n,\n",
        "            domain_size,\n",
        "            sens,\n",
        "            beta[i],\n",
        "            eps[i],\n",
        "            num_repeat,\n",
        "            true_med,\n",
        "            np.average(est_median),\n",
        "            correct_rate,\n",
        "            avgLength,\n",
        "            errorQuantile,\n",
        "            avg_error,\n",
        "            stddev_based_avg_err,\n",
        "            IQR_based_avg_err,\n",
        "            avg_rank_error_1,\n",
        "            avg_rank_error_2,\n",
        "            avgLength / errorQuantile,\n",
        "            avgTime,\n",
        "            b_list_step,\n",
        "            beta_1,\n",
        "            beta_2,\n",
        "            eps_1,\n",
        "            eps_2\n",
        "        ]\n",
        "        write_to_sheet(worksheet1, row_data, output_mode=output_mode, compare=compare)\n",
        "\n",
        "      # New! Check all medians and errors\n",
        "      if (output_mode == 1 or output_mode == 2):\n",
        "        sorted_med = sorted(est_median)\n",
        "        est_median.insert(0, \"Our est_median\")\n",
        "        sorted_med.insert(0, \"Sorted Our est_median\")\n",
        "\n",
        "        sorted_errors = sorted(original_errors)\n",
        "        original_errors.insert(0, \"Our errors\")\n",
        "        sorted_errors.insert(0, \"Sorted Our errors\")\n",
        "\n",
        "        sorted_ranks = sorted(ranks)\n",
        "        ranks.insert(0, \"Our ranks\")\n",
        "        sorted_ranks.insert(0, \"Sorted Our ranks\")\n",
        "\n",
        "        sorted_re_1 = sorted(rank_errors_1)\n",
        "        sorted_re_2 = sorted(rank_errors_2)\n",
        "        rank_errors_1.insert(0, \"Our rank_errors(n/2)\")\n",
        "        rank_errors_2.insert(0, \"Our rank_errors(find)\")\n",
        "        sorted_re_1.insert(0, \"Sorted Our rank_errors(n/2)\")\n",
        "        sorted_re_2.insert(0, \"Sorted Our rank_errors(find)\")\n",
        "\n",
        "        data_uid_row = [\"data:\", data_uuid, \"method:\", \"Our_CI\"]\n",
        "        true_med_row = [\"true median\"]+[true_med]*num_repeat\n",
        "        n_over_2_row = [\"true n/2\"] + [n/2]*num_repeat\n",
        "        med_rank_row = [\"true med_rank(find)\"] + [med_rank]*num_repeat\n",
        "\n",
        "        worksheet.append_row(data_uid_row)\n",
        "        worksheet.append_row(est_median)\n",
        "        worksheet.append_row(true_med_row)\n",
        "        worksheet.append_row(original_errors)\n",
        "        # write_to_sheet(worksheet1, errors, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(ranks)\n",
        "        worksheet.append_row(n_over_2_row)\n",
        "        worksheet.append_row(rank_errors_1)\n",
        "        # write_to_sheet(worksheet1, rank_errors_1, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(med_rank_row)\n",
        "        worksheet.append_row(rank_errors_2)\n",
        "        # write_to_sheet(worksheet1, rank_errors_2, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(sorted_med)\n",
        "        worksheet.append_row(sorted_ranks)\n",
        "        worksheet.append_row(sorted_errors)\n",
        "        worksheet.append_row(sorted_re_1)\n",
        "        worksheet.append_row(sorted_re_2)\n",
        "\n",
        "\n",
        "      len_eps.append(avgLength)\n",
        "      err_eps.append(errorQuantile)\n",
        "  print(len_eps)\n",
        "  print(err_eps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to test difference between est and est_median\n",
        "\n",
        "# if est_median != est_list:\n",
        "#     print(\"The two lists are different. The differences are as follows:\")\n",
        "\n",
        "#     # Check each position for differing elements\n",
        "#     for j, (a, b) in enumerate(zip(est_median, est_list)):\n",
        "#         if a != b:\n",
        "#             print(f\"Index {j}: est_median = {a}, est_list = {b}\")\n",
        "\n",
        "# else:\n",
        "#     print(\"The two lists are the same\")\n",
        "\n",
        "# avg_error = np.average(errors)"
      ],
      "metadata": {
        "id": "lVO0t6I7IMMf"
      },
      "id": "lVO0t6I7IMMf",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "id": "490b3cbd",
      "metadata": {
        "id": "490b3cbd"
      },
      "outputs": [],
      "source": [
        "def test_theirs(compare = False):\n",
        "  len_eps = []\n",
        "  err_eps = []\n",
        "  est_median = []\n",
        "  times = []\n",
        "  ranks = []\n",
        "  med_rank = int(find_rank(rank_dict, true_med))\n",
        "  rank_errors_1 = [] # based on n/2\n",
        "  rank_errors_2 = [] # based on find_rank(rank_dict,true_med)\n",
        "  for i in range(len(beta)):\n",
        "      print(\"Results for EM based median, beta = \"+str(beta[i]))\n",
        "      errors = []\n",
        "      lengths = []\n",
        "      correct_count = 0\n",
        "      n = len(newD)\n",
        "      rad = 10000000\n",
        "      left=-rad\n",
        "      constructu(eps[i], left*n,rad*n, newD)\n",
        "\n",
        "      constructu_CI(eps[i],beta[i], rad)\n",
        "      for j in range(num_repeat):\n",
        "          start = time.time()\n",
        "          xl,xr,indi,est = EMMedianCI()\n",
        "          end = time.time()\n",
        "          times.append(end-start)\n",
        "          correct_count+=indi\n",
        "          lengths.append((xr-xl)/(2))\n",
        "          est = (xr+xl)/2\n",
        "          est_median.append(est)\n",
        "          errors.append(abs((xr+xl)/2-true_med))\n",
        "          est_rank = int(find_rank(rank_dict, est))\n",
        "          ranks.append(est_rank)\n",
        "          rank_errors_1.append(int(abs(n/2 - est_rank)))\n",
        "          rank_errors_2.append(int(abs(med_rank - est_rank)))\n",
        "\n",
        "      original_errors = errors\n",
        "      correct_rate = correct_count/num_repeat\n",
        "      avgLength = sum(lengths)/num_repeat\n",
        "      errors.sort()\n",
        "      errorQuantile = errors[int(num_repeat*(1-beta[i]))]\n",
        "      avgTime = sum(times)/len(times)\n",
        "      # new\n",
        "\n",
        "      errors = np.array(errors)\n",
        "      avg_error = np.average(errors)\n",
        "      if np.all(errors == errors[0]):\n",
        "          stddev_based_avg_err = errors[0]\n",
        "          IQR_based_avg_err = errors[0]\n",
        "      else:\n",
        "          std_dev = np.std(errors)\n",
        "          stddev_based_avg_err = np.average(errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "\n",
        "          q1 = np.percentile(errors, 25)\n",
        "          q3 = np.percentile(errors, 75)\n",
        "          iqr = q3 - q1\n",
        "          lower_bound = q1 - 1.5 * iqr\n",
        "          upper_bound = q3 + 1.5 * iqr\n",
        "          IQR_based_avg_err = np.average(errors[(errors >= lower_bound) & (errors <= upper_bound)])\n",
        "\n",
        "      #rank_avg\n",
        "      avg_rank_error_1 = np.average(rank_errors_1)\n",
        "      avg_rank_error_2 = np.average(rank_errors_2)\n",
        "      print(\"Filtered Errors for IQR_based_avg_err:\", IQR_based_avg_err)\n",
        "\n",
        "      print(\"estimated median value: \"+ str(np.average(est_median)))\n",
        "      print(\"correct rate = \" +str(correct_count/num_repeat))\n",
        "      print(\"Average CI length = \"+str(avgLength))\n",
        "      print(\"error quantile is \"+ str(errorQuantile))\n",
        "      print(\"CI length/ error quantile = \"+str(avgLength/errorQuantile))\n",
        "      print(\"Average Time to find CI = \" + str(sum(times)/len(times)))\n",
        "      # print(\"Errors:\", errors)\n",
        "      # print(\"Standard Deviation:\", std_dev)\n",
        "      # print(\"Filtered Errors for stddev_based_avg_err:\", errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "\n",
        "      # print(\"Q1:\", q1, \"Q3:\", q3)\n",
        "      # print(\"IQR:\", iqr)\n",
        "      # print(\"Lower Bound:\", lower_bound, \"Upper Bound:\", upper_bound)\n",
        "      if (output_mode == 0 or output_mode == 2):\n",
        "        row_data = [\n",
        "            \"EM_CI\",\n",
        "            data_uuid,\n",
        "            n,\n",
        "            domain_size,\n",
        "            sens,\n",
        "            beta[i],\n",
        "            eps[i],\n",
        "            num_repeat,\n",
        "            true_med,\n",
        "            np.average(est_median),\n",
        "            correct_rate,\n",
        "            avgLength,\n",
        "            errorQuantile,\n",
        "            avg_error,\n",
        "            stddev_based_avg_err,\n",
        "            IQR_based_avg_err,\n",
        "            avg_rank_error_1,\n",
        "            avg_rank_error_2,\n",
        "            avgLength / errorQuantile,\n",
        "            avgTime,\n",
        "            b_list_step,\n",
        "            beta_1,\n",
        "            beta_2,\n",
        "            eps_1,\n",
        "            eps_2\n",
        "        ]\n",
        "        write_to_sheet(worksheet1, row_data, compare = compare)\n",
        "\n",
        "      # New! Check all medians and errors\n",
        "      if (output_mode == 1 or output_mode == 2):\n",
        "        sorted_med = sorted(est_median)\n",
        "        est_median.insert(0, \"EM est_median\")\n",
        "        sorted_med.insert(0, \"Sorted EM est_median\")\n",
        "\n",
        "        sorted_errors = sorted(original_errors)\n",
        "        original_errors.insert(0, \"EM errors\")\n",
        "        sorted_errors.insert(0, \"Sorted EM errors\")\n",
        "\n",
        "        sorted_ranks = sorted(ranks)\n",
        "        ranks.insert(0, \"EM ranks\")\n",
        "        sorted_ranks.insert(0, \"Sorted EM ranks\")\n",
        "\n",
        "        sorted_re_1 = sorted(rank_errors_1)\n",
        "        sorted_re_2 = sorted(rank_errors_2)\n",
        "        rank_errors_1.insert(0, \"EM rank_errors(n/2)\")\n",
        "        rank_errors_2.insert(0, \"EM rank_errors(find)\")\n",
        "        sorted_re_1.insert(0, \"Sorted EM rank_errors(n/2)\")\n",
        "        sorted_re_2.insert(0, \"Sorted EM rank_errors(find)\")\n",
        "\n",
        "        data_uid_row = [\"data:\", data_uuid, \"method:\", \"EM_CI\"]\n",
        "        true_med_row = [\"true median\"]+[true_med]*num_repeat\n",
        "        n_over_2_row = [\"true n/2\"] + [n/2]*num_repeat\n",
        "        med_rank_row = [\"true med_rank(find)\"] + [med_rank]*num_repeat\n",
        "\n",
        "        worksheet.append_row(data_uid_row)\n",
        "        worksheet.append_row(est_median)\n",
        "        worksheet.append_row(true_med_row)\n",
        "\n",
        "        worksheet.append_row(original_errors)\n",
        "        # write_to_sheet(worksheet1, original_errors, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(ranks)\n",
        "        worksheet.append_row(n_over_2_row)\n",
        "        worksheet.append_row(rank_errors_1)\n",
        "        # write_to_sheet(worksheet1, rank_errors_1, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(med_rank_row)\n",
        "        worksheet.append_row(rank_errors_2)\n",
        "        # write_to_sheet(worksheet1, rank_errors_2, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(sorted_med)\n",
        "        worksheet.append_row(sorted_ranks)\n",
        "        worksheet.append_row(sorted_errors)\n",
        "        worksheet.append_row(sorted_re_1)\n",
        "        worksheet.append_row(sorted_re_2)\n",
        "\n",
        "\n",
        "\n",
        "      len_eps.append(avgLength)\n",
        "      err_eps.append(errorQuantile)\n",
        "  print(len_eps)\n",
        "  print(err_eps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def readInput(mode):\n",
        "    import numpy as np\n",
        "\n",
        "    global D\n",
        "    global n\n",
        "    read_data_uuid = \"64b7c8bf89f14113bd12f5f15e276546\"\n",
        "    file_paths = {\n",
        "        0: (\"./bank_marketing.csv\", 5),\n",
        "        1: (\"./adult.csv\", 2),\n",
        "        2: (\"./sample_data/california_housing_test.csv\", 3),\n",
        "        3: (\"./sample_data/california_housing_test.csv\", 8),\n",
        "        10: (\"./data_\"+read_data_uuid+\".csv\",0)\n",
        "    }\n",
        "\n",
        "    if mode not in file_paths:\n",
        "        raise ValueError(\"Invalid mode. Choose between 0, 1, or 2.\")\n",
        "\n",
        "    input_path, column_index = file_paths[mode]\n",
        "\n",
        "    with open(input_path, 'r') as input_file:\n",
        "        lines = input_file.readlines()\n",
        "    n = len(lines)\n",
        "    D = np.zeros(n)\n",
        "    for i, line in enumerate(lines):\n",
        "        if i > 0:\n",
        "            elements = line.split(\",\")\n",
        "            try:\n",
        "                value = float(elements[column_index])\n",
        "                D[i - 1] = int(value)\n",
        "            except ValueError:\n",
        "                print(f\"Skipping invalid data at line {i}: {elements[column_index]}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-xoDZUe5Or-N"
      },
      "id": "-xoDZUe5Or-N",
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment Data Input\n",
        "\n",
        "dataset_id_dict = {0:\"bank_marketing\", 1:\"adult\", 2:\"cali_housing_test\", 3:\"cali_housing_value\",\n",
        "                   10: \"old_synthetic_data\"}\n",
        "mode = 0\n",
        "\n",
        "if (mode == -1):\n",
        "  n = 4000  # 45#000\n",
        "  domain_size = 4000  # 40#000\n",
        "  D = np.random.uniform(0, domain_size, n)\n",
        "  lowest = 0\n",
        "  highest = domain_size\n",
        "else:\n",
        "  readInput(mode)\n",
        "\n",
        "  lowest = int(min(D))\n",
        "  highest = int(max(D))\n",
        "  print(\"lowest:\",lowest)\n",
        "  domain_size = highest - lowest\n",
        "\n",
        "print(\"Data_size:\", n)\n",
        "print(\"Domain size:\", domain_size)\n",
        "print(D)\n",
        "\n",
        "D.sort()\n",
        "D = discretize(D, 1)\n",
        "newD = discrete(D)\n",
        "\n",
        "true_med = np.median(D)  # GET EXACT MEDIAN\n",
        "print(\"true median: \", true_med)\n",
        "\n",
        "# rank_dict\n",
        "vals, counts = np.unique(D,return_counts=True)\n",
        "rank_dict = {}\n",
        "rank = 0\n",
        "vals = [0.0] + vals.tolist()\n",
        "for i in range(1,len(vals)):\n",
        "    rank += counts[i-1]\n",
        "    rank_dict[vals[i]] = rank\n",
        "print(\"true median rank:\",n/2)\n",
        "\n",
        "\n",
        "\n",
        "# Data Persistence\n",
        "if (mode == -1):\n",
        "  df = pd.DataFrame(D)\n",
        "  data_uuid = uuid.uuid4().hex\n",
        "  file_name = f\"data_{data_uuid}.csv\"\n",
        "  df.to_csv(file_name, index=False, header=False)\n",
        "  files.download(file_name)\n",
        "  print(f\"File saved as {file_name}\")\n",
        "else:\n",
        "  data_uuid = dataset_id_dict[mode]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTEhx4k8KNoQ",
        "outputId": "c0798a59-848b-4312-cea2-da3f008d761c"
      },
      "id": "kTEhx4k8KNoQ",
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lowest: -8019\n",
            "Data_size: 45212\n",
            "Domain size: 110146\n",
            "[2.143e+03 2.900e+01 2.000e+00 ... 6.680e+02 2.971e+03 0.000e+00]\n",
            "true median:  448.0\n",
            "true median rank: 22606.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CI Parameters\n",
        "eps = [1]\n",
        "beta = [0.01]\n",
        "sens = 1 #fixed\n",
        "num_repeat=100\n",
        "\n",
        "\n",
        "# for val, rank in rank_dict.items():\n",
        "#     print(val,\"  \",rank)\n",
        "\n",
        "# Parameters for our_CI\n",
        "beta_1 = 0.5 *beta[0]\n",
        "beta_2 = beta[0] - beta_1\n",
        "eps_1 = 0.5 * eps[0]\n",
        "eps_2 = eps[0] - eps_1\n",
        "\n",
        "b_list_step = 1\n",
        "if mode == 1: b_list_step = 50\n",
        "b_list = range(0, domain_size, b_list_step)  # [0,10,20,30,40,50,60,70,80,90,100]\n",
        "m = len(b_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "G-o_F3TWSUzN"
      },
      "id": "G-o_F3TWSUzN",
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test both\n",
        "\n",
        "# output_mode 0:experiment results,\n",
        "#        1:medians&ranks\n",
        "#        2:both\n",
        "output_mode = 2\n",
        "test_theirs()\n",
        "print(\"-------------------First Test Done--------------------\")\n",
        "\n",
        "if output_mode==2:\n",
        "  print(\"wait for 90 secs for the Second Test\")\n",
        "  time.sleep(90)\n",
        "\n",
        "\n",
        "# test_ours(compare = True)\n",
        "print(\"-------------------Second Test Done--------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "ZZKk-CjfKeLU",
        "outputId": "57a4d70f-b4ae-4f1b-e414-24350374a3c9"
      },
      "id": "ZZKk-CjfKeLU",
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for EM based median, beta = 0.01\n",
            "factor is 262\n",
            "Filtered Errors for IQR_based_avg_err: 0.53\n",
            "estimated median value: 448.53\n",
            "correct rate = 1.0\n",
            "Average CI length = 13.14\n",
            "error quantile is 2.0\n",
            "CI length/ error quantile = 6.57\n",
            "Average Time to find CI = 0.012030017375946046\n",
            "[13.14]\n",
            "[2.0]\n",
            "-------------------First Test Done--------------------\n",
            "wait for 90 secs for the Second Test\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-172-da7bedb805b5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wait for 90 secs for the Second Test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test different beta\n",
        "eps = [1]\n",
        "eps_1 = 0.5 * eps[0]\n",
        "eps_2 = eps[0] - eps_1\n",
        "beta_list = [0.01,0.025,0.05,0.1,0.2]\n",
        "for beta in beta_list:\n",
        "  beta = [beta]\n",
        "  beta_1 = 0.5 * beta[0]\n",
        "  beta_2 = beta[0] - beta_1\n",
        "  print(f\"Running for beta={beta}\")\n",
        "  test_theirs()\n",
        "  # test_ours()\n",
        "  print(f\"beta={beta} done\")\n",
        "  time.sleep(20)\n",
        "\n"
      ],
      "metadata": {
        "id": "72FYc7UozH2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe97761-d284-473a-c50b-46f2c2e46569"
      },
      "id": "72FYc7UozH2c",
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running for beta=[0.01]\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 243\n",
            "Filtered Errors for IQR_based_avg_err: 8.357142857142858\n",
            "estimated median value: 2006.09\n",
            "correct rate = 1.0\n",
            "Average CI length = 233.55\n",
            "error quantile is 22.0\n",
            "CI length/ error quantile = 10.615909090909092\n",
            "Average Time to find CI = 0.0020871376991271973\n",
            "[233.55]\n",
            "[22.0]\n",
            "beta=[0.01] done\n",
            "Running for beta=[0.025]\n",
            "Results for EM based median, beta = 0.025\n",
            "factor is 235\n",
            "Filtered Errors for IQR_based_avg_err: 9.742424242424242\n",
            "estimated median value: 2004.57\n",
            "correct rate = 1.0\n",
            "Average CI length = 226.76\n",
            "error quantile is 16.0\n",
            "CI length/ error quantile = 14.1725\n",
            "Average Time to find CI = 0.001212770938873291\n",
            "[226.76]\n",
            "[16.0]\n",
            "beta=[0.025] done\n",
            "Running for beta=[0.05]\n",
            "Results for EM based median, beta = 0.05\n",
            "factor is 230\n",
            "Filtered Errors for IQR_based_avg_err: 10.675\n",
            "estimated median value: 2003.845\n",
            "correct rate = 1.0\n",
            "Average CI length = 223.155\n",
            "error quantile is 16.5\n",
            "CI length/ error quantile = 13.524545454545455\n",
            "Average Time to find CI = 0.0012735366821289063\n",
            "[223.155]\n",
            "[16.5]\n",
            "beta=[0.05] done\n",
            "Running for beta=[0.1]\n",
            "Results for EM based median, beta = 0.1\n",
            "factor is 224\n",
            "Filtered Errors for IQR_based_avg_err: 10.106060606060606\n",
            "estimated median value: 2004.54\n",
            "correct rate = 1.0\n",
            "Average CI length = 217.17\n",
            "error quantile is 15.5\n",
            "CI length/ error quantile = 14.010967741935483\n",
            "Average Time to find CI = 0.0022544145584106447\n",
            "[217.17]\n",
            "[15.5]\n",
            "beta=[0.1] done\n",
            "Running for beta=[0.2]\n",
            "Results for EM based median, beta = 0.2\n",
            "factor is 219\n",
            "Filtered Errors for IQR_based_avg_err: 10.75\n",
            "estimated median value: 2003.77\n",
            "correct rate = 1.0\n",
            "Average CI length = 212.42\n",
            "error quantile is 14.0\n",
            "CI length/ error quantile = 15.172857142857142\n",
            "Average Time to find CI = 0.003131992816925049\n",
            "[212.42]\n",
            "[14.0]\n",
            "beta=[0.2] done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GfTJIPHarSAT"
      },
      "id": "GfTJIPHarSAT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}