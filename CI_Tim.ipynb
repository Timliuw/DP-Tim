{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Timliuw/DP-Tim/blob/main/CI_Tim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cfd74f5f",
      "metadata": {
        "id": "cfd74f5f"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "import pandas as pd\n",
        "import uuid\n",
        "import psutil\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "zfatDYXyr6eo",
      "metadata": {
        "id": "zfatDYXyr6eo"
      },
      "outputs": [],
      "source": [
        "Run_Locally = True\n",
        "# Google Spreadsheet\n",
        "import gspread\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.service_account import Credentials\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "if not Run_Locally:\n",
        "    from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "import os\n",
        "os.listdir()\n",
        "\n",
        "scope = [\n",
        "    \"https://spreadsheets.google.com/feeds\",  # Google Sheets API\n",
        "    \"https://www.googleapis.com/auth/drive\"   # Google Drive API\n",
        "]\n",
        "\n",
        "\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(\"sublime-mission-447319-c2-0df1612796a8.json\", scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "spreadsheet = client.open_by_key(\"1yVVt5ACdBbjsZ_7IiRkvPGIHmpKe8mFXcvyL0PVP2cE\")\n",
        "\n",
        "worksheet1 = spreadsheet.get_worksheet(0)\n",
        "worksheet = worksheet1\n",
        "worksheet2 = spreadsheet.get_worksheet(1)\n",
        "\n",
        "def get_color(curr_value, prev_value):\n",
        "    if curr_value < 0.6 * prev_value:\n",
        "        return {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6}  # very green\n",
        "    elif curr_value < prev_value:\n",
        "        return {\"red\": 0.8, \"green\": 1.0, \"blue\": 0.8}  # green\n",
        "    elif curr_value > 1.4 * prev_value:\n",
        "        return {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6}  # very red\n",
        "    elif curr_value > prev_value:\n",
        "        return {\"red\": 1.0, \"green\": 0.8, \"blue\": 0.8}  # red\n",
        "    return None\n",
        "\n",
        "def write_to_sheet(worksheet, row_data, output_mode=0, compare=False):\n",
        "    # Append the new row to the sheet\n",
        "    try:\n",
        "        worksheet.append_row(row_data)\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        print(f\"Row data: {row_data}\")\n",
        "    # Format colour according to the comparing results\n",
        "    if compare:\n",
        "        pre_row_index = -2\n",
        "        if (output_mode == 2): pre_row_index = -18\n",
        "        sheet_data = worksheet.get_all_values()\n",
        "        last_row_index = len(sheet_data)\n",
        "        if last_row_index > 1:\n",
        "            last_row = sheet_data[-1]\n",
        "            prev_row = sheet_data[pre_row_index]\n",
        "            for col_index, (curr_value, prev_value) in enumerate(zip(last_row, prev_row), start=1):\n",
        "                try:\n",
        "                    curr_value = float(curr_value)\n",
        "                    prev_value = float(prev_value)\n",
        "                    if (worksheet.row_values(1)[col_index-1] == \"est median\"):\n",
        "                      prev_value = abs(true_med - prev_value)\n",
        "                      curr_value = abs(true_med - curr_value)\n",
        "                    color = get_color(curr_value, prev_value)\n",
        "                    if color:\n",
        "                        worksheet.format(f\"{chr(64 + col_index)}{last_row_index}\", {\"backgroundColor\": color})\n",
        "                except:\n",
        "                    continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "202456b3",
      "metadata": {
        "id": "202456b3"
      },
      "outputs": [],
      "source": [
        "def discretize(D, b):\n",
        "    n = len(D)\n",
        "    discreteD = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        discreteD[i] = int(D[i]/b)\n",
        "    return discreteD\n",
        "\n",
        "def discrete(D):\n",
        "    n = len(D)\n",
        "    newD = np.zeros(n)\n",
        "    previous = -1\n",
        "    for i in range(n):\n",
        "        if D[i]!=previous:\n",
        "            newD[i] = n*D[i]\n",
        "            #print(newD[i])\n",
        "            previous = D[i]\n",
        "        elif D[i]==previous:\n",
        "            newD[i] = newD[i-1]+1\n",
        "\n",
        "    return newD\n",
        "\n",
        "def count(D, a):\n",
        "    counter = 0\n",
        "    n = len(D)\n",
        "    low = 0\n",
        "    up=n-1\n",
        "    mid = int((low+up)/2)\n",
        "    while True:\n",
        "        if D[mid]>a:\n",
        "            up=mid\n",
        "            mid = int((low+up)/2)\n",
        "        if D[mid]<a:\n",
        "            low=mid\n",
        "            mid = int((low+up)/2)\n",
        "        if D[mid]==a:\n",
        "            i=0\n",
        "            while D[mid+i]==a:\n",
        "                i+=1\n",
        "            return mid+i\n",
        "\n",
        "def clip(D, a, b):\n",
        "    clipped = copy.deepcopy(D)\n",
        "    clipped[clipped<a] = a\n",
        "    clipped[clipped>b] = b\n",
        "    return clipped\n",
        "\n",
        "def LapNoise():\n",
        "    a = random.uniform(0,1)\n",
        "    b = math.log(1/(1-a))\n",
        "    c = random.uniform(0,1)\n",
        "    if c>0.5:\n",
        "        return b\n",
        "    else:\n",
        "        return -b\n",
        "\n",
        "def F(x):\n",
        "    return 1/2+1/(4*math.pi)*(math.log(abs(2*x**2+2*math.sqrt(2)*x+2)/abs(abs(2*x**2-2*math.sqrt(2)*x+2)))+2*math.atan(math.sqrt(2)*x+1)+2*math.atan(math.sqrt(2)*x-1))\n",
        "def inver_F(y):\n",
        "    #find the solution of F(x)=y\n",
        "    #Find between -1000000 and 1000000 because F(1000000)=1.0 in python\n",
        "    if y>1/2:\n",
        "        low =0.0\n",
        "        high = 1000000.0\n",
        "        mid = (high+low)/2\n",
        "        while abs(high-low)>0.0000001:\n",
        "            if F(mid)>y:\n",
        "                high=mid\n",
        "            elif F(mid)==y:\n",
        "                return mid\n",
        "            else:\n",
        "                low = mid\n",
        "            mid = (high+low)/2\n",
        "\n",
        "        return high\n",
        "    if y==1/2:\n",
        "        return 0\n",
        "\n",
        "def CauchyNoise():\n",
        "    a = random.uniform(0.5,1)\n",
        "    b = inver_F(a)\n",
        "    c = random.uniform(0,1)\n",
        "    if c>0.5:\n",
        "        return b\n",
        "    else:\n",
        "        return -b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "531be4b4",
      "metadata": {
        "id": "531be4b4"
      },
      "outputs": [],
      "source": [
        "# Their algorithm\n",
        "def constructu(eps, a,b, D,sensitivity = 0.5):\n",
        "    # global u\n",
        "    # global l\n",
        "    # global weight\n",
        "    #[a,b] denotes range\n",
        "    n = len(D)\n",
        "\n",
        "    u = np.zeros(n+2)#utility score\n",
        "    l = np.zeros(n+2)#corresponding data\n",
        "    l[0] = a\n",
        "    for i in range(n+1): #i=rank-1\n",
        "        if i<=int(n/2):\n",
        "            u[i] = -int(n/2)-1+i\n",
        "            l[i+1]= D[i]\n",
        "        #u[int(n/2+1)] = 0\n",
        "        #l[int(n/2+2)] = D[int(n/2)]\n",
        "        if i>int(n/2):\n",
        "            u[i] = int(n/2)+1-i\n",
        "            l[i]= D[i-1]\n",
        "\n",
        "    l[n+1] = b\n",
        "    u[n+1] = -n-1-u[0]\n",
        "    weight = []\n",
        "    # l[i] corresponds to data in D with rank i\n",
        "    for i in range(int(n/2)+1): # build weight[0...n/2]\n",
        "        weight.append((l[i+1]-l[i])*math.pow(np.e, eps*u[i]/(2*sensitivity))) # weight[i]=(l[i+1]-l[i])...\n",
        "    weight.append(1) # weight[n/2+1] = 1\n",
        "    for i in range(int(n/2)+1,n+1): # build weight[n/2+2..n+1]\n",
        "        weight.append((l[i]-l[i-1])*math.pow(np.e, eps*u[i]/(2*sensitivity))) # weight[i+1]=(l[i]-l[i-1])...\n",
        "        # which means weight[i] corresponds to interval [ l[i-1],l[i-2] ) for i > int(n/2)+1\n",
        "        # should be:\n",
        "        # weight.append((l[i+1]-l[i])*math.pow(np.e, eps*u[i]/(2*sensitivity))) # weight[i+1]=(l[i+1]-l[i])...\n",
        "    totalWeight = sum(weight)\n",
        "    weight = weight/totalWeight\n",
        "    # if show_EM_median_u:\n",
        "    #   print(\"totalWeight\",totalWeight)\n",
        "    #   df[\"Their u\"] = list(u)\n",
        "    #   df['Their weights'] = weight\n",
        "    return u, l, weight\n",
        "\n",
        "def EMMedian_new(l,weight):\n",
        "    i = np.random.choice(list(range(len(l))), p=weight) # choose index i from 0 to n+1\n",
        "    # pick i with weight[i]\n",
        "    # only return int\n",
        "    if i==int(n/2)+1:\n",
        "        return int(l[i]/n)\n",
        "    if i<int(n/2)+1:\n",
        "        return int(np.random.randint(l[i], l[i+1],dtype=np.int64) / n)\n",
        "    if i>int(n/2)+1:\n",
        "        return int(np.random.randint(l[i-1], l[i],dtype=np.int64) / n) # bug?\n",
        "\n",
        "def constructu_CI(eps, beta, N, u, l,sensitivity = 0.5):\n",
        "    # global u1\n",
        "    # global weight1\n",
        "    # global u2\n",
        "    # global weight2\n",
        "    # global factor\n",
        "    if show_EM_median_u:\n",
        "      return [],[],[],[],0\n",
        "    factor = int(8/eps*np.log(4*n*N/beta))\n",
        "    print(\"factor is \"+str(factor))\n",
        "    #u1: left util\n",
        "    #u2: right util\n",
        "    u1 = np.zeros(n+2)\n",
        "    u2 = np.zeros(n+2)\n",
        "    for i in range(n+2):\n",
        "        if i<=int(n/2)+1:\n",
        "            u1[i] = -abs(u[i]+factor)\n",
        "            u2[i] = u[i]-factor\n",
        "        else:\n",
        "            u1[i] = u[i]-factor\n",
        "            u2[i] = -abs(u[i]+factor)\n",
        "\n",
        "    idx = int(n/2)+1-factor\n",
        "    weight1 = []\n",
        "    for i in range(idx):\n",
        "        weight1.append((l[i+1]-l[i])*math.pow(np.e, eps*u1[i]/(4*sensitivity)))\n",
        "    weight1.append(1)\n",
        "    for i in range(idx,n+1):\n",
        "        weight1.append((l[i]-l[i-1])*math.pow(np.e, eps*u1[i]/(4*sensitivity)))\n",
        "    totalWeight1 = sum(weight1)\n",
        "    weight1 = weight1/totalWeight1\n",
        "\n",
        "    idx = int(n/2)+1+factor\n",
        "    idx = min(int(n/2)+1+factor,n+1)\n",
        "    weight2 = []\n",
        "    for i in range(idx):\n",
        "        weight2.append((l[i+1]-l[i])*math.pow(np.e, eps*u2[i]/(4*sensitivity)))\n",
        "    weight2.append(1)\n",
        "    for i in range(idx,n+1):\n",
        "        weight2.append((l[i]-l[i-1])*math.pow(np.e, eps*u2[i]/(4*sensitivity)))\n",
        "\n",
        "    totalWeight2 = sum(weight2)\n",
        "    weight2 = weight2/totalWeight2\n",
        "    return u1,weight1,u2,weight2,factor\n",
        "\n",
        "def EMMedianCI(l,weight,weight1, weight2,factor):\n",
        "    est = EMMedian_new(l,weight)\n",
        "    if show_EM_median_u:\n",
        "      return 0,0,0,est\n",
        "    i1 = np.random.choice(list(range(len(l))), p=weight1)\n",
        "    if i1==int(n/2)+1-factor:\n",
        "        x1= int(l[i1]/n)\n",
        "    if i1<int(n/2)+1-factor:\n",
        "        x1= int(np.random.randint(l[i1], l[i1+1],dtype=np.int64)/n)\n",
        "    if i1>int(n/2)+1-factor:\n",
        "        x1= int(np.random.randint(l[i1-1], l[i1],dtype=np.int64)/n)\n",
        "\n",
        "    i2 = np.random.choice(list(range(len(l))), p=weight2)\n",
        "    if i2==int(n/2)+1+factor:\n",
        "        x2= int(l[i2]/n)\n",
        "    if i2<int(n/2)+1+factor:\n",
        "        x2= int(np.random.randint(l[i2], l[i2+1],dtype=np.int64)/n)\n",
        "    if i2>int(n/2)+1+factor:\n",
        "        x2= int(np.random.randint(l[i2-1], l[i2],dtype=np.int64)/n)\n",
        "\n",
        "\n",
        "    indicator=0\n",
        "    if D[int(n/2)]<=x2 and D[int(n/2)]>=x1:\n",
        "        indicator=1\n",
        "\n",
        "    return x1,x2 ,indicator,est"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "iYqaj0NLo-tw",
      "metadata": {
        "id": "iYqaj0NLo-tw"
      },
      "outputs": [],
      "source": [
        "eps = []\n",
        "beta = []\n",
        "D = []\n",
        "newD = []\n",
        "domain_size = 4000\n",
        "num_repeat = 100\n",
        "b_list_step = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "5cdd1c06",
      "metadata": {
        "id": "5cdd1c06"
      },
      "outputs": [],
      "source": [
        "from json.encoder import INFINITY\n",
        "# Our algorithm\n",
        "#1) Learn noisy median o of distribution using Exponential Mechanism\n",
        "def EM_median(eps,beta,D,domain_size,use_discretized = False):\n",
        "    interval_prob = []\n",
        "    rank_dict = {}\n",
        "    # D = np.array([lowest]) + D\n",
        "    vals, counts = np.unique(D,return_counts=True)\n",
        "    rank = 0\n",
        "    n = len(D)\n",
        "    last_val = vals[-1]\n",
        "    if use_discretized:\n",
        "      last_val += n\n",
        "    else:\n",
        "      last_val += 1\n",
        "    vals = vals.tolist() + [int(last_val)]\n",
        "    counts = counts.tolist() + [0]\n",
        "    cdf = 0.0\n",
        "    weights = []\n",
        "    u = []\n",
        "\n",
        "    for i in range(0,len(vals)-1):\n",
        "      rank += counts[i]\n",
        "      rank_dict[vals[i]] = rank\n",
        "      utility = -1.0* np.abs(rank - n/2)\n",
        "      u.append(utility) # u[i] = utility, corresponding to vals[i]\n",
        "      p = (vals[i+1] - vals[i])* math.pow(np.e, eps*utility/2)\n",
        "      cdf += p\n",
        "      weights.append(p) # weight[i] = p, corresponding to interval [vals[i],vals[i+1])\n",
        "      if use_discretized == 0:\n",
        "        for j in range(counts[i]-1):\n",
        "          weights.append(\".\")\n",
        "          u.append(\".\")\n",
        "      interval_prob.append(cdf) # interval[i-1] = cdf,corresponding to interval (val[i-1],val[i]]\n",
        "    rank_dict[vals[-1]] = rank\n",
        "    # print(\"our weight len\",len(weight))\n",
        "    rand_val = cdf * np.random.uniform(0,1)\n",
        "    rank_o = 0\n",
        "    # print(\"total weights:\",sum(weights))\n",
        "    if (use_discretized == 0):\n",
        "      weight_name = 'our weights'\n",
        "      u_name = 'our u'\n",
        "    else:\n",
        "      weight_name = 'our weights(discre)'\n",
        "      u_name = 'our u(discre)'\n",
        "\n",
        "    for i in range(0,len(vals)-1):\n",
        "        if rand_val <= interval_prob[i]:\n",
        "          o = int(np.random.randint(vals[i], vals[i+1],dtype=np.int64)) # [vals[i],vals[i+1])\n",
        "          rank_o = rank_dict[vals[i]]\n",
        "          break\n",
        "    if show_EM_median_u:\n",
        "      totalWeight = 0\n",
        "      for weight in weights:\n",
        "        try:\n",
        "          totalWeight +=weight\n",
        "        except:\n",
        "          continue\n",
        "      # print(\"totalWeight\",totalWeight)\n",
        "      std_weight = []\n",
        "      for weight in weights:\n",
        "          try:\n",
        "              std_weight.append(weight / totalWeight)\n",
        "          except Exception as e:\n",
        "              std_weight.append(\".\")\n",
        "      df[u_name] = [\".\"] + u + [\".\"]\n",
        "      df[weight_name] = [\".\"] + weights + [\".\"]\n",
        "      df[\"std_\"+weight_name] = [\".\"] + std_weight + [\".\"]\n",
        "    return o,rank_o,rank_dict\n",
        "\n",
        "#2)\n",
        "def find_rank(rank_dict, val, vals=None, ranks=None):\n",
        "    if use_discretized==0 and (val in rank_dict_record.keys()):\n",
        "      return rank_dict_record[val]\n",
        "    elif use_discretized==1 and (val in rank_dict_discretized.keys()):\n",
        "      return rank_dict_discretized[val]\n",
        "        \n",
        "    if vals is None:\n",
        "        vals = list(rank_dict.keys())\n",
        "        ranks = list(rank_dict.values())\n",
        "    if val <= vals[0]:\n",
        "        result = 0\n",
        "    elif val > vals[-1]:\n",
        "        result = ranks[-1]\n",
        "    else:\n",
        "        left, right = 0, len(vals) - 1\n",
        "        while left <= right:\n",
        "            mid = (left + right) // 2\n",
        "            if val > vals[mid]:\n",
        "                left = mid + 1\n",
        "            else:\n",
        "                right = mid - 1\n",
        "        result = ranks[left - 1] if left > 0 else 0\n",
        "\n",
        "    if use_discretized == 0:\n",
        "        rank_dict_record[val] = result\n",
        "    else:\n",
        "        rank_dict_record_discretized[val] = result\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "def SVT_median(o,rank_o,rank_dict,eps,D,domain_size,T,b_list):\n",
        "    # print(\"T: \", T)\n",
        "    noisy_T = T + np.random.laplace(2/eps)\n",
        "    sensitivity = 1\n",
        "    bounds = domain_size\n",
        "    #print(min(o+bounds,domain_size-1))\n",
        "    for b in b_list: #range(0,b_max,step):\n",
        "        perturbed_value = min(abs(find_rank(rank_dict, o+b)-rank_o),abs(find_rank(rank_dict, o-b)-rank_o)) + np.random.laplace(2*sensitivity/eps)\n",
        "        if perturbed_value > noisy_T:\n",
        "            bounds = b\n",
        "            # print(\"b:\",b,\"perturbed_value:\",perturbed_value,\"noisy_T:\",noisy_T)\n",
        "            break\n",
        "    result = max(o-bounds,0),min(o+bounds,D[-1])\n",
        "\n",
        "    return result\n",
        "\n",
        "def find_next_smaller(vals, val):\n",
        "    # special case: return val if val is in vals\n",
        "    if val < vals[0]:\n",
        "      return float('-inf')\n",
        "    left, right = 0, len(vals) - 1\n",
        "    while left <= right:\n",
        "        mid = (left + right) // 2\n",
        "        if val < vals[mid]:\n",
        "            right = mid - 1\n",
        "        else:\n",
        "            left = mid + 1\n",
        "    return vals[left-1]\n",
        "\n",
        "def find_next_larger(vals, val):\n",
        "    # special case: return val if val is in vals\n",
        "    if val > vals[-1]:\n",
        "        return float('inf')\n",
        "    left, right = 0, len(vals) - 1\n",
        "    while left <= right:\n",
        "        mid = (left + right) // 2\n",
        "        if val > vals[mid]:\n",
        "            left = mid + 1\n",
        "        else:\n",
        "            right = mid - 1\n",
        "    return vals[left]\n",
        "        \n",
        "def EMCI(D,o,rank_o,rank_dict,eps,b_list,C1,C2,domain_size,sl_in_u=False,precomputed_vals=None,precomputed_ranks=None):\n",
        "  u = []\n",
        "  fb_list = []\n",
        "  weights = []\n",
        "  interval_prob = []\n",
        "  cdf = 0.0\n",
        "  l = 1\n",
        "  n = len(D)\n",
        "  if len(b_list) >= 1:\n",
        "    step_size = b_list[0]\n",
        "  b_list = list(b_list)\n",
        "\n",
        "  for i in range(0,len(b_list)):\n",
        "    b = b_list[i]\n",
        "    right_bound = abs(find_rank(rank_dict,o+b,vals=precomputed_vals,ranks=precomputed_ranks)-rank_o)\n",
        "    left_bound = abs(find_rank(rank_dict,o-b,vals=precomputed_vals,ranks=precomputed_ranks)-rank_o)\n",
        "    fb = min(left_bound,right_bound)\n",
        "    # print(\"b:\",b/n,\"fb:\",rank_o,left_bound, right_bound)\n",
        "    fb_list.append(fb)\n",
        "\n",
        "    if sl_in_u: utility = -1.0 * abs(fb - C1 - C2)\n",
        "    else: utility = -1.0 * abs(fb - C1 - C2 - step_size*l)\n",
        "    u.append(utility) # huge space required?\n",
        "\n",
        "  sensitivity = 1\n",
        "  for i in range(0, len(b_list)):\n",
        "    utility = u[i]\n",
        "    eps_utility = eps * utility / sensitivity # u is monotonic\n",
        "    p = np.exp(eps_utility)\n",
        "    cdf += p\n",
        "    weights.append(p)\n",
        "    interval_prob.append(float(cdf))\n",
        "\n",
        "  if show_EMCI_u:\n",
        "    original_b = [b/n for b in b_list]\n",
        "    df['b'] = original_b\n",
        "    df['b'] = b_list\n",
        "    df['fb'] = ['.']+fb_list\n",
        "    df['utility'] = ['.']+u\n",
        "    df['weight'] = ['.']+weights\n",
        "    df['interval_prob'] = ['.']+interval_prob\n",
        "\n",
        "  rand_val = cdf * np.random.uniform(0,1)\n",
        "  # print(\"rand_val:\",rand_val)\n",
        "  bounds = domain_size\n",
        "  for i in range(0,len(b_list)-1):\n",
        "    b = b_list[i+1]\n",
        "    if rand_val <= interval_prob[i]:\n",
        "      # bounds = int(np.random.randint(b_list[i]+1, b_list[i+1]+1,dtype=np.int64))\n",
        "      bounds = b\n",
        "      break\n",
        "  # print(\"bounds:\",bounds)\n",
        "  # print(o,o+bounds)\n",
        "  if sl_in_u:\n",
        "    result = max(o-bounds,0),min(o+bounds,D[-1])\n",
        "  else:\n",
        "    result = max(o-bounds-step_size*l,0),min(o+bounds+step_size*l,D[-1])\n",
        "  # result = max(o-bounds-step_size,0),min(o+bounds,D[-1])\n",
        "  return result\n",
        "\n",
        "\n",
        "def EMCI_new(D,o,rank_o,rank_dict,eps,b_list,C1,C2,domain_size,sl_in_u=False,precomputed_vals=None,precomputed_ranks=None):\n",
        "  cdf = 0.0\n",
        "  l = 1\n",
        "  sensitivity = 1\n",
        "  n = len(D)\n",
        "  step_size = b_list[0]\n",
        "  interval_prob = []\n",
        "  # b has the same fb value for b in interval [b1,b2] \n",
        "  \n",
        "  b = b_list[0]\n",
        "  rank_1 = find_rank(rank_dict, o-b, vals=precomputed_vals, ranks=precomputed_ranks)\n",
        "  rank_2 = find_rank(rank_dict, o+b, vals=precomputed_vals, ranks=precomputed_ranks)\n",
        "  pre_fb = min(abs(rank_1 - rank_o), abs(rank_2 - rank_o))\n",
        "  next_smaller = find_next_smaller(precomputed_vals, o-b)\n",
        "  next_larger = find_next_larger(precomputed_vals, o+b)\n",
        "  b_intervals = []\n",
        "  interval_start = b\n",
        "  for i in range(1,len(b_list)):\n",
        "    b = b_list[i]\n",
        "    if o-b >= next_smaller and o+b < next_larger:\n",
        "      # skip the case b has the same fb value as the previous b\n",
        "      # since rank(o+b) and rank(o-b) stays same\n",
        "      continue\n",
        "\n",
        "\n",
        "    rank_1 = find_rank(rank_dict, o-b, vals=precomputed_vals, ranks=precomputed_ranks)\n",
        "    rank_2 = find_rank(rank_dict, o+b, vals=precomputed_vals, ranks=precomputed_ranks)\n",
        "    fb = min(abs(rank_1 - rank_o), abs(rank_2 - rank_o))\n",
        "    if fb != pre_fb:\n",
        "      # new fb value\n",
        "      interval_end = b_list[i-1] + 1\n",
        "      b_intervals.append((interval_start, interval_end))\n",
        "      utility = -1.0 * abs(pre_fb - C1 - C2 - step_size*l)\n",
        "      eps_utility = eps * utility / sensitivity # u is monotonic\n",
        "      p = (interval_end - interval_start + 1) * np.exp(eps_utility)\n",
        "      cdf += p\n",
        "      interval_prob.append(float(cdf))\n",
        "      interval_start = b # set the start of the next interval\n",
        "      pre_fb = fb\n",
        "  if not b_intervals or b_intervals[-1][1] != b_list[-1]: # b_list[-1] has the same fb value as the previous b\n",
        "    # Add last interval\n",
        "    interval_end = b_list[-1]\n",
        "    b_intervals.append((interval_start, interval_end))\n",
        "    utility = -1.0 * abs(pre_fb - C1 - C2 - step_size*l)\n",
        "    eps_utility = eps * utility / sensitivity # u is monotonic\n",
        "    p = np.exp(eps_utility)\n",
        "    cdf += p\n",
        "    interval_prob.append(float(cdf))\n",
        "  \n",
        "  # find b\n",
        "  print(\"D:\",D)\n",
        "  print(\"o:\",o)\n",
        "  print(\"b_list:\",b_list)\n",
        "  print(\"b_intervals:\",b_intervals)\n",
        "  print(\"interval_prob:\",interval_prob)\n",
        "\n",
        "  # Verify fb values in the same interval\n",
        "  for i, interval in enumerate(b_intervals):\n",
        "      start, end = interval\n",
        "      fb_values = set()\n",
        "      for b in range(start, end):\n",
        "          rank_1 = find_rank(rank_dict, o-b, vals=precomputed_vals, ranks=precomputed_ranks)\n",
        "          rank_2 = find_rank(rank_dict, o+b, vals=precomputed_vals, ranks=precomputed_ranks) \n",
        "          fb = min(abs(rank_1 - rank_o), abs(rank_2 - rank_o))\n",
        "          fb_values.add(fb)\n",
        "      if len(fb_values) == 1:\n",
        "          print(f\"Interval {interval} has the same fb value: {fb_values}\")\n",
        "      else:\n",
        "          print(f\"Warning: Interval {interval} has different fb values: {fb_values}\")\n",
        "\n",
        "  rand_val = cdf * np.random.uniform(0,1)\n",
        "  bounds = domain_size/2\n",
        "  for i in range(0,len(b_intervals)):\n",
        "    if rand_val <= interval_prob[i]:\n",
        "      interval = b_intervals[i]\n",
        "      b = np.random.randint(interval[0], interval[1])\n",
        "      bounds = b\n",
        "      break\n",
        "  if sl_in_u:\n",
        "    result = max(o-bounds,0),min(o+bounds,D[-1])\n",
        "  else:\n",
        "    result = max(o-bounds-step_size*l,0),min(o+bounds+step_size*l,D[-1])\n",
        "  return result\n",
        "        \n",
        "        \n",
        "\n",
        "def Their_EMMedian_modified(l,weight,D):\n",
        "    n = len(D)\n",
        "    vals, counts = np.unique(D,return_counts=True)\n",
        "    rank_dict = {}\n",
        "    rank_dict_record = {}\n",
        "    rank = 0\n",
        "    last_val = vals[-1]\n",
        "    if use_discretized:\n",
        "      last_val += n\n",
        "    else:\n",
        "      last_val += 1\n",
        "    vals = vals.tolist() + [int(last_val)]\n",
        "    counts = counts.tolist() + [0]\n",
        "    for i in range(0,len(vals)-1):\n",
        "        rank += counts[i]\n",
        "        rank_dict[vals[i]] = rank\n",
        "    rank_dict[vals[-1]] = rank\n",
        "    i = np.random.choice(list(range(len(l))), p=weight)\n",
        "    # only return int\n",
        "    val = 0\n",
        "    if i==int(n/2)+1:\n",
        "      val = int(l[i])\n",
        "    if i<int(n/2)+1:\n",
        "      val = int(np.random.randint(l[i], l[i+1],dtype=np.int64))\n",
        "    if i>int(n/2)+1:\n",
        "      val = int(np.random.randint(l[i-1], l[i],dtype=np.int64))\n",
        "      i=i-1\n",
        "    # print(\"est_med:\",val/n)\n",
        "    return val,i,rank_dict #rank_dict is from global variable\n",
        "\n",
        "##### main function ######\n",
        "\n",
        "def our_CI(D,domain_size,b_list,med_method=0,CI_method=0,l=[],weight=[],sl_in_u=False):\n",
        "    if len(b_list) >= 1:\n",
        "      step_size = b_list[0]\n",
        "    m = len(b_list)\n",
        "    alpha = (8*np.log(m)+np.log(2/beta_2)) / eps_2\n",
        "    C = (2/eps_1) *(np.log(domain_size/beta_1)) # γ\n",
        "    C2 = (1/eps_2) *(np.log(domain_size/(b_list_step*beta_2)))\n",
        "    # print(\"C1=\",C,\"C2=\",C2)\n",
        "    #print(\"alpha\", alpha)\n",
        "    T = C + alpha\n",
        "    if (med_method==0):\n",
        "      o,rank_o,rank_dict = EM_median(eps_1,beta_1,D,domain_size) #our EM\n",
        "    elif (med_method==1):\n",
        "      o,rank_o,rank_dict = Their_EMMedian_modified(l,weight,D) #their EM\n",
        "    if (CI_method==0):\n",
        "      lower,upper = SVT_median(o,rank_o,rank_dict,eps_2,D,domain_size,T,b_list)\n",
        "    elif (CI_method==1):\n",
        "      precomputed_vals = list(rank_dict.keys())\n",
        "      precomputed_ranks = list(rank_dict.values())\n",
        "      lower,upper = EMCI(D,o,rank_o,rank_dict,eps_2,b_list,C,C2,domain_size,sl_in_u,precomputed_vals,precomputed_ranks)\n",
        "    elif (CI_method==2):\n",
        "      precomputed_vals = list(rank_dict.keys())\n",
        "      precomputed_ranks = list(rank_dict.values())\n",
        "      lower,upper = EMCI_new(D,o,rank_o,rank_dict,eps_2,b_list,C,C2,domain_size,sl_in_u,precomputed_vals,precomputed_ranks)\n",
        "    else:\n",
        "      lower,upper = 0,0 # do not run CI algorithm\n",
        "    #print(\"median:\",o)\n",
        "    #print(\"The bounds are:\")\n",
        "    #print('[{},{}]'.format(lower,upper))\n",
        "    indi = -1 #if CI contains true med\n",
        "    if (use_discretized == 1):\n",
        "      if lower < D[0]: lower = D[0]\n",
        "      if upper > D[-1]: upper = D[-1]\n",
        "      lower,upper = int(lower/n),int(upper/n)\n",
        "      o = int(o/n)\n",
        "\n",
        "    # if true_med < upper and true_med > lower:\n",
        "    if true_med <= upper and true_med >= lower: #new\n",
        "        indi = 1\n",
        "    else:\n",
        "        indi = 0\n",
        "    return lower,upper,indi,o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c742116c",
      "metadata": {
        "id": "c742116c"
      },
      "outputs": [],
      "source": [
        "def test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,compare=False,output=[],med_method=0,CI_method=0,name=\"\",sl_in_u = False):\n",
        "  # med_method: 0 use our EM\n",
        "  #      : 1 use their EM (use_discretized must = 1)\n",
        "  domain_size = int(max(D)-min(D))\n",
        "  if (use_discretized == 1):\n",
        "    # b_list_step *= n\n",
        "    b_list = range(b_list_step, b_list_step*int(domain_size/b_list_step)+1,b_list_step)\n",
        "\n",
        "    u,l,weight = [],[],[]\n",
        "    if (len(b_list) == 0): b_list = range(0,2)\n",
        "    if (med_method == 1):\n",
        "      rad = 10000000\n",
        "      left = -rad\n",
        "      u,l,weight=constructu(eps_1,left*n,rad*n, D,sensitivity = 1)\n",
        "  else:\n",
        "    # b_list = range(0, domain_size, b_list_step)\n",
        "    b_list = range(b_list_step, b_list_step*int(domain_size/b_list_step)+1,b_list_step)\n",
        "    l = 0\n",
        "    weight = []\n",
        "  len_eps = []\n",
        "  err_eps = []\n",
        "  est_median = []\n",
        "  times = []\n",
        "  ranks = []\n",
        "  lengths = []\n",
        "  errors = []\n",
        "  rank_errors_1 = [] # based on n/2\n",
        "  rank_errors_2 = [] # based on find_rank(rank_dict,true_med)\n",
        "  rank_CI_lengths = []\n",
        "  # est_list = []\n",
        "  med_rank = int(find_rank(rank_dict, true_med))\n",
        "  # print(\"rank_dict:\",rank_dict)\n",
        "  # print(\"med_rank:\",med_rank)\n",
        "  for i in range(len(beta)):\n",
        "      print(\"Results for EM based median, beta = \"+str(beta[i]))\n",
        "      correct_count = 0\n",
        "\n",
        "      for j in range(num_repeat):\n",
        "          start = time.time()\n",
        "          # xl,xr,indi,est = 0,0,0,0\n",
        "          xl,xr,indi,est = our_CI(D,domain_size,b_list,med_method,CI_method,l,weight,sl_in_u)\n",
        "          end = time.time()\n",
        "          times.append(end-start)\n",
        "          correct_count+=indi\n",
        "          lengths.append((xr-xl)/(2))\n",
        "          # print(xr,xl)\n",
        "          # interesting and subtle difference!\n",
        "          # mid_value = (xr+xl)/2\n",
        "          errors.append(abs(est-true_med))\n",
        "          est_median.append(est)\n",
        "          rank = int(find_rank(rank_dict, est))\n",
        "          ranks.append(rank)\n",
        "          rank_errors_1.append(int(abs(n/2 - rank)))\n",
        "          rank_errors_2.append(int(abs(med_rank - rank)))\n",
        "      original_errors = errors\n",
        "      errors = np.array(errors, dtype=object)\n",
        "      correct_rate = correct_count/num_repeat\n",
        "      avgLength = sum(lengths)/num_repeat\n",
        "      errors.sort()\n",
        "      errorQuantile = errors[int(num_repeat*(1-beta[i]))]\n",
        "      avg_error = np.average(errors)\n",
        "      avgTime = sum(times)/len(times)\n",
        "\n",
        "      # rank CI length\n",
        "      rank_lower = int(find_rank(rank_dict,xl))\n",
        "      rank_upper = int(find_rank(rank_dict,xr))\n",
        "      rank_CI_length = (rank_upper-rank_lower)/2\n",
        "      rank_CI_lengths.append(rank_CI_length)\n",
        "\n",
        "\n",
        "      # output medians and error\n",
        "\n",
        "      #download errors\n",
        "      # df = pd.DataFrame(errors)\n",
        "      # file_name = f\"data_error.csv\"\n",
        "      # df.to_csv(file_name, index=False, header=False)\n",
        "      # files.download(file_name)\n",
        "\n",
        "      # median_error\n",
        "      if np.all(errors == errors[0]):\n",
        "          stddev_based_avg_err = errors[0]\n",
        "          IQR_based_avg_err = errors[0]\n",
        "      else:\n",
        "          std_dev = np.std(errors)\n",
        "          stddev_based_avg_err = np.average(errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "          q1 = np.percentile(errors, 25)\n",
        "          q3 = np.percentile(errors, 75)\n",
        "          iqr = q3 - q1\n",
        "          lower_bound = q1 - 1.5 * iqr\n",
        "          upper_bound = q3 + 1.5 * iqr\n",
        "          IQR_based_avg_err = np.average(errors[(errors >= lower_bound) & (errors <= upper_bound)])\n",
        "      # rank_error\n",
        "      avg_rank_error_1 = np.average(rank_errors_1)\n",
        "      avg_rank_error_2 = np.average(rank_errors_2)\n",
        "\n",
        "      # avg rank CI length\n",
        "      avg_rank_CI_length = np.average(rank_CI_lengths)\n",
        "\n",
        "      if name==\"\":\n",
        "        name = \"our_CI\"\n",
        "        if (use_discretized == 1):\n",
        "          name = \"our_CI(discretized)\"\n",
        "          domain_size = int(domain_size/n)\n",
        "          if (med_method == 1): name = \"our_CI(their EM)\"\n",
        "      if (errorQuantile == 0): relative_CI_width = -1\n",
        "      else: relative_CI_width = avgLength / errorQuantile\n",
        "      print(\"last experiment CI:\",xl,xr)\n",
        "      print(\"avg estimated median value: \"+ str(np.average(est_median)))\n",
        "      print(\"avg median error: \"+ str(avg_error))\n",
        "      print(\"correct rate = \", correct_rate)\n",
        "      print(\"Average CI length = \"+str(avgLength))\n",
        "      print(\"error quantile is \"+ str(errorQuantile))\n",
        "      print(\"CI length/ error quantile = \"+str(relative_CI_width))\n",
        "      print(\"Average Time to find CI = \" + str(avgTime))\n",
        "\n",
        "\n",
        "      row_data = [\n",
        "          name,\n",
        "          data_uuid,\n",
        "          n,\n",
        "          domain_size,\n",
        "          sens,\n",
        "          beta[i],\n",
        "          eps[i],\n",
        "          num_repeat,\n",
        "          true_med,\n",
        "          np.average(est_median),\n",
        "          correct_rate,\n",
        "          avgLength,\n",
        "          errorQuantile,\n",
        "          avg_error,\n",
        "          stddev_based_avg_err,\n",
        "          IQR_based_avg_err,\n",
        "          avg_rank_error_1,\n",
        "          avg_rank_error_2,\n",
        "          relative_CI_width,\n",
        "          avg_rank_CI_length,\n",
        "          avgTime,\n",
        "          b_list_step,\n",
        "          beta_1,\n",
        "          beta_2,\n",
        "          eps_1,\n",
        "          eps_2\n",
        "      ]\n",
        "      if (output_mode == 0 or output_mode == 2):\n",
        "        write_to_sheet(worksheet1, row_data, output_mode=output_mode, compare=compare)\n",
        "\n",
        "      # New! Check all medians and errors\n",
        "      if (output_mode == 1 or output_mode == 2):\n",
        "        sorted_med = sorted(est_median)\n",
        "        est_median.insert(0, \"Our est_median\")\n",
        "        sorted_med.insert(0, \"Sorted Our est_median\")\n",
        "\n",
        "        sorted_errors = sorted(original_errors)\n",
        "        original_errors.insert(0, \"Our errors\")\n",
        "        sorted_errors.insert(0, \"Sorted Our errors\")\n",
        "\n",
        "        sorted_ranks = sorted(ranks)\n",
        "        ranks.insert(0, \"Our ranks\")\n",
        "        sorted_ranks.insert(0, \"Sorted Our ranks\")\n",
        "\n",
        "        sorted_lengths = sorted(lengths)\n",
        "        lengths.insert(0,\"Our CI lengths\")\n",
        "        sorted_lengths.insert (0, \"Sorted Our CI lengths\")\n",
        "\n",
        "        sorted_re_1 = sorted(rank_errors_1)\n",
        "        sorted_re_2 = sorted(rank_errors_2)\n",
        "        rank_errors_1.insert(0, \"Our rank_errors(n/2)\")\n",
        "        rank_errors_2.insert(0, \"Our rank_errors(find)\")\n",
        "        sorted_re_1.insert(0, \"Sorted Our rank_errors(n/2)\")\n",
        "        sorted_re_2.insert(0, \"Sorted Our rank_errors(find)\")\n",
        "\n",
        "\n",
        "        data_uid_row = [\"data:\", data_uuid, \"method:\", \"Our_CI\"]\n",
        "        true_med_row = [\"true median\"]+[true_med]*num_repeat\n",
        "        n_over_2_row = [\"true n/2\"] + [n/2]*num_repeat\n",
        "        med_rank_row = [\"true med_rank(find)\"] + [med_rank]*num_repeat\n",
        "\n",
        "        worksheet.append_row(data_uid_row)\n",
        "        worksheet.append_row(est_median)\n",
        "        worksheet.append_row(true_med_row)\n",
        "        worksheet.append_row(original_errors)\n",
        "        # write_to_sheet(worksheet1, errors, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(ranks)\n",
        "        worksheet.append_row(n_over_2_row)\n",
        "        worksheet.append_row(rank_errors_1)\n",
        "        # write_to_sheet(worksheet1, rank_errors_1, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(med_rank_row)\n",
        "        worksheet.append_row(rank_errors_2)\n",
        "        worksheet.append_row(lengths)\n",
        "\n",
        "        # write_to_sheet(worksheet1, rank_errors_2, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(sorted_med)\n",
        "        worksheet.append_row(sorted_ranks)\n",
        "        worksheet.append_row(sorted_errors)\n",
        "        worksheet.append_row(sorted_re_1)\n",
        "        worksheet.append_row(sorted_re_2)\n",
        "        worksheet.append_row(sorted_lengths)\n",
        "\n",
        "      len_eps.append(avgLength)\n",
        "      err_eps.append(errorQuantile)\n",
        "      if (output_mode == 3):\n",
        "        output = row_data\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "490b3cbd",
      "metadata": {
        "id": "490b3cbd"
      },
      "outputs": [],
      "source": [
        "def test_theirs(eps=eps, beta=beta, num_repeat=num_repeat, D=newD,median_method = 0,compare = False,output=[],sensitivity=0.5):\n",
        "  #median_method = 0:median from CI algorithm\n",
        "  #        = 1:median from EMMedianCI\n",
        "  n = len(newD)\n",
        "  domain_size = int((max(D)-min(D))/n)\n",
        "  len_eps = []\n",
        "  err_eps = []\n",
        "  est_median = []\n",
        "  times = []\n",
        "  ranks = []\n",
        "  EM_median_errors = []\n",
        "  med_rank = int(find_rank(rank_dict, true_med))\n",
        "  est_list = []\n",
        "  rank_errors_1 = [] # based on n/2\n",
        "  rank_errors_2 = [] # based on find_rank(rank_dict,true_med)\n",
        "  rank_CI_lengths = []\n",
        "  for i in range(len(beta)):\n",
        "      print(\"Results for EM based median, beta = \"+str(beta[i]))\n",
        "      errors = []\n",
        "      lengths = []\n",
        "      correct_count = 0\n",
        "      rad = 10000000\n",
        "      left=-rad\n",
        "      u,l,weight = constructu(eps[i], left*n,rad*n, newD,sensitivity=sensitivity)\n",
        "      u1,weight1,u2,weight2,factor = constructu_CI(eps[i],beta[i], rad,u,l,sensitivity=sensitivity)\n",
        "      for j in range(num_repeat):\n",
        "          start = time.time()\n",
        "          xl,xr,indi,est = EMMedianCI(l,weight,weight1,weight2,factor)\n",
        "          end = time.time()\n",
        "          times.append(end-start)\n",
        "          correct_count+=indi\n",
        "          lengths.append((xr-xl)/(2))\n",
        "          if (median_method == 0):\n",
        "            their_median = (xr+xl)/2\n",
        "          else:\n",
        "            their_median = est\n",
        "          est_median.append(their_median)\n",
        "          errors.append(abs(their_median-true_med))\n",
        "          EM_median_errors.append(abs(est-true_med)) # their def of errors\n",
        "          rank = int(find_rank(rank_dict, their_median))\n",
        "          ranks.append(rank)\n",
        "          rank_errors_1.append(int(abs(n/2 - rank)))\n",
        "          rank_errors_2.append(int(abs(med_rank - rank)))\n",
        "\n",
        "          # rank CI length\n",
        "          rank_lower = int(find_rank(rank_dict,xl))\n",
        "          rank_upper = int(find_rank(rank_dict,xr))\n",
        "          rank_CI_length = (rank_upper-rank_lower)/2\n",
        "          rank_CI_lengths.append(rank_CI_length)\n",
        "\n",
        "      original_errors = errors\n",
        "      errors = np.array(errors, dtype=object)\n",
        "      correct_rate = correct_count/num_repeat\n",
        "      avgLength = sum(lengths)/num_repeat\n",
        "      errors.sort()\n",
        "      errorQuantile = errors[int(num_repeat*(1-beta[i]))]\n",
        "\n",
        "      avgTime = sum(times)/len(times)\n",
        "\n",
        "\n",
        "      errors = np.array(errors)\n",
        "      avg_error = np.average(errors)\n",
        "      if (errorQuantile == 0): relative_CI_width = -1\n",
        "      else: relative_CI_width = avgLength / errorQuantile\n",
        "      if np.all(errors == errors[0]):\n",
        "          stddev_based_avg_err = errors[0]\n",
        "          IQR_based_avg_err = errors[0]\n",
        "      else:\n",
        "          std_dev = np.std(errors)\n",
        "          stddev_based_avg_err = np.average(errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "\n",
        "          q1 = np.percentile(errors, 25)\n",
        "          q3 = np.percentile(errors, 75)\n",
        "          iqr = q3 - q1\n",
        "          lower_bound = q1 - 1.5 * iqr\n",
        "          upper_bound = q3 + 1.5 * iqr\n",
        "          IQR_based_avg_err = np.average(errors[(errors >= lower_bound) & (errors <= upper_bound)])\n",
        "\n",
        "      #rank_error avg\n",
        "      avg_rank_error_1 = np.average(rank_errors_1)\n",
        "      avg_rank_error_2 = np.average(rank_errors_2)\n",
        "      print(\"Filtered Errors for IQR_based_avg_err:\", IQR_based_avg_err)\n",
        "      # avg rank CI length\n",
        "      avg_rank_CI_length = np.average(rank_CI_lengths)\n",
        "\n",
        "      print(\"estimated median value: \"+ str(np.average(est_median)))\n",
        "      print(\"correct rate = \" +str(correct_count/num_repeat))\n",
        "      print(\"Average CI length = \"+str(avgLength))\n",
        "      print(\"error quantile is \"+ str(errorQuantile))\n",
        "      print(\"CI length/ error quantile = \"+str(avgLength/errorQuantile))\n",
        "      print(\"Average Time to find CI = \" + str(sum(times)/len(times)))\n",
        "      # print(\"Errors:\", errors)\n",
        "      # print(\"Standard Deviation:\", std_dev)\n",
        "      # print(\"Filtered Errors for stddev_based_avg_err:\", errors[np.abs(errors - avg_error) < 3 * std_dev])\n",
        "\n",
        "      # print(\"Q1:\", q1, \"Q3:\", q3)\n",
        "      # print(\"IQR:\", iqr)\n",
        "      # print(\"Lower Bound:\", lower_bound, \"Upper Bound:\", upper_bound)\n",
        "      if (median_method == 0):\n",
        "        name = \"EM_CI\"\n",
        "      else:\n",
        "        name = \"EM\"\n",
        "      row_data = [\n",
        "          name,\n",
        "          data_uuid,\n",
        "          n,\n",
        "          domain_size, #3\n",
        "          sens, #4\n",
        "          beta[i],#5\n",
        "          eps[i], #6\n",
        "          num_repeat, #7\n",
        "          true_med, #8\n",
        "          np.average(est_median), #9\n",
        "          correct_rate, #10\n",
        "          avgLength, #11\n",
        "          errorQuantile, #12\n",
        "          avg_error,#13\n",
        "          stddev_based_avg_err, #14\n",
        "          IQR_based_avg_err, #15\n",
        "          avg_rank_error_1, #16\n",
        "          avg_rank_error_2, #17\n",
        "          relative_CI_width, #18\n",
        "          avg_rank_CI_length, #19\n",
        "          avgTime\n",
        "      ]\n",
        "      if (output_mode == 0 or output_mode == 2):\n",
        "        write_to_sheet(worksheet1, row_data, compare = compare)\n",
        "\n",
        "      if (output_mode == 1 or output_mode == 2):\n",
        "        sorted_med = sorted(est_median)\n",
        "        est_median.insert(0, \"EM est_median\")\n",
        "        sorted_med.insert(0, \"Sorted EM est_median\")\n",
        "\n",
        "        sorted_errors = sorted(original_errors)\n",
        "        original_errors.insert(0, \"EM errors\")\n",
        "        sorted_errors.insert(0, \"Sorted EM errors\")\n",
        "\n",
        "        sorted_ranks = sorted(ranks)\n",
        "        ranks.insert(0, \"EM ranks\")\n",
        "        sorted_ranks.insert(0, \"Sorted EM ranks\")\n",
        "\n",
        "        sorted_re_1 = sorted(rank_errors_1)\n",
        "        sorted_re_2 = sorted(rank_errors_2)\n",
        "        rank_errors_1.insert(0, \"EM rank_errors(n/2)\")\n",
        "        rank_errors_2.insert(0, \"EM rank_errors(find)\")\n",
        "        sorted_re_1.insert(0, \"Sorted EM rank_errors(n/2)\")\n",
        "        sorted_re_2.insert(0, \"Sorted EM rank_errors(find)\")\n",
        "\n",
        "        sorted_lengths = sorted(lengths)\n",
        "        lengths.insert(0,\"EM CI lengths\")\n",
        "        sorted_lengths.insert (0, \"Sorted EM CI lengths\")\n",
        "\n",
        "        data_uid_row = [\"data:\", data_uuid, \"method:\", \"EM_CI\"]\n",
        "        true_med_row = [\"true median\"]+[true_med]*num_repeat\n",
        "        n_over_2_row = [\"true n/2\"] + [n/2]*num_repeat\n",
        "        med_rank_row = [\"true med_rank(find)\"] + [med_rank]*num_repeat\n",
        "\n",
        "        print(est_list)\n",
        "        worksheet.append_row(data_uid_row)\n",
        "        worksheet.append_row(est_median)\n",
        "        worksheet.append_row(true_med_row)\n",
        "\n",
        "        worksheet.append_row(original_errors)\n",
        "        # write_to_sheet(worksheet1, original_errors, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(ranks)\n",
        "        worksheet.append_row(n_over_2_row)\n",
        "        worksheet.append_row(rank_errors_1)\n",
        "        # write_to_sheet(worksheet1, rank_errors_1, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(med_rank_row)\n",
        "        worksheet.append_row(rank_errors_2)\n",
        "        worksheet.append_row(lengths)\n",
        "        # write_to_sheet(worksheet1, rank_errors_2, output_mode=output_mode, compare=compare)\n",
        "        worksheet.append_row(sorted_med)\n",
        "        worksheet.append_row(sorted_ranks)\n",
        "        worksheet.append_row(sorted_errors)\n",
        "        worksheet.append_row(sorted_re_1)\n",
        "        worksheet.append_row(sorted_re_2)\n",
        "        worksheet.append_row(sorted_lengths)\n",
        "\n",
        "\n",
        "\n",
        "      len_eps.append(avgLength)\n",
        "      err_eps.append(errorQuantile)\n",
        "      print(len_eps)\n",
        "      print(err_eps)\n",
        "      if (output_mode == 3):\n",
        "        output = row_data\n",
        "      return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "-xoDZUe5Or-N",
      "metadata": {
        "id": "-xoDZUe5Or-N"
      },
      "outputs": [],
      "source": [
        "def readInput(mode,read_data_uuid=\"64b7c8bf89f14113bd12f5f15e276546\"):\n",
        "    import numpy as np\n",
        "    file_paths = {\n",
        "        0: (\"./bank_marketing.csv\", 5),\n",
        "        1: (\"./adult.csv\", 2),\n",
        "        2: (\"./sample_data/california_housing_test.csv\", 3),\n",
        "        3: (\"./sample_data/california_housing_test.csv\", 8),\n",
        "        5: (\"./ratings_small.csv\",3),\n",
        "        6: (\"./airplane_price_dataset.csv\",1),\n",
        "        7: (\"./airplane_price_dataset.csv\",2),\n",
        "        8: (\"./airplane_price_dataset.csv\",3),\n",
        "        9: (\"./airplane_price_dataset.csv\",4),\n",
        "        10: (\"./data_\"+read_data_uuid+\".csv\",0),\n",
        "        11: (\"./healthcare.csv\",1),\n",
        "        12: (\"./healthcare.csv\",2),\n",
        "        13: (\"./Estate_Sales.csv\",1),\n",
        "        14: (\"./Estate_Sales.csv\",2)\n",
        "    }\n",
        "\n",
        "    if mode not in file_paths:\n",
        "        raise ValueError(\"Invalid mode. Choose between 0 to 3\")\n",
        "\n",
        "    input_path, column_index = file_paths[mode]\n",
        "    if Run_Locally:\n",
        "       input_path = \"./Data\"+input_path[1:]\n",
        "    with open(input_path, 'r',errors='ignore') as input_file:\n",
        "        lines = input_file.readlines()\n",
        "    n = len(lines)\n",
        "    # D = np.zeros(n)\n",
        "    D = np.zeros(n-1) #new! there are n-1 data points\n",
        "    for i, line in enumerate(lines):\n",
        "        if i > 0:\n",
        "            elements = line.split(\",\")\n",
        "            try:\n",
        "                value = float(elements[column_index])\n",
        "                D[i - 1] = int(value)\n",
        "            except ValueError:\n",
        "              if (column_index < len(elements)):\n",
        "                print(f\"Skipping invalid data at line {i}: {elements[column_index]}\")\n",
        "    return D\n",
        "\n",
        "def normalize_non_negative(D):\n",
        "  if lowest<0:\n",
        "    D = [d-lowest for d in D]\n",
        "  return D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "aV2Tp7gg_Nl8",
      "metadata": {
        "id": "aV2Tp7gg_Nl8"
      },
      "outputs": [],
      "source": [
        "def color_vertically(worksheet,col=10,smaller_better=True,row_number=4):\n",
        "  # row_number: number of rows you want to colour\n",
        "  # Define the column indices\n",
        "  col_true = 9\n",
        "  values_I = worksheet.col_values(col_true)\n",
        "  values_col = worksheet.col_values(col)\n",
        "\n",
        "  # Extract the last k rows (ensuring they are numeric)\n",
        "  last_4_true = [float(values_I[-row_number + i]) for i in range(row_number)]\n",
        "  last_4_vals = [float(values_col[-row_number + i]) for i in range(row_number)]\n",
        "\n",
        "  if (col==10):\n",
        "    diffs = [abs(last_4_vals[i] - last_4_true[i]) for i in range(row_number)]\n",
        "  else:\n",
        "    diffs = last_4_vals\n",
        "\n",
        "  # Rank differences from smallest to largest\n",
        "  if smaller_better:\n",
        "      sorted_indices = sorted(range(len(diffs)), key=lambda k: diffs[k])\n",
        "  else:\n",
        "      sorted_indices = sorted(range(len(diffs)), key=lambda k: diffs[k], reverse=True)\n",
        "\n",
        "\n",
        "  # Define colors for ranking\n",
        "  colors = [\n",
        "    {\"red\": 0.0, \"green\": 1.0, \"blue\": 0.0},  # Green (best)\n",
        "    {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6},  # Light Green\n",
        "    {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6},  # Light Red\n",
        "    {\"red\": 1.0, \"green\": 0.0, \"blue\": 0.0},  # Red (worst)\n",
        "  ]\n",
        "\n",
        "  # Get the last 4 row indices\n",
        "  base_row = len(values_col) - row_number+1  # First of the last 4 rows (1-based index)\n",
        "\n",
        "  # Apply formatting\n",
        "  for rank, index in enumerate(sorted_indices):\n",
        "    row = base_row + index  # Correct row number\n",
        "    cell = f\"{chr(64 + col)}{row}\"  # Convert column number to letter (J)\n",
        "    worksheet.format(cell, {\"backgroundColor\": colors[rank]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ZIngr9znP4Vp",
      "metadata": {
        "id": "ZIngr9znP4Vp"
      },
      "outputs": [],
      "source": [
        "def color_horizontally(worksheet,col_n=4,starting_col = 2):\n",
        "    #starting_col starts from 1\n",
        "    col_end = starting_col + col_n - 1\n",
        "\n",
        "    # Get the last row values from Column B to Column E\n",
        "    last_row = worksheet.row_values(len(worksheet.get_all_values()))\n",
        "    # Convert the values to floats (or int if appropriate)\n",
        "    values_b_to_end = [float(value) for value in last_row[starting_col - 1:col_end]]  # Ensure values are numeric\n",
        "\n",
        "    # Define colors for ranking\n",
        "    colors = [\n",
        "        {\"red\": 0.0, \"green\": 1.0, \"blue\": 0.0},  # Green (min)\n",
        "        {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6},  # Light Green (2nd smallest)\n",
        "        {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6},  # Light Red\n",
        "        {\"red\": 1.0, \"green\": 0.0, \"blue\": 0.0},  # Red (max)\n",
        "    ]\n",
        "    if col_n==3:\n",
        "      colors = [\n",
        "        {\"red\": 0.0, \"green\": 1.0, \"blue\": 0.0},  # Green (min)\n",
        "        {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6},  # Light Green (2nd smallest\n",
        "        {\"red\": 1.0, \"green\": 0.0, \"blue\": 0.0},  # Red (max)\n",
        "      ]\n",
        "    if col_n==5:\n",
        "      colors = [\n",
        "        {\"red\": 0.0, \"green\": 1.0, \"blue\": 0.0},  # Green (min)\n",
        "        {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6},  # Light Green (2nd smallest)\n",
        "        {\"red\": 1.0, \"green\": 1.0, \"blue\": 1.0},\n",
        "        {\"red\": 1.0, \"green\": 0.6, \"blue\": 0.6},  # Light Red\n",
        "        {\"red\": 1.0, \"green\": 0.0, \"blue\": 0.0},  # Red (max)\n",
        "      ]\n",
        "\n",
        "    if col_n == 7:\n",
        "      colors = [\n",
        "          {\"red\": 0.0, \"green\": 1.0, \"blue\": 0.0},  # Pure Green\n",
        "          {\"red\": 0.4, \"green\": 0.8, \"blue\": 0.4},  # Darker Green\n",
        "          {\"red\": 0.6, \"green\": 1.0, \"blue\": 0.6},  # Light Green\n",
        "          {\"red\": 1.0, \"green\": 1.0, \"blue\": 1.0},  # White\n",
        "          {\"red\": 1.0, \"green\": 0.8, \"blue\": 0.8},  # Light Red\n",
        "          {\"red\": 1.0, \"green\": 0.5, \"blue\": 0.5},  # Darker Red\n",
        "          {\"red\": 1.0, \"green\": 0.0, \"blue\": 0.0}   # Pure Red\n",
        "      ]\n",
        "\n",
        "    # Sort the values and map them to their ranks\n",
        "    sorted_indices = sorted(range(len(values_b_to_end)), key=lambda k: values_b_to_end[k])\n",
        "    rank_map = {sorted_indices[i]: i for i in range(len(sorted_indices))}  # Map index to rank\n",
        "\n",
        "    # Get the column letters for Column B to Column E\n",
        "    if (starting_col == 2):\n",
        "      if col_n==4: columns = ['B', 'C', 'D', 'E']\n",
        "      elif col_n==3: columns = ['B', 'C', 'D']\n",
        "      elif col_n==5: columns = ['B', 'C', 'D', 'E', 'F']\n",
        "      elif col_n==7: columns = ['B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
        "    elif (starting_col == 10):\n",
        "      if col_n==4: columns = ['J', 'K', 'L', 'M']\n",
        "      elif col_n==5: columns = ['J', 'K', 'L', 'M', 'N']\n",
        "      elif col_n==7: columns = ['J', 'K', 'L', 'M', 'N','O','P']\n",
        "    elif (starting_col == 6):\n",
        "      if col_n==3: columns = ['F','G','H']\n",
        "    elif (starting_col == 7):\n",
        "      if col_n==4: columns = ['G','H','I','J']\n",
        "    elif (starting_col == 8):\n",
        "      if col_n==5: columns = ['H','I','J','K','L']\n",
        "    elif (starting_col == 9):\n",
        "      if col_n==4: columns = ['I','J','K','L']\n",
        "    # Loop through each value and apply the background color based on its rank\n",
        "    for i, value in enumerate(values_b_to_end):\n",
        "        col_letter = columns[i]  # Get column letter\n",
        "        cell = f\"{col_letter}{len(worksheet.get_all_values())}\"  # Cell reference\n",
        "        rank = rank_map[i]  # Get the rank from the rank map\n",
        "        worksheet.format(cell, {\"backgroundColor\": colors[rank]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "XZRZLB9GhgBF",
      "metadata": {
        "id": "XZRZLB9GhgBF"
      },
      "outputs": [],
      "source": [
        "def build_rank_dict(D, discretized=False):\n",
        "    n = len(D)\n",
        "    vals, counts = np.unique(D, return_counts=True)\n",
        "    rank_dict = {}\n",
        "    rank = 0\n",
        "    last_val = vals[-1] + (n if discretized else 1)\n",
        "    vals = vals.tolist() + [int(last_val)]\n",
        "    counts = counts.tolist() + [0]\n",
        "\n",
        "    for i in range(len(vals) - 1):\n",
        "        rank += counts[i]\n",
        "        rank_dict[vals[i]] = rank\n",
        "    rank_dict[vals[-1]] = rank\n",
        "\n",
        "    return rank_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "kTEhx4k8KNoQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTEhx4k8KNoQ",
        "outputId": "bbc12ab9-f14d-4a5d-8935-53babbedb429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lowest,hightest: 25 100\n",
            "[25, 50, 70, 100]\n",
            "Data_size: 4\n",
            "Domain size: 75\n",
            "true median: 60.0\n",
            "true median rank: 2.0\n",
            "true median rank in rank_dict: 2\n",
            "rank_dict: {25.0: 1, 50.0: 2, 70.0: 3, 100.0: 4, 101: 4}\n"
          ]
        }
      ],
      "source": [
        "# Experiment Data Input\n",
        "\n",
        "dataset_id_dict = {0:\"bank_marketing\", 1:\"adult\", 2:\"cali_housing_test\", 3:\"cali_housing_value\",\n",
        "           5:\"IMDB_time\",6:\"airplane_capacity\",7:\"airplane_range\",8:\"airplane_maintenance\",9:\"airplane_price\",\n",
        "           10: \"old_synthetic_data\",11:\"healthcare_age\",12:\"healthcare_bill\",13:\"estate_assesval\",14:\"estate_saleamount\"}\n",
        "mode = 0\n",
        "if (mode == -1):\n",
        "  n = 4000  # 45#000\n",
        "  domain_size = 100000\n",
        "  D = np.random.uniform(0, domain_size+1, n)\n",
        "\n",
        "  # normal distribution\n",
        "  # n = 1000\n",
        "  # mean = 1\n",
        "  # std_dev = 1\n",
        "  # D = np.random.normal(loc=mean, scale=std_dev, size=n) * 8000\n",
        "\n",
        "  # gamma distribution\n",
        "  # n = 10000\n",
        "  # alpha = 0.5\n",
        "  # beta_g = 5000\n",
        "  # D = np.random.gamma(alpha, beta_g, n)\n",
        "\n",
        "  # Laplace distribution\n",
        "  # n = 10000\n",
        "  # mean = 0\n",
        "  # std_dev = 1000\n",
        "  # D = np.random.laplace(loc=mean, scale=std_dev, size=n)\n",
        "\n",
        "  # Exponential Distribution\n",
        "  # scale = 2000\n",
        "  # D = np.random.exponential(scale=scale, size=4000)\n",
        "\n",
        "  # Beta Distribution\n",
        "  # a = 1\n",
        "  # b = 1\n",
        "  # n = 2000\n",
        "  # scale = 1000000\n",
        "  # D = np.random.beta(a, b, n)\n",
        "  # D = D * scale\n",
        "\n",
        "\n",
        "  # Log Distribution\n",
        "  # mean = 0\n",
        "  # std_dev = 0.5\n",
        "  # n = 3000\n",
        "  # scale = 80000\n",
        "  # D = np.random.lognormal(mean, std_dev, n) * scale\n",
        "\n",
        "  # Combined distribution\n",
        "  # D2 = np.random.beta(b, a, n)\n",
        "  D = D.astype(int)\n",
        "\n",
        "\n",
        "else:\n",
        "  D = readInput(mode,read_data_uuid=\"2c368240d51540a9b0c2ab422f38ffdb\")\n",
        "\n",
        "D = [25,50,70,100]\n",
        "lowest = min(D)\n",
        "highest = max(D)\n",
        "print(\"lowest,hightest:\",lowest, highest)\n",
        "if (lowest < 0):\n",
        "  D = normalize_non_negative(D)\n",
        "\n",
        "lowest = min(D)\n",
        "highest = max(D)\n",
        "\n",
        "df = pd.DataFrame(D)\n",
        "domain_size = highest - lowest\n",
        "n = len(D)\n",
        "\n",
        "D.sort()\n",
        "print(D)\n",
        "\n",
        "D = discretize(D, 1)\n",
        "newD = discrete(D)\n",
        "# print(newD)\n",
        "true_med = np.median(D)\n",
        "\n",
        "print(\"Data_size:\", n)\n",
        "print(\"Domain size:\", domain_size)\n",
        "print(\"true median:\", true_med)\n",
        "# rank_dict\n",
        "\n",
        "\n",
        "rank_dict= build_rank_dict(D)\n",
        "rank_dict_discretized = build_rank_dict(newD,discretized=True)\n",
        "rank_dict_record = rank_dict.copy()\n",
        "rank_dict_record_discretized = rank_dict_discretized.copy()\n",
        "\n",
        "# print(\"rank_dict_discretized:\",rank_dict_discretized)\n",
        "# keys = rank_dict.keys()\n",
        "# ranks = rank_dict.values()\n",
        "# print(next(iter(keys)),lowest,next(reversed(keys)),highest)\n",
        "\n",
        "print(\"true median rank:\",n/2)\n",
        "use_discretized = 0\n",
        "print(\"true median rank in rank_dict:\",find_rank(rank_dict, true_med))\n",
        "print(\"rank_dict:\",rank_dict)\n",
        "#print(find_rank(rank_dict, 51))\n",
        "\n",
        "# Data Persistence\n",
        "if (mode == -1):\n",
        "  df = pd.DataFrame(D)\n",
        "  data_uuid = uuid.uuid4().hex\n",
        "  file_name = f\"data_{data_uuid}.csv\"\n",
        "  df.to_csv(file_name, index=False, header=False)\n",
        "  files.download(file_name)\n",
        "  print(f\"File saved as {file_name}\")\n",
        "else:\n",
        "  data_uuid = dataset_id_dict[mode]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "G-o_F3TWSUzN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-o_F3TWSUzN",
        "outputId": "1dab9aa2-8ca8-43bf-a6b8-c6000c72fd6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "γ1: 153.85288768134956\n"
          ]
        }
      ],
      "source": [
        "# CI Parameters\n",
        "eps = [0.25]\n",
        "beta = [0.01]\n",
        "sens = 1 #fixed\n",
        "num_repeat = 1\n",
        "\n",
        "# for val, rank in rank_dict.items():\n",
        "#     print(val,\"  \",rank)\n",
        "\n",
        "# Parameters for our_CI\n",
        "beta_1 = 0.5 *beta[0]\n",
        "beta_2 = beta[0] - beta_1\n",
        "# eps_1 = 0.5 * eps[0]\n",
        "# eps_2 = eps[0] - eps_1\n",
        "eps_1 = 0.5 * eps[0]\n",
        "eps_2 = eps[0] - eps_1\n",
        "\n",
        "print(\"γ1:\",(2/eps_1) *(np.log(domain_size/beta_1))) # γ)\n",
        "\n",
        "b_list_step = 1\n",
        "\n",
        "download = 0\n",
        "\n",
        "use_discretized = 1\n",
        "show_EM_median_u = False\n",
        "show_EMCI_u = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MMW1vZwFKEmM",
      "metadata": {
        "id": "MMW1vZwFKEmM"
      },
      "outputs": [],
      "source": [
        "# Run Before"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-dXdapmL3kgv",
      "metadata": {
        "id": "-dXdapmL3kgv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ZZKk-CjfKeLU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZKk-CjfKeLU",
        "outputId": "205aeece-a7d2-4a02-cef2-034175cb1e92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------EMCI Test--------------------\n",
            "-------------------ourCI Test--------------------\n",
            "Results for EM based median, beta = 0.01\n",
            "D: [100. 200. 280. 400.]\n",
            "o: 176\n",
            "b_list: range(16, 289, 16)\n",
            "b_intervals: [(16, 65), (80, 288)]\n",
            "interval_prob: [3.132761186032709e-14, 3.203758855868324e-14]\n",
            "Interval (16, 65) has the same fb value: {0}\n",
            "Interval (80, 288) has the same fb value: {1}\n",
            "last experiment CI: 27 60\n",
            "avg estimated median value: 44.0\n",
            "avg median error: 16.0\n",
            "correct rate =  1.0\n",
            "Average CI length = 16.5\n",
            "error quantile is 16.0\n",
            "CI length/ error quantile = 1.03125\n",
            "Average Time to find CI = 0.0031037330627441406\n"
          ]
        }
      ],
      "source": [
        "# Test both\n",
        "\n",
        "# output_mode 0:experiment results,\n",
        "#        1:medians&ranks, CI legnths\n",
        "#        2:both\n",
        "#        3:return row_result and do not write to google spreadsheet\n",
        "\n",
        "# EM_mode  0: use our original EM\n",
        "#       1: use our original EM with discretized data\n",
        "#       2: use their EM with discretized data\n",
        "\n",
        "output_mode = 3\n",
        "download = 0\n",
        "df = pd.DataFrame()\n",
        "print(\"-------------------EMCI Test--------------------\")\n",
        "if show_EM_median_u:\n",
        "  df[\"rank\"] = [0]+list(range(1,len(D)+1)) + ['.']\n",
        "  df[\"data\"] = ['.']+list(D)+ ['.']\n",
        "  df[\"discretized_data\"] = ['.'] + list(newD) + [',']\n",
        "eps_val = eps[0]\n",
        "# test_theirs(eps=[0.5*eps_val], beta=beta, num_repeat=num_repeat,median_method=1,D=newD,sensitivity=0.5) #test EM\n",
        "\n",
        "\n",
        "print(\"-------------------ourCI Test--------------------\")\n",
        "optimized_step = int(2/eps_2)\n",
        "use_discretized = 1\n",
        "test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,CI_method=2,sl_in_u=False)\n",
        "# if (output_mode != 3):`\n",
        "#   color_vertically(worksheet,col=10,row_number=4) #est_median\n",
        "#   color_vertically(worksheet,col=14,row_number=4) #avg error\n",
        "#   color_vertically(worksheet,col=12,row_number=4) #avgCI_length\n",
        "\n",
        "# Result Persistence\n",
        "csv_name = \"weight\"+data_uuid\n",
        "df.to_csv(csv_name+\".csv\",index=False)\n",
        "if (download == 1):\n",
        "  files.download(csv_name+\".csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3gYsrWGcmHHt",
      "metadata": {
        "id": "3gYsrWGcmHHt"
      },
      "outputs": [],
      "source": [
        "# Test any return index\n",
        "# (use our EM_CI(discretized) and SVT_CI)\n",
        "output_mode = 3\n",
        "return_index = 10\n",
        "experiment_target = \"Correct Rate\"\n",
        "column1_title = \"eps\"\n",
        "num_repeat = 10\n",
        "use_opt_stepsize = False\n",
        "b_list_step = 1\n",
        "download = 0\n",
        "show_EM_median_u = False\n",
        "df = pd.DataFrame()\n",
        "# worksheet.append_row([\"alpha:\"+str(alpha),\"beta:\"+str(beta_g)])\n",
        "# worksheet.append_row([\"mean:\"+str(mean),\"std_dev:\"+str(std_dev)])\n",
        "# worksheet.append_row([\"scale:\"+str(scale)])\n",
        "eps_list = [0.25,0.5,1,2,4] #\n",
        "if use_opt_stepsize:\n",
        "  step_option = \"opt step\"\n",
        "else:\n",
        "  step_option = b_list_step\n",
        "worksheet.append_row([data_uuid,\"domain_size:\"+str(domain_size),\"n:\"+str(n),experiment_target,\"b_step:\"+str(step_option),\"num_repeat:\"+str(num_repeat)])\n",
        "worksheet.append_row([column1_title,\"their_EM\",\"our_EM\",\"our_EM(sl_in_u)\"])\n",
        "\n",
        "\n",
        "for eps_val in eps_list:\n",
        "  eps = [eps_val]\n",
        "  print(\"---------Runing eps:\"+str(eps_val)+\"---------\")\n",
        "  EMCI_output = test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=1,D=newD,sensitivity=0.5)[return_index]\n",
        "  eps_1 = 0.5 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  optimized_step = int(2/eps_2)\n",
        "  if use_opt_stepsize:\n",
        "    b_list_step = optimized_step\n",
        "\n",
        "  use_discretized = 1\n",
        "  ourCI_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,CI_method=1,sl_in_u=False)[return_index]\n",
        "\n",
        "  # ourCI2_output = 0\n",
        "  ourCI2_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,CI_method=1,sl_in_u=True)[return_index]\n",
        "  output_RowData = [eps_val,EMCI_output,ourCI_output,ourCI2_output]\n",
        "  worksheet.append_row(output_RowData)\n",
        "  # color_horizontally(worksheet)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aWLOJMtGwb1",
      "metadata": {
        "id": "9aWLOJMtGwb1"
      },
      "outputs": [],
      "source": [
        "# Test both Median err and CI\n",
        "# including eps split\n",
        "output_mode = 3\n",
        "num_repeat=100\n",
        "CIindex = 11\n",
        "errindex = 13\n",
        "b_list_step = 1\n",
        "CI_method = 1\n",
        "\n",
        "first_row_err = [data_uuid,\"domain_size:\"+str(domain_size),\"n:\"+str(n),\"avg Median err\",\"b_step:\"+str(b_list_step),\"num_repeat:\"+str(num_repeat)]\n",
        "first_row_CI = [data_uuid,\"domain_size:\"+str(domain_size),\"n:\"+str(n),\"avg CI length\",\"b_step:\"+str(b_list_step),\"num_repeat:\"+str(num_repeat)]\n",
        "test_types = [\"eps\",\"EM_CI\",\"our_CI(b_step)\",\"our_CI(opt)\",\"our_CI 4:6\",\"our_CI(opt) 4:6\",\"our_CI 6:4\",\"our_CI(opt) 6:4\"]\n",
        "worksheet.append_row(first_row_err+first_row_CI)\n",
        "worksheet.append_row(test_types+test_types)\n",
        "eps_list = [0.25,0.5,1,2,4]\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for eps_val in eps_list:\n",
        "  eps = [eps_val]\n",
        "  print(\"---------Runing eps:\"+str(eps_val)+\"---------\")\n",
        "  EMCI_output = test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=0,D=newD)\n",
        "  EMCI_err = EMCI_output[errindex]\n",
        "  EMCI_CI = EMCI_output[CIindex]\n",
        "\n",
        "  # even split eps\n",
        "  eps_1 = 0.5 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  optimized_step = int(8/eps_2)\n",
        "  use_discretized = 0\n",
        "  ourCI_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,CI_method=CI_method)\n",
        "  ourCI2_output = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D,CI_method=CI_method)\n",
        "  ourCI_err = ourCI_output[errindex]\n",
        "  ourCI_CI = ourCI_output[CIindex]\n",
        "  ourCI2_err = ourCI2_output[errindex]\n",
        "  ourCI2_CI = ourCI2_output[CIindex]\n",
        "\n",
        "  # eps1:eps2 = 4:6\n",
        "  eps_1 = 0.4 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  ourCI3_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D)\n",
        "  ourCI4_output = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D)\n",
        "  ourCI3_err = ourCI3_output[errindex]\n",
        "  ourCI3_CI = ourCI3_output[CIindex]\n",
        "  ourCI4_err = ourCI4_output[errindex]\n",
        "  ourCI4_CI = ourCI4_output[CIindex]\n",
        "\n",
        "  # eps1:eps2 = 6:4\n",
        "  eps_1 = 0.6 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  ourCI5_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D)\n",
        "  ourCI6_output = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D)\n",
        "  ourCI5_err = ourCI5_output[errindex]\n",
        "  ourCI5_CI = ourCI5_output[CIindex]\n",
        "  ourCI6_err = ourCI6_output[errindex]\n",
        "  ourCI6_CI = ourCI6_output[CIindex]\n",
        "\n",
        "\n",
        "  # use_discretized = 1\n",
        "  # ourCI2_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD)[return_index] #our_CI(discretized)\n",
        "  # ourCI3_output = test_ours(b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,med_method=1)[return_index] #our_CI(their_EM)\n",
        "  RowData_err = [eps_val,EMCI_err,ourCI_err,ourCI2_err,ourCI3_err,ourCI4_err,ourCI5_err,ourCI6_err]\n",
        "  RowData_CI = [eps_val,EMCI_CI,ourCI_CI,ourCI2_CI,ourCI3_CI,ourCI4_CI,ourCI5_CI,ourCI6_CI]\n",
        "  Final_RowData = RowData_err+RowData_CI\n",
        "  worksheet.append_row(Final_RowData)\n",
        "  color_horizontally(worksheet,col_n=7)\n",
        "  color_horizontally(worksheet,col_n=7,starting_col=10)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_o2ui9KrPjlM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o2ui9KrPjlM",
        "outputId": "8ad31d74-ee22-42fd-89f7-a145d3461816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------Runing eps:0.25---------\n",
            "Results for EM based median, beta = 0.01\n",
            "factor is 1050\n",
            "Filtered Errors for IQR_based_avg_err: 2.0\n",
            "estimated median value: 8469.0\n",
            "correct rate = 1.0\n",
            "Average CI length = 51.0\n",
            "error quantile is 2.0\n",
            "CI length/ error quantile = 25.5\n",
            "Average Time to find CI = 0.06326079368591309\n",
            "[51.0]\n",
            "[np.float64(2.0)]\n",
            "Results for EM based median, beta = 0.01\n"
          ]
        }
      ],
      "source": [
        "# Test both Median err and CI\n",
        "# no eps split\n",
        "output_mode = 3\n",
        "num_repeat = 1\n",
        "CIindex = 11\n",
        "# errindex = 13 # Est Median error\n",
        "errindex = 10 # this is actually correct rate\n",
        "b_list_step = 1\n",
        "\n",
        "# worksheet.append_row([\"a=\"+str(a),\"b=\"+str(b),\"scale=\"+str(scale),\"true_med:\"+str(true_med)]) # beta distribution parameters\n",
        "first_row_err = [data_uuid,\"domain_size:\"+str(domain_size),\"n:\"+str(n),\"correct rate\",\"b_step:opt\",\"num_repeat:\"+str(num_repeat)]\n",
        "first_row_CI = [\"avg CI length\"]\n",
        "test_types = [\"eps\",\"EM_CI\",\"our_CI\",\"our_CI(sl_in_u)\"]\n",
        "worksheet.append_row(first_row_err+first_row_CI)\n",
        "worksheet.append_row(test_types+test_types)\n",
        "eps_list = [0.25,0.5,1,2]\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for eps_val in eps_list:\n",
        "  eps = [eps_val]\n",
        "  print(\"---------Runing eps:\"+str(eps_val)+\"---------\")\n",
        "  EMCI_output = test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=0,D=newD)\n",
        "  EMCI_err = EMCI_output[errindex]\n",
        "  EMCI_CI = EMCI_output[CIindex]\n",
        "\n",
        "  # even split eps\n",
        "  eps_1 = 0.5 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  optimized_step = int(2/eps_2)\n",
        "  use_discretized = 1\n",
        "  ourCI_output = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,CI_method=1,sl_in_u=False)\n",
        "  ourCI2_output = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,CI_method=1,sl_in_u=True)\n",
        "  ourCI_err = ourCI_output[errindex]\n",
        "  ourCI_CI = ourCI_output[CIindex]\n",
        "  ourCI2_err = ourCI2_output[errindex]\n",
        "  ourCI2_CI = ourCI2_output[CIindex]\n",
        "\n",
        "  RowData_err = [eps_val,EMCI_err,ourCI_err,ourCI2_err]\n",
        "  RowData_CI = [eps_val,EMCI_CI,ourCI_CI,ourCI2_CI]\n",
        "  Final_RowData = RowData_err+RowData_CI\n",
        "  worksheet.append_row(Final_RowData)\n",
        "  # color_horizontally(worksheet,col_n=3)\n",
        "  color_horizontally(worksheet,col_n=3,starting_col=6)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NZiVc23q-bxi",
      "metadata": {
        "id": "NZiVc23q-bxi"
      },
      "outputs": [],
      "source": [
        "# Test CI with different b_step\n",
        "output_mode = 3\n",
        "return_index = 11\n",
        "experiment_target = \"Avg CI Length\"\n",
        "column1_title = \"eps\"\n",
        "b_list_step = 50\n",
        "num_repeat = 20\n",
        "CI_method = 1\n",
        "# worksheet.append_row([\"alpha:\"+str(alpha),\"beta:\"+str(beta_g)])\n",
        "# worksheet.append_row([\"mean:\"+str(mean),\"std_dev:\"+str(std_dev),\"scale=\"+str(scale)])\n",
        "# worksheet.append_row([\"a=\"+str(a),\"b=\"+str(b),\"scale=\"+str(scale),\"true_med:\"+str(true_med)]) # beta distribution parameters\n",
        "worksheet.append_row([data_uuid,\"domain_size:\"+str(domain_size),\"n:\"+str(n),\"Avg CI Length\",\"b_step:\"+str(b_list_step),\"num_repeat:\"+str(num_repeat),\"true_med:\"+str(true_med)])\n",
        "worksheet.append_row([column1_title,\"EM_CI\",\"our_CI(b_step)\",\"our_CI(opt)\",\"our_CI(opt/2)\",\"our_CI(opt*2)\"])\n",
        "# eps_list = [0.25,0.5,1,2] #\n",
        "eps_list = [1,2]\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for eps_val in eps_list:\n",
        "  eps = [eps_val]\n",
        "  print(\"---------Runing eps:\"+str(eps_val)+\"---------\")\n",
        "  EMCI_output = test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=0,D=newD)[return_index] #test EM_CI\n",
        "  eps_1 = 0.5 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  optimized_step = int(2/eps_2)\n",
        "  use_discretized = 1\n",
        "  ourCI_output = test_ours(D=newD,b_list_step=b_list_step,eps=eps, beta=beta, num_repeat=num_repeat,compare = True,CI_method=CI_method )[return_index]\n",
        "  ourCI_output2 = test_ours(D=newD,b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,compare = True,CI_method=CI_method )[return_index]\n",
        "  ourCI_output3 = test_ours(D=newD,b_list_step=int(optimized_step/2),eps=eps, beta=beta, num_repeat=num_repeat,compare = True,CI_method=CI_method )[return_index]\n",
        "  ourCI_output4 = test_ours(D=newD,b_list_step=optimized_step*2,eps=eps, beta=beta, num_repeat=num_repeat,compare = True,CI_method=CI_method )[return_index]\n",
        "  output_RowData = [eps_val,EMCI_output,ourCI_output,ourCI_output2,ourCI_output3,ourCI_output4]\n",
        "  worksheet.append_row(output_RowData)\n",
        "  color_horizontally(worksheet,col_n=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04wHp4pd-iv1",
      "metadata": {
        "id": "04wHp4pd-iv1"
      },
      "outputs": [],
      "source": [
        "# def find_best_eps_splitting(domain_size,eps_val):\n",
        "#   r_values = np.arange(0.01, 1, 0.01)\n",
        "#   min_error_bound = float('inf')\n",
        "#   min_r_value = None\n",
        "#   min_error = None\n",
        "#   for r in r_values:\n",
        "#     eps_1 = float(r * eps_val)\n",
        "#     eps_2 = float(eps_val - eps_1)\n",
        "#     optimized_step = int(8/eps_2)\n",
        "#     b_list_step = optimized_step\n",
        "#     b_list = range(0, b_list_step*int(domain_size/b_list_step),b_list_step)\n",
        "#     if (len(b_list) == 0): b_list = range(0,1)\n",
        "#     C = (2/eps_1) *(np.log(domain_size/beta_1))\n",
        "#     m = len(b_list)\n",
        "#     alpha = (8*np.log(m)+np.log(2/beta_2)) / eps_2\n",
        "#     error_bound = C + alpha + optimized_step\n",
        "#     if error_bound < min_error_bound:\n",
        "#       min_error_bound = error_bound\n",
        "#       min_r_value = r\n",
        "#       min_error = error_bound\n",
        "\n",
        "#   return min_r_value\n",
        "def find_best_eps_splitting(domain_size,eps_val,b_list_step=0):\n",
        "  r_values = np.arange(0.01, 1, 0.01)\n",
        "  min_error_bound = float('inf')\n",
        "  min_r_value = None\n",
        "  for r in r_values:\n",
        "    eps_1 = float(r * eps_val)\n",
        "    eps_2 = float(eps_val - eps_1)\n",
        "    optimized_step = int(2/eps_2)\n",
        "    b_list_step = optimized_step\n",
        "    if (b_list_step == 0): b_list_step = 1\n",
        "    # b_list_step = 1\n",
        "    b_list = range(0, b_list_step*int(domain_size/b_list_step),b_list_step)\n",
        "    if (len(b_list) == 0): b_list = range(0,1)\n",
        "    C1 = (2/eps_1) *(np.log(domain_size/beta_1))\n",
        "    C2 = (1/eps_2) *(np.log(domain_size/(b_list_step*beta_2)))\n",
        "    m = len(b_list)\n",
        "    error_bound = C1 + C2 + 1*b_list_step\n",
        "    if error_bound < min_error_bound:\n",
        "      min_error_bound = error_bound\n",
        "      min_r_value = r\n",
        "\n",
        "  return min_r_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MfrP14FQIzj8",
      "metadata": {
        "id": "MfrP14FQIzj8"
      },
      "outputs": [],
      "source": [
        "# Test both Median err and CI\n",
        "# eps split (using opt_b)\n",
        "output_mode = 3\n",
        "num_repeat = 3\n",
        "CI_method = 1\n",
        "download = 0\n",
        "eps_list = [0.25,0.5,1,2]\n",
        "eps_list = [1]\n",
        "use_rank = False\n",
        "if use_rank:\n",
        "  CIindex = 19\n",
        "  errindex = 17\n",
        "else:\n",
        "  CIindex = 11\n",
        "  errindex = 13\n",
        "\n",
        "first_row_err = [data_uuid,\"domain_size:\"+str(domain_size),\"n:\"+str(n),\"avg Median err\",\"num_repeat:\"+str(num_repeat)]\n",
        "first_row_CI = [data_uuid,\"domain_size:\"+str(domain_size),\"n:\"+str(n),\"avg CI length\",\"num_repeat:\"+str(num_repeat)]\n",
        "# test_types = [\"eps\",\"EM_CI\",\"our_CI 7:3\",\"our_CI 6:4\",\"our_CI 5:5\",\"our_CI 4:6\",\"our_CI 3:7\",\"our_CI(best)\"]\n",
        "test_types = [\"eps\",\"EM_CI\",\"our_CI 6:4\",\"our_CI 5:5\",\"our_CI 4:6\",\"our_CI best\"]\n",
        "worksheet.append_row(first_row_err+first_row_CI)\n",
        "worksheet.append_row(test_types+test_types)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "for eps_val in eps_list:\n",
        "  # time.sleep(10)\n",
        "  eps = [eps_val]\n",
        "  print(\"---------Runing eps:\"+str(eps_val)+\"---------\")\n",
        "  EMCI_output = test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=0,D=newD)\n",
        "  EMCI_err = EMCI_output[errindex]\n",
        "  EMCI_CI = EMCI_output[CIindex]\n",
        "\n",
        "  use_discretized = 1\n",
        "  # 7:3\n",
        "  # eps_1 = 0.7 * eps_val\n",
        "  # eps_2 = eps_val - eps_1\n",
        "  # optimized_step = int(8/eps_2)\n",
        "  # ourCI_output = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D)\n",
        "  # ourCI_err = ourCI_output[errindex]\n",
        "  # ourCI_CI = ourCI_output[CIindex]\n",
        "\n",
        "  # 6:4\n",
        "  eps_1 = 0.6 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  optimized_step = int(2/eps_2)\n",
        "  ourCI_output2 = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,CI_method=CI_method)\n",
        "  ourCI_err2 = ourCI_output2[errindex]\n",
        "  ourCI_CI2 = ourCI_output2[CIindex]\n",
        "\n",
        "  # 5:5\n",
        "  eps_1 = 0.5 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  optimized_step = int(2/eps_2)\n",
        "  ourCI_output3 = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,CI_method=CI_method)\n",
        "  ourCI_err3 = ourCI_output3[errindex]\n",
        "  ourCI_CI3 = ourCI_output3[CIindex]\n",
        "\n",
        "  # 4:6\n",
        "  eps_1 = 0.4 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  optimized_step = int(2/eps_2)\n",
        "  ourCI_output4 = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,CI_method=CI_method)\n",
        "  ourCI_err4 = ourCI_output4[errindex]\n",
        "  ourCI_CI4 = ourCI_output4[CIindex]\n",
        "\n",
        "  # 3:7\n",
        "  # eps_1 = 0.3 * eps_val\n",
        "  # eps_2 = eps_val - eps_1\n",
        "  # optimized_step = int(8/eps_2)\n",
        "  # ourCI_output5 = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D)\n",
        "  # ourCI_err5 = ourCI_output5[errindex]\n",
        "  # ourCI_CI5 = ourCI_output5[CIindex]\n",
        "\n",
        "  # best eps splitting\n",
        "  r = find_best_eps_splitting(domain_size=domain_size,eps_val=eps_val,b_list_step=optimized_step)\n",
        "  eps_1 = r * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  optimized_step = int(2/eps_2)\n",
        "  ourCI_output6 = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD,CI_method=CI_method)\n",
        "  ourCI_err6 = ourCI_output6[errindex]\n",
        "  ourCI_CI6 = ourCI_output6[CIindex]\n",
        "  # RowData_err = [eps_val,EMCI_err,ourCI_err,ourCI_err2,ourCI_err3,ourCI_err4,ourCI_err5,ourCI_err6]\n",
        "  # RowData_CI = [eps_val,EMCI_CI,ourCI_CI,ourCI_CI2,ourCI_CI3,ourCI_CI4,ourCI_CI5,ourCI_CI6]\n",
        "  RowData_err = [eps_val,EMCI_err,ourCI_err2,ourCI_err3,ourCI_err4,ourCI_err6]\n",
        "  RowData_CI = [eps_val,EMCI_CI,ourCI_CI2,ourCI_CI3,ourCI_CI4,ourCI_CI6]\n",
        "  Final_RowData = RowData_err+RowData_CI\n",
        "  worksheet.append_row(Final_RowData)\n",
        "  color_horizontally(worksheet,col_n=5)\n",
        "  color_horizontally(worksheet,col_n=5,starting_col=8)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "utU3fihdTKee",
      "metadata": {
        "id": "utU3fihdTKee"
      },
      "outputs": [],
      "source": [
        "# Test both Median err and CI\n",
        "# discretized\n",
        "output_mode = 0\n",
        "num_repeat=100\n",
        "eps_list = [0.25,0.5,1,2,4]\n",
        "use_rank = False\n",
        "if use_rank:\n",
        "  CIindex = 19\n",
        "  errindex = 17\n",
        "else:\n",
        "  CIindex = 11\n",
        "  errindex = 13\n",
        "\n",
        "worksheet.append_row([\"value:\"])\n",
        "first_row_err = [data_uuid,\"domain_size:\"+str(domain_size),\"n:\"+str(n),\"avg Median err\",\"num_repeat:\"+str(num_repeat)]\n",
        "first_row_CI = [\"avg CI length\",\"num_repeat:\"+str(num_repeat)]\n",
        "test_types = [\"eps\",\"EM_CI\",\"our_CI\",\"our_CI(discre)\"]\n",
        "worksheet.append_row(first_row_err+first_row_CI)\n",
        "worksheet.append_row(test_types+test_types)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "\n",
        "EMCI_output = {key: [] for key in eps_list}\n",
        "ourCI_output = {key: [] for key in eps_list}\n",
        "ourCI_output2 = {key: [] for key in eps_list}\n",
        "\n",
        "\n",
        "for eps_val in eps_list:\n",
        "  time.sleep(10)\n",
        "  eps = [eps_val]\n",
        "  print(\"---------Runing eps:\"+str(eps_val)+\"---------\")\n",
        "  EMCI_output[eps_val] = test_theirs(eps=eps, beta=beta, num_repeat=num_repeat,median_method=0,D=newD)\n",
        "  EMCI_err = EMCI_output[eps_val][errindex]\n",
        "  EMCI_CI = EMCI_output[eps_val][CIindex]\n",
        "\n",
        "  use_discretized = 0\n",
        "  eps_1 = 0.5 * eps_val\n",
        "  eps_2 = eps_val - eps_1\n",
        "  optimized_step = int(8/eps_2)\n",
        "  ourCI_output[eps_val]  = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=D)\n",
        "  ourCI_err = ourCI_output[eps_val][errindex]\n",
        "  ourCI_CI = ourCI_output[eps_val][CIindex]\n",
        "\n",
        "  use_discretized = 1\n",
        "  ourCI_output2[eps_val] = test_ours(b_list_step=optimized_step,eps=eps, beta=beta, num_repeat=num_repeat,D=newD)\n",
        "  ourCI_err2 = ourCI_output2[eps_val][errindex]\n",
        "  ourCI_CI2 = ourCI_output2[eps_val][CIindex]\n",
        "\n",
        "  RowData_err = [eps_val,EMCI_err,ourCI_err,ourCI_err2]\n",
        "  RowData_CI = [eps_val,EMCI_CI,ourCI_CI,ourCI_CI2]\n",
        "  Final_RowData = RowData_err+RowData_CI\n",
        "  worksheet.append_row(Final_RowData)\n",
        "  color_horizontally(worksheet,col_n=3)\n",
        "  color_horizontally(worksheet,col_n=3,starting_col=6)\n",
        "\n",
        "use_rank = True\n",
        "worksheet.append_row([\"rank:\"])\n",
        "first_row_err = [data_uuid,\"domain_size:\"+str(domain_size),\"n:\"+str(n),\"avg Median err\",\"num_repeat:\"+str(num_repeat)]\n",
        "first_row_CI = [\"avg CI length\",\"num_repeat:\"+str(num_repeat)]\n",
        "test_types = [\"eps\",\"EM_CI\",\"our_CI\",\"our_CI(discre)\"]\n",
        "worksheet.append_row(first_row_err+first_row_CI)\n",
        "worksheet.append_row(test_types+test_types)\n",
        "\n",
        "if use_rank:\n",
        "  CIindex = 19\n",
        "  errindex = 17\n",
        "else:\n",
        "  CIindex = 11\n",
        "  errindex = 13\n",
        "for eps_val in eps_list:\n",
        "  time.sleep(10)\n",
        "\n",
        "  EMCI_err = EMCI_output[eps_val][errindex]\n",
        "  EMCI_CI = EMCI_output[eps_val][CIindex]\n",
        "\n",
        "  ourCI_err = ourCI_output[eps_val][errindex]\n",
        "  ourCI_CI = ourCI_output[eps_val][CIindex]\n",
        "\n",
        "  ourCI_err2 = ourCI_output2[eps_val][errindex]\n",
        "  ourCI_CI2 = ourCI_output2[eps_val][CIindex]\n",
        "\n",
        "  RowData_err = [eps_val,EMCI_err,ourCI_err,ourCI_err2]\n",
        "  RowData_CI = [eps_val,EMCI_CI,ourCI_CI,ourCI_CI2]\n",
        "  Final_RowData = RowData_err+RowData_CI\n",
        "  worksheet.append_row(Final_RowData)\n",
        "  color_horizontally(worksheet,col_n=3)\n",
        "  color_horizontally(worksheet,col_n=3,starting_col=6)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GfXUB3LEVFRV",
      "metadata": {
        "id": "GfXUB3LEVFRV"
      },
      "outputs": [],
      "source": [
        "  # Test error bound with diff eps splitting for all datasets\n",
        "import matplotlib.pyplot as plt\n",
        "dataset_id_dict = {0:\"bank_marketing\", 1:\"adult\", 2:\"cali_housing_test\", 3:\"cali_housing_value\",\n",
        "           5:\"IMDB_time\",6:\"airplane_capacity\",7:\"airplane_range\",8:\"airplane_maintenance\",9:\"airplane_price\",\n",
        "           10: \"old_synthetic_data\",11:\"healthcare_age\",12:\"healthcare_bill\",13:\"estate_assesval\",14:\"estate_saleamount\"}\n",
        "eps_list = [0.25,0.5,1,2,4]\n",
        "for mode,data_uuid in dataset_id_dict.items():\n",
        "  if mode == 0:\n",
        "    D = discrete(readInput(mode))\n",
        "    n = len(D)\n",
        "    lowest = int(min(D))\n",
        "    highest = int(max(D))\n",
        "    domain_size = highest - lowest\n",
        "\n",
        "    for eps_val in eps_list:\n",
        "      error_bound_values = []\n",
        "      eps = [eps_val]\n",
        "      r_values = np.arange(0.01, 1, 0.01)\n",
        "      min_error_bound = float('inf')\n",
        "      min_r_value = None\n",
        "      min_error = None\n",
        "      for r in r_values:\n",
        "        eps_1 = float(r * eps_val)\n",
        "        eps_2 = float(eps_val - eps_1)\n",
        "        optimized_step = int(2/eps_2)\n",
        "        b_list_step = optimized_step\n",
        "        l = 1\n",
        "        if (b_list_step == 0): b_list_step = 1\n",
        "        # b_list_step = 1\n",
        "        b_list = range(0, b_list_step*int(domain_size/b_list_step),b_list_step)\n",
        "        if (len(b_list) == 0): b_list = range(0,1)\n",
        "        C1 = (2/eps_1) *(np.log(domain_size/beta_1))\n",
        "        C2 = (1/eps_2) *(np.log(domain_size/(b_list_step*beta_2)))\n",
        "        m = len(b_list)\n",
        "        if (m == 0): print(\"m=0, r=:\",r)\n",
        "        error_bound = C1 + C2 + l * optimized_step\n",
        "        error_bound_values.append(error_bound)\n",
        "        if error_bound < min_error_bound:\n",
        "          min_error_bound = error_bound\n",
        "          min_r_value = r\n",
        "          min_error = error_bound\n",
        "      # Plot\n",
        "      plt.plot(r_values, error_bound_values, label=data_uuid)\n",
        "      plt.scatter(min_r_value, min_error, color='red', zorder=5)\n",
        "      plt.annotate(f\"Min: {min_error:.2f} at r:{min_r_value}\",\n",
        "              (min_r_value, min_error),\n",
        "              textcoords=\"offset points\",\n",
        "              xytext=(0,10),\n",
        "              ha='center', color='red')\n",
        "\n",
        "\n",
        "      plt.title(f\"Error Bound vs r for Dataset: {data_uuid} with eps:{eps_val}\")\n",
        "      plt.xlabel(\"r\")\n",
        "      plt.ylabel(\"Error Bound\")\n",
        "      plt.legend(loc=\"best\")\n",
        "      plt.grid(True)\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0Y_3o6QkJ0Z",
      "metadata": {
        "id": "a0Y_3o6QkJ0Z"
      },
      "outputs": [],
      "source": [
        "# Test error bound with diff domain_size\n",
        "import matplotlib.pyplot as plt\n",
        "dataset_id_dict = {0:\"bank_marketing\", 1:\"adult\", 2:\"cali_housing_test\", 3:\"cali_housing_value\",\n",
        "           5:\"IMDB_time\",6:\"airplane_capacity\",7:\"airplane_range\",8:\"airplane_maintenance\",9:\"airplane_price\",\n",
        "           10: \"old_synthetic_data\",11:\"healthcare_age\",12:\"healthcare_bill\",13:\"estate_assesval\",14:\"estate_saleamount\"}\n",
        "eps_list = [0.25,0.5,1,2,4]\n",
        "domain_sizes = range(1000,100000,1)\n",
        "error_bound_values = []\n",
        "min_error_bound = float('inf')\n",
        "min_domain = None\n",
        "min_error = None\n",
        "r = 0.6\n",
        "eps_val = 2\n",
        "l = 1\n",
        "eps_1 = float(r * eps_val)\n",
        "eps_2 = float(eps_val - eps_1)\n",
        "for domain_size in domain_sizes:\n",
        "  optimized_step = int(2/eps_2)\n",
        "  b_list_step = optimized_step\n",
        "  # b_list_step = 1\n",
        "  b_list = range(b_list_step, b_list_step*int(domain_size/b_list_step),b_list_step)\n",
        "  C1 = (2/eps_1) *(np.log(domain_size/beta_1))\n",
        "  C2 = (1/eps_2) *(np.log(domain_size/(b_list_step*beta_2)))\n",
        "  m = len(b_list)\n",
        "  # alpha = (8*np.log(m)+np.log(2/beta_2)) / eps_2\n",
        "  if (m == 0): print(\"m=0, r=:\",r)\n",
        "  error_bound = C1 + C2 + b_list_step\n",
        "  error_bound_values.append(error_bound)\n",
        "  if error_bound < min_error_bound:\n",
        "    min_error_bound = error_bound\n",
        "    min_domain = domain_size\n",
        "    min_error = error_bound\n",
        "plt.plot(domain_sizes, error_bound_values, label=data_uuid)\n",
        "plt.scatter(min_domain, min_error, color='red', zorder=5)\n",
        "\n",
        "\n",
        "\n",
        "plt.title(f\"Error Bound vs domain_size\")\n",
        "plt.xlabel(\"domain_size\")\n",
        "plt.ylabel(\"Error Bound\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MHg0pEK8eWOE",
      "metadata": {
        "id": "MHg0pEK8eWOE"
      },
      "outputs": [],
      "source": [
        "# see eps splitting\n",
        "import math\n",
        "\n",
        "N = 1000\n",
        "beta1 = 0.005\n",
        "beta2 = 0.005\n",
        "epsilon = 1\n",
        "max_iterations = 100\n",
        "# s = 2/(2/3)\n",
        "s = 1\n",
        "def calculate_epsilon_1(epsilon_2, N, beta1, beta2, s):\n",
        "  return epsilon_2 * math.sqrt(math.log(N / beta1) / math.log(N / (s * beta2)))\n",
        "\n",
        "\n",
        "def iterative_optimization(N, beta1, beta2, epsilon, max_iterations):\n",
        "  global s\n",
        "  iteration = 0\n",
        "  while iteration < max_iterations:\n",
        "    denominator = 1 + math.sqrt(math.log(N / beta1) / math.log(N / (s * beta2)))\n",
        "    epsilon_2 = epsilon / denominator\n",
        "    epsilon_1 = calculate_epsilon_1(epsilon_2, N, beta1, beta2, s)\n",
        "    epsilon_2 = epsilon_2\n",
        "    s = int(2/epsilon_2)\n",
        "    iteration += 1\n",
        "    # print(s)\n",
        "    # print(epsilon_1,epsilon_2)\n",
        "  return epsilon_1, epsilon_2\n",
        "\n",
        "D = discrete(readInput(0))\n",
        "n = len(D)\n",
        "lowest = int(min(D))\n",
        "highest = int(max(D))\n",
        "domain_size = highest - lowest\n",
        "eps_1,eps_2 = iterative_optimization(N, beta1, beta2, epsilon, max_iterations)\n",
        "print(eps_1,eps_2)\n",
        "C1 = (2/eps_1) *(np.log(domain_size/beta_1))\n",
        "C2 = (1/eps_2) *(np.log(domain_size/(b_list_step*beta_2)))\n",
        "b_list_step = 2/eps_2\n",
        "error_bound = C1 + C2 + b_list_step\n",
        "print(error_bound)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cm10j2-py96T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm10j2-py96T",
        "outputId": "86053e8d-275b-4e26-d220-03b2342909f8"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'build_rank_dict' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m D \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m25\u001b[39m,\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m75\u001b[39m]\n\u001b[1;32m      2\u001b[0m newD \u001b[38;5;241m=\u001b[39m discrete(D)\n\u001b[0;32m----> 3\u001b[0m rank_dict\u001b[38;5;241m=\u001b[39m build_rank_dict(D)\n\u001b[1;32m      4\u001b[0m rank_dict_discretized \u001b[38;5;241m=\u001b[39m build_rank_dict(newD,discretized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m use_discretized \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_rank_dict' is not defined"
          ]
        }
      ],
      "source": [
        "D = [25,50,50,75]\n",
        "newD = discrete(D)\n",
        "rank_dict= build_rank_dict(D)\n",
        "rank_dict_discretized = build_rank_dict(newD,discretized=True)\n",
        "\n",
        "\n",
        "use_discretized = 0\n",
        "print(\"test 1:\")\n",
        "print(\"rank_dict:\",rank_dict)\n",
        "for i in range(101):\n",
        "  res = find_rank(rank_dict,i)\n",
        "  print(i,res)\n",
        "\n",
        "use_discretized = 1\n",
        "print(\"test 2:\")\n",
        "print(\"rank_dict_discretized:\",rank_dict_discretized)\n",
        "for i in range(401):\n",
        "  res = find_rank(rank_dict_discretized,i)\n",
        "  print(i,i//4,res)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
